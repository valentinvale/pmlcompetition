{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.5.0-py3-none-win_amd64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from lightgbm) (1.26.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from lightgbm) (1.11.4)\n",
      "Downloading lightgbm-4.5.0-py3-none-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/1.4 MB 1.2 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.3/1.4 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.7/1.4 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.2/1.4 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 6.1 MB/s eta 0:00:00\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from lightgbm import LGBMRegressor\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")  \n",
    "val_data = pd.read_csv(\"val.csv\")     \n",
    "test_data = pd.read_csv(\"test.csv\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spearman_correlation(y_true, y_pred):\n",
    "    return spearmanr(y_true, y_pred).correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(data):\n",
    "    data[\"sentence_length\"] = data[\"text\"].apply(len)\n",
    "    data[\"word_count\"] = data[\"text\"].apply(lambda x: len(x.split()))\n",
    "    data[\"avg_word_length\"] = data[\"text\"].apply(\n",
    "        lambda x: np.mean([len(word) for word in x.split()]) if len(x.split()) > 0 else 0\n",
    "    )\n",
    "    data[\"punctuation_count\"] = data[\"text\"].str.count(r\"[^\\w\\s]\")\n",
    "    return data[[\"sentence_length\", \"word_count\", \"avg_word_length\", \"punctuation_count\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = extract_features(train_data)\n",
    "y_train = train_data[\"score\"]\n",
    "\n",
    "x_val = extract_features(val_data)\n",
    "y_val = val_data[\"score\"]\n",
    "\n",
    "X_test = extract_features(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 370\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 0.520791\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's rmse: 0.812291\tvalid_0's l2: 0.659817\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(learning_rate=0.05, n_estimators=500, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(learning_rate=0.05, n_estimators=500, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor(learning_rate=0.05, n_estimators=500, random_state=42)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import early_stopping\n",
    "\n",
    "# Callback for early stopping\n",
    "callbacks = [early_stopping(stopping_rounds=50, verbose=True)]\n",
    "\n",
    "# Train the model with callbacks\n",
    "lgb_model = LGBMRegressor(n_estimators=500, learning_rate=0.05, random_state=42)\n",
    "lgb_model.fit(x_train, y_train, eval_set=[(x_val, y_val)], eval_metric=\"rmse\", callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Spearman Correlation: 0.06544091085924854\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = lgb_model.predict(x_val)\n",
    "spearman_corr = spearman_correlation(y_val, y_val_pred)\n",
    "print(\"Validation Spearman Correlation:\", spearman_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textstat\n",
      "  Downloading textstat-0.7.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting pyphen (from textstat)\n",
      "  Downloading pyphen-0.17.0-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from textstat) (68.0.0)\n",
      "Downloading textstat-0.7.4-py3-none-any.whl (105 kB)\n",
      "   ---------------------------------------- 0.0/105.1 kB ? eta -:--:--\n",
      "   ----------- --------------------------- 30.7/105.1 kB 640.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 105.1/105.1 kB 1.2 MB/s eta 0:00:00\n",
      "Downloading pyphen-0.17.0-py3-none-any.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.1 MB 6.5 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.6/2.1 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.2/2.1 MB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 12.1 MB/s eta 0:00:00\n",
      "Installing collected packages: pyphen, textstat\n",
      "Successfully installed pyphen-0.17.0 textstat-0.7.4\n"
     ]
    }
   ],
   "source": [
    "!pip install textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.1.3-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from xgboost) (1.26.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from xgboost) (1.11.4)\n",
      "Downloading xgboost-2.1.3-py3-none-win_amd64.whl (124.9 MB)\n",
      "   ---------------------------------------- 0.0/124.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/124.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/124.9 MB 656.4 kB/s eta 0:03:11\n",
      "   ---------------------------------------- 0.2/124.9 MB 1.3 MB/s eta 0:01:36\n",
      "   ---------------------------------------- 0.4/124.9 MB 2.3 MB/s eta 0:00:56\n",
      "   ---------------------------------------- 0.7/124.9 MB 3.0 MB/s eta 0:00:42\n",
      "   ---------------------------------------- 0.9/124.9 MB 3.4 MB/s eta 0:00:37\n",
      "    --------------------------------------- 1.6/124.9 MB 5.2 MB/s eta 0:00:24\n",
      "    --------------------------------------- 2.1/124.9 MB 5.9 MB/s eta 0:00:21\n",
      "    --------------------------------------- 3.1/124.9 MB 7.5 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 3.9/124.9 MB 9.0 MB/s eta 0:00:14\n",
      "   - -------------------------------------- 5.0/124.9 MB 10.2 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 6.0/124.9 MB 11.3 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 7.1/124.9 MB 12.3 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 8.3/124.9 MB 13.2 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 9.5/124.9 MB 14.1 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 9.7/124.9 MB 14.4 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 11.7/124.9 MB 21.8 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 11.9/124.9 MB 21.1 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 12.6/124.9 MB 21.8 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 13.7/124.9 MB 21.8 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 14.4/124.9 MB 20.5 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 15.0/124.9 MB 20.5 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 15.7/124.9 MB 19.9 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 16.3/124.9 MB 18.7 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 17.0/124.9 MB 18.2 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 17.0/124.9 MB 17.2 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 17.8/124.9 MB 16.4 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 18.1/124.9 MB 15.6 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 18.5/124.9 MB 14.9 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 18.5/124.9 MB 14.6 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 19.0/124.9 MB 13.4 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 19.2/124.9 MB 13.1 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 19.5/124.9 MB 12.4 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 19.7/124.9 MB 11.9 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 19.9/124.9 MB 12.1 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 20.2/124.9 MB 11.5 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 20.4/124.9 MB 10.9 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 20.7/124.9 MB 10.4 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 20.8/124.9 MB 9.9 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 21.1/124.9 MB 9.5 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 21.3/124.9 MB 9.2 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 21.6/124.9 MB 8.8 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 21.8/124.9 MB 8.7 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 22.1/124.9 MB 8.4 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 22.3/124.9 MB 8.5 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 22.5/124.9 MB 8.2 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 22.8/124.9 MB 7.9 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 23.0/124.9 MB 7.8 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 23.2/124.9 MB 7.5 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 23.3/124.9 MB 7.3 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 23.5/124.9 MB 7.0 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 23.7/124.9 MB 6.9 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 23.9/124.9 MB 6.8 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 24.1/124.9 MB 6.7 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 24.3/124.9 MB 6.5 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 24.5/124.9 MB 6.4 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 24.6/124.9 MB 6.3 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 24.8/124.9 MB 6.2 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 25.0/124.9 MB 6.1 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 25.2/124.9 MB 5.9 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 25.4/124.9 MB 5.8 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 25.6/124.9 MB 5.7 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 25.8/124.9 MB 5.6 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 26.0/124.9 MB 5.5 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 26.2/124.9 MB 5.5 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 26.4/124.9 MB 5.3 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 26.6/124.9 MB 5.4 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 26.8/124.9 MB 5.2 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 26.9/124.9 MB 5.2 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 27.2/124.9 MB 5.0 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 27.3/124.9 MB 5.1 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 27.5/124.9 MB 5.0 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 27.6/124.9 MB 4.9 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 27.7/124.9 MB 4.8 MB/s eta 0:00:21\n",
      "   -------- ------------------------------- 27.9/124.9 MB 4.7 MB/s eta 0:00:21\n",
      "   -------- ------------------------------- 28.0/124.9 MB 4.6 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 28.2/124.9 MB 4.5 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 28.3/124.9 MB 4.5 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 28.5/124.9 MB 4.5 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 28.6/124.9 MB 4.4 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 28.8/124.9 MB 4.5 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 28.9/124.9 MB 4.4 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 29.1/124.9 MB 4.3 MB/s eta 0:00:23\n",
      "   --------- ------------------------------ 29.2/124.9 MB 4.3 MB/s eta 0:00:23\n",
      "   --------- ------------------------------ 29.4/124.9 MB 4.3 MB/s eta 0:00:23\n",
      "   --------- ------------------------------ 29.5/124.9 MB 4.2 MB/s eta 0:00:23\n",
      "   --------- ------------------------------ 29.7/124.9 MB 4.2 MB/s eta 0:00:23\n",
      "   --------- ------------------------------ 29.8/124.9 MB 4.1 MB/s eta 0:00:23\n",
      "   --------- ------------------------------ 30.0/124.9 MB 4.1 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 30.2/124.9 MB 4.1 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 30.3/124.9 MB 4.1 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 30.5/124.9 MB 4.0 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 30.6/124.9 MB 4.0 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 30.8/124.9 MB 4.0 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 31.0/124.9 MB 4.0 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 31.1/124.9 MB 4.0 MB/s eta 0:00:24\n",
      "   ---------- ----------------------------- 31.3/124.9 MB 3.9 MB/s eta 0:00:24\n",
      "   ---------- ----------------------------- 31.3/124.9 MB 3.9 MB/s eta 0:00:24\n",
      "   ---------- ----------------------------- 31.6/124.9 MB 3.9 MB/s eta 0:00:24\n",
      "   ---------- ----------------------------- 31.7/124.9 MB 3.9 MB/s eta 0:00:25\n",
      "   ---------- ----------------------------- 31.8/124.9 MB 3.8 MB/s eta 0:00:25\n",
      "   ---------- ----------------------------- 31.9/124.9 MB 3.8 MB/s eta 0:00:25\n",
      "   ---------- ----------------------------- 32.0/124.9 MB 3.7 MB/s eta 0:00:25\n",
      "   ---------- ----------------------------- 32.1/124.9 MB 3.7 MB/s eta 0:00:26\n",
      "   ---------- ----------------------------- 32.2/124.9 MB 3.7 MB/s eta 0:00:26\n",
      "   ---------- ----------------------------- 32.3/124.9 MB 3.6 MB/s eta 0:00:26\n",
      "   ---------- ----------------------------- 32.5/124.9 MB 3.6 MB/s eta 0:00:26\n",
      "   ---------- ----------------------------- 32.6/124.9 MB 3.6 MB/s eta 0:00:26\n",
      "   ---------- ----------------------------- 32.7/124.9 MB 3.6 MB/s eta 0:00:26\n",
      "   ---------- ----------------------------- 32.8/124.9 MB 3.6 MB/s eta 0:00:26\n",
      "   ---------- ----------------------------- 33.0/124.9 MB 3.5 MB/s eta 0:00:27\n",
      "   ---------- ----------------------------- 33.1/124.9 MB 3.5 MB/s eta 0:00:27\n",
      "   ---------- ----------------------------- 33.2/124.9 MB 3.5 MB/s eta 0:00:27\n",
      "   ---------- ----------------------------- 33.3/124.9 MB 3.4 MB/s eta 0:00:27\n",
      "   ---------- ----------------------------- 33.4/124.9 MB 3.4 MB/s eta 0:00:27\n",
      "   ---------- ----------------------------- 33.6/124.9 MB 3.4 MB/s eta 0:00:27\n",
      "   ---------- ----------------------------- 33.7/124.9 MB 3.4 MB/s eta 0:00:27\n",
      "   ---------- ----------------------------- 33.8/124.9 MB 3.4 MB/s eta 0:00:27\n",
      "   ---------- ----------------------------- 34.0/124.9 MB 3.4 MB/s eta 0:00:27\n",
      "   ---------- ----------------------------- 34.1/124.9 MB 3.4 MB/s eta 0:00:28\n",
      "   ---------- ----------------------------- 34.2/124.9 MB 3.3 MB/s eta 0:00:28\n",
      "   ---------- ----------------------------- 34.3/124.9 MB 3.3 MB/s eta 0:00:28\n",
      "   ----------- ---------------------------- 34.5/124.9 MB 3.3 MB/s eta 0:00:28\n",
      "   ----------- ---------------------------- 34.6/124.9 MB 3.3 MB/s eta 0:00:28\n",
      "   ----------- ---------------------------- 34.7/124.9 MB 3.3 MB/s eta 0:00:28\n",
      "   ----------- ---------------------------- 34.9/124.9 MB 3.3 MB/s eta 0:00:28\n",
      "   ----------- ---------------------------- 35.0/124.9 MB 3.3 MB/s eta 0:00:28\n",
      "   ----------- ---------------------------- 35.1/124.9 MB 3.2 MB/s eta 0:00:28\n",
      "   ----------- ---------------------------- 35.3/124.9 MB 3.2 MB/s eta 0:00:28\n",
      "   ----------- ---------------------------- 35.4/124.9 MB 3.2 MB/s eta 0:00:29\n",
      "   ----------- ---------------------------- 35.5/124.9 MB 3.2 MB/s eta 0:00:28\n",
      "   ----------- ---------------------------- 35.7/124.9 MB 3.2 MB/s eta 0:00:29\n",
      "   ----------- ---------------------------- 35.8/124.9 MB 3.2 MB/s eta 0:00:29\n",
      "   ----------- ---------------------------- 36.0/124.9 MB 3.1 MB/s eta 0:00:29\n",
      "   ----------- ---------------------------- 36.1/124.9 MB 3.1 MB/s eta 0:00:29\n",
      "   ----------- ---------------------------- 36.1/124.9 MB 3.1 MB/s eta 0:00:29\n",
      "   ----------- ---------------------------- 36.3/124.9 MB 3.1 MB/s eta 0:00:29\n",
      "   ----------- ---------------------------- 36.4/124.9 MB 3.1 MB/s eta 0:00:29\n",
      "   ----------- ---------------------------- 36.5/124.9 MB 3.1 MB/s eta 0:00:29\n",
      "   ----------- ---------------------------- 36.6/124.9 MB 3.0 MB/s eta 0:00:30\n",
      "   ----------- ---------------------------- 36.7/124.9 MB 3.0 MB/s eta 0:00:30\n",
      "   ----------- ---------------------------- 36.8/124.9 MB 3.0 MB/s eta 0:00:30\n",
      "   ----------- ---------------------------- 36.9/124.9 MB 3.0 MB/s eta 0:00:30\n",
      "   ----------- ---------------------------- 37.1/124.9 MB 3.0 MB/s eta 0:00:30\n",
      "   ----------- ---------------------------- 37.2/124.9 MB 3.0 MB/s eta 0:00:30\n",
      "   ----------- ---------------------------- 37.3/124.9 MB 2.9 MB/s eta 0:00:30\n",
      "   ----------- ---------------------------- 37.4/124.9 MB 2.9 MB/s eta 0:00:30\n",
      "   ------------ --------------------------- 37.5/124.9 MB 2.9 MB/s eta 0:00:31\n",
      "   ------------ --------------------------- 37.6/124.9 MB 2.9 MB/s eta 0:00:31\n",
      "   ------------ --------------------------- 37.7/124.9 MB 2.9 MB/s eta 0:00:31\n",
      "   ------------ --------------------------- 37.8/124.9 MB 2.9 MB/s eta 0:00:31\n",
      "   ------------ --------------------------- 38.0/124.9 MB 2.9 MB/s eta 0:00:31\n",
      "   ------------ --------------------------- 38.1/124.9 MB 2.9 MB/s eta 0:00:31\n",
      "   ------------ --------------------------- 38.2/124.9 MB 2.9 MB/s eta 0:00:31\n",
      "   ------------ --------------------------- 38.3/124.9 MB 2.9 MB/s eta 0:00:31\n",
      "   ------------ --------------------------- 38.4/124.9 MB 2.8 MB/s eta 0:00:31\n",
      "   ------------ --------------------------- 38.5/124.9 MB 2.8 MB/s eta 0:00:31\n",
      "   ------------ --------------------------- 38.6/124.9 MB 2.8 MB/s eta 0:00:31\n",
      "   ------------ --------------------------- 38.6/124.9 MB 2.8 MB/s eta 0:00:31\n",
      "   ------------ --------------------------- 38.7/124.9 MB 2.8 MB/s eta 0:00:32\n",
      "   ------------ --------------------------- 38.8/124.9 MB 2.8 MB/s eta 0:00:32\n",
      "   ------------ --------------------------- 38.9/124.9 MB 2.7 MB/s eta 0:00:32\n",
      "   ------------ --------------------------- 39.0/124.9 MB 2.7 MB/s eta 0:00:32\n",
      "   ------------ --------------------------- 39.1/124.9 MB 2.7 MB/s eta 0:00:32\n",
      "   ------------ --------------------------- 39.2/124.9 MB 2.7 MB/s eta 0:00:32\n",
      "   ------------ --------------------------- 39.2/124.9 MB 2.7 MB/s eta 0:00:32\n",
      "   ------------ --------------------------- 39.3/124.9 MB 2.7 MB/s eta 0:00:33\n",
      "   ------------ --------------------------- 39.4/124.9 MB 2.7 MB/s eta 0:00:33\n",
      "   ------------ --------------------------- 39.5/124.9 MB 2.7 MB/s eta 0:00:33\n",
      "   ------------ --------------------------- 39.6/124.9 MB 2.6 MB/s eta 0:00:33\n",
      "   ------------ --------------------------- 39.7/124.9 MB 2.6 MB/s eta 0:00:33\n",
      "   ------------ --------------------------- 39.8/124.9 MB 2.6 MB/s eta 0:00:33\n",
      "   ------------ --------------------------- 39.9/124.9 MB 2.6 MB/s eta 0:00:33\n",
      "   ------------ --------------------------- 39.9/124.9 MB 2.6 MB/s eta 0:00:33\n",
      "   ------------ --------------------------- 40.0/124.9 MB 2.6 MB/s eta 0:00:34\n",
      "   ------------ --------------------------- 40.1/124.9 MB 2.6 MB/s eta 0:00:34\n",
      "   ------------ --------------------------- 40.3/124.9 MB 2.5 MB/s eta 0:00:34\n",
      "   ------------ --------------------------- 40.3/124.9 MB 2.5 MB/s eta 0:00:34\n",
      "   ------------ --------------------------- 40.4/124.9 MB 2.5 MB/s eta 0:00:34\n",
      "   ------------ --------------------------- 40.5/124.9 MB 2.5 MB/s eta 0:00:34\n",
      "   ------------- -------------------------- 40.6/124.9 MB 2.5 MB/s eta 0:00:34\n",
      "   ------------- -------------------------- 40.7/124.9 MB 2.5 MB/s eta 0:00:34\n",
      "   ------------- -------------------------- 40.8/124.9 MB 2.5 MB/s eta 0:00:34\n",
      "   ------------- -------------------------- 40.8/124.9 MB 2.5 MB/s eta 0:00:35\n",
      "   ------------- -------------------------- 40.9/124.9 MB 2.5 MB/s eta 0:00:35\n",
      "   ------------- -------------------------- 41.0/124.9 MB 2.4 MB/s eta 0:00:35\n",
      "   ------------- -------------------------- 41.1/124.9 MB 2.4 MB/s eta 0:00:35\n",
      "   ------------- -------------------------- 41.2/124.9 MB 2.4 MB/s eta 0:00:35\n",
      "   ------------- -------------------------- 41.2/124.9 MB 2.4 MB/s eta 0:00:36\n",
      "   ------------- -------------------------- 41.3/124.9 MB 2.4 MB/s eta 0:00:36\n",
      "   ------------- -------------------------- 41.4/124.9 MB 2.4 MB/s eta 0:00:36\n",
      "   ------------- -------------------------- 41.5/124.9 MB 2.4 MB/s eta 0:00:36\n",
      "   ------------- -------------------------- 41.6/124.9 MB 2.4 MB/s eta 0:00:36\n",
      "   ------------- -------------------------- 41.6/124.9 MB 2.3 MB/s eta 0:00:36\n",
      "   ------------- -------------------------- 41.7/124.9 MB 2.3 MB/s eta 0:00:36\n",
      "   ------------- -------------------------- 41.8/124.9 MB 2.3 MB/s eta 0:00:36\n",
      "   ------------- -------------------------- 41.9/124.9 MB 2.3 MB/s eta 0:00:36\n",
      "   ------------- -------------------------- 41.9/124.9 MB 2.3 MB/s eta 0:00:36\n",
      "   ------------- -------------------------- 42.0/124.9 MB 2.3 MB/s eta 0:00:37\n",
      "   ------------- -------------------------- 42.1/124.9 MB 2.3 MB/s eta 0:00:37\n",
      "   ------------- -------------------------- 42.2/124.9 MB 2.3 MB/s eta 0:00:37\n",
      "   ------------- -------------------------- 42.3/124.9 MB 2.3 MB/s eta 0:00:37\n",
      "   ------------- -------------------------- 42.4/124.9 MB 2.3 MB/s eta 0:00:37\n",
      "   ------------- -------------------------- 42.5/124.9 MB 2.3 MB/s eta 0:00:37\n",
      "   ------------- -------------------------- 42.6/124.9 MB 2.3 MB/s eta 0:00:37\n",
      "   ------------- -------------------------- 42.7/124.9 MB 2.3 MB/s eta 0:00:37\n",
      "   ------------- -------------------------- 42.7/124.9 MB 2.2 MB/s eta 0:00:37\n",
      "   ------------- -------------------------- 42.8/124.9 MB 2.2 MB/s eta 0:00:37\n",
      "   ------------- -------------------------- 42.9/124.9 MB 2.2 MB/s eta 0:00:37\n",
      "   ------------- -------------------------- 43.0/124.9 MB 2.2 MB/s eta 0:00:37\n",
      "   ------------- -------------------------- 43.1/124.9 MB 2.2 MB/s eta 0:00:37\n",
      "   ------------- -------------------------- 43.2/124.9 MB 2.2 MB/s eta 0:00:37\n",
      "   ------------- -------------------------- 43.3/124.9 MB 2.2 MB/s eta 0:00:37\n",
      "   ------------- -------------------------- 43.4/124.9 MB 2.2 MB/s eta 0:00:37\n",
      "   ------------- -------------------------- 43.5/124.9 MB 2.2 MB/s eta 0:00:37\n",
      "   ------------- -------------------------- 43.6/124.9 MB 2.2 MB/s eta 0:00:37\n",
      "   ------------- -------------------------- 43.7/124.9 MB 2.2 MB/s eta 0:00:37\n",
      "   -------------- ------------------------- 43.8/124.9 MB 2.2 MB/s eta 0:00:37\n",
      "   -------------- ------------------------- 43.9/124.9 MB 2.2 MB/s eta 0:00:37\n",
      "   -------------- ------------------------- 44.0/124.9 MB 2.2 MB/s eta 0:00:37\n",
      "   -------------- ------------------------- 44.1/124.9 MB 2.2 MB/s eta 0:00:37\n",
      "   -------------- ------------------------- 44.2/124.9 MB 2.2 MB/s eta 0:00:37\n",
      "   -------------- ------------------------- 44.3/124.9 MB 2.2 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 44.4/124.9 MB 2.2 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 44.5/124.9 MB 2.2 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 44.6/124.9 MB 2.2 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 44.7/124.9 MB 2.2 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 44.8/124.9 MB 2.2 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 44.9/124.9 MB 2.1 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 45.0/124.9 MB 2.1 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 45.0/124.9 MB 2.1 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 45.1/124.9 MB 2.1 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 45.2/124.9 MB 2.1 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 45.3/124.9 MB 2.1 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 45.4/124.9 MB 2.1 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 45.4/124.9 MB 2.1 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 45.5/124.9 MB 2.1 MB/s eta 0:00:39\n",
      "   -------------- ------------------------- 45.6/124.9 MB 2.1 MB/s eta 0:00:39\n",
      "   -------------- ------------------------- 45.7/124.9 MB 2.1 MB/s eta 0:00:39\n",
      "   -------------- ------------------------- 45.8/124.9 MB 2.1 MB/s eta 0:00:39\n",
      "   -------------- ------------------------- 45.9/124.9 MB 2.1 MB/s eta 0:00:39\n",
      "   -------------- ------------------------- 45.9/124.9 MB 2.1 MB/s eta 0:00:39\n",
      "   -------------- ------------------------- 46.0/124.9 MB 2.0 MB/s eta 0:00:39\n",
      "   -------------- ------------------------- 46.1/124.9 MB 2.0 MB/s eta 0:00:39\n",
      "   -------------- ------------------------- 46.2/124.9 MB 2.0 MB/s eta 0:00:39\n",
      "   -------------- ------------------------- 46.2/124.9 MB 2.0 MB/s eta 0:00:40\n",
      "   -------------- ------------------------- 46.3/124.9 MB 2.0 MB/s eta 0:00:40\n",
      "   -------------- ------------------------- 46.4/124.9 MB 2.0 MB/s eta 0:00:40\n",
      "   -------------- ------------------------- 46.4/124.9 MB 2.0 MB/s eta 0:00:40\n",
      "   -------------- ------------------------- 46.5/124.9 MB 2.0 MB/s eta 0:00:40\n",
      "   -------------- ------------------------- 46.6/124.9 MB 2.0 MB/s eta 0:00:40\n",
      "   -------------- ------------------------- 46.6/124.9 MB 2.0 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 46.7/124.9 MB 2.0 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 46.7/124.9 MB 1.9 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 46.8/124.9 MB 1.9 MB/s eta 0:00:41\n",
      "   --------------- ------------------------ 46.9/124.9 MB 1.9 MB/s eta 0:00:41\n",
      "   --------------- ------------------------ 46.9/124.9 MB 1.9 MB/s eta 0:00:41\n",
      "   --------------- ------------------------ 47.0/124.9 MB 1.9 MB/s eta 0:00:41\n",
      "   --------------- ------------------------ 47.1/124.9 MB 1.9 MB/s eta 0:00:41\n",
      "   --------------- ------------------------ 47.2/124.9 MB 1.9 MB/s eta 0:00:41\n",
      "   --------------- ------------------------ 47.2/124.9 MB 1.9 MB/s eta 0:00:41\n",
      "   --------------- ------------------------ 47.3/124.9 MB 1.9 MB/s eta 0:00:41\n",
      "   --------------- ------------------------ 47.4/124.9 MB 1.9 MB/s eta 0:00:41\n",
      "   --------------- ------------------------ 47.5/124.9 MB 1.9 MB/s eta 0:00:41\n",
      "   --------------- ------------------------ 47.5/124.9 MB 1.9 MB/s eta 0:00:41\n",
      "   --------------- ------------------------ 47.6/124.9 MB 1.9 MB/s eta 0:00:42\n",
      "   --------------- ------------------------ 47.7/124.9 MB 1.9 MB/s eta 0:00:42\n",
      "   --------------- ------------------------ 47.8/124.9 MB 1.9 MB/s eta 0:00:42\n",
      "   --------------- ------------------------ 47.8/124.9 MB 1.9 MB/s eta 0:00:42\n",
      "   --------------- ------------------------ 47.9/124.9 MB 1.9 MB/s eta 0:00:42\n",
      "   --------------- ------------------------ 48.0/124.9 MB 1.9 MB/s eta 0:00:42\n",
      "   --------------- ------------------------ 48.1/124.9 MB 1.9 MB/s eta 0:00:42\n",
      "   --------------- ------------------------ 48.2/124.9 MB 1.8 MB/s eta 0:00:42\n",
      "   --------------- ------------------------ 48.2/124.9 MB 1.8 MB/s eta 0:00:42\n",
      "   --------------- ------------------------ 48.3/124.9 MB 1.8 MB/s eta 0:00:42\n",
      "   --------------- ------------------------ 48.4/124.9 MB 1.8 MB/s eta 0:00:42\n",
      "   --------------- ------------------------ 48.4/124.9 MB 1.8 MB/s eta 0:00:42\n",
      "   --------------- ------------------------ 48.5/124.9 MB 1.8 MB/s eta 0:00:42\n",
      "   --------------- ------------------------ 48.5/124.9 MB 1.8 MB/s eta 0:00:43\n",
      "   --------------- ------------------------ 48.6/124.9 MB 1.8 MB/s eta 0:00:43\n",
      "   --------------- ------------------------ 48.7/124.9 MB 1.8 MB/s eta 0:00:43\n",
      "   --------------- ------------------------ 48.8/124.9 MB 1.8 MB/s eta 0:00:43\n",
      "   --------------- ------------------------ 48.8/124.9 MB 1.8 MB/s eta 0:00:43\n",
      "   --------------- ------------------------ 48.9/124.9 MB 1.8 MB/s eta 0:00:43\n",
      "   --------------- ------------------------ 48.9/124.9 MB 1.8 MB/s eta 0:00:43\n",
      "   --------------- ------------------------ 49.0/124.9 MB 1.8 MB/s eta 0:00:43\n",
      "   --------------- ------------------------ 49.1/124.9 MB 1.8 MB/s eta 0:00:43\n",
      "   --------------- ------------------------ 49.2/124.9 MB 1.8 MB/s eta 0:00:43\n",
      "   --------------- ------------------------ 49.2/124.9 MB 1.8 MB/s eta 0:00:43\n",
      "   --------------- ------------------------ 49.3/124.9 MB 1.8 MB/s eta 0:00:43\n",
      "   --------------- ------------------------ 49.4/124.9 MB 1.8 MB/s eta 0:00:43\n",
      "   --------------- ------------------------ 49.4/124.9 MB 1.8 MB/s eta 0:00:43\n",
      "   --------------- ------------------------ 49.5/124.9 MB 1.8 MB/s eta 0:00:43\n",
      "   --------------- ------------------------ 49.6/124.9 MB 1.8 MB/s eta 0:00:43\n",
      "   --------------- ------------------------ 49.6/124.9 MB 1.8 MB/s eta 0:00:43\n",
      "   --------------- ------------------------ 49.6/124.9 MB 1.8 MB/s eta 0:00:44\n",
      "   --------------- ------------------------ 49.7/124.9 MB 1.7 MB/s eta 0:00:44\n",
      "   --------------- ------------------------ 49.7/124.9 MB 1.7 MB/s eta 0:00:44\n",
      "   --------------- ------------------------ 49.7/124.9 MB 1.7 MB/s eta 0:00:44\n",
      "   --------------- ------------------------ 49.7/124.9 MB 1.7 MB/s eta 0:00:44\n",
      "   --------------- ------------------------ 49.8/124.9 MB 1.7 MB/s eta 0:00:44\n",
      "   --------------- ------------------------ 49.8/124.9 MB 1.7 MB/s eta 0:00:45\n",
      "   --------------- ------------------------ 49.8/124.9 MB 1.7 MB/s eta 0:00:45\n",
      "   --------------- ------------------------ 49.9/124.9 MB 1.7 MB/s eta 0:00:45\n",
      "   --------------- ------------------------ 49.9/124.9 MB 1.7 MB/s eta 0:00:45\n",
      "   --------------- ------------------------ 49.9/124.9 MB 1.7 MB/s eta 0:00:46\n",
      "   --------------- ------------------------ 49.9/124.9 MB 1.7 MB/s eta 0:00:46\n",
      "   ---------------- ----------------------- 50.0/124.9 MB 1.6 MB/s eta 0:00:46\n",
      "   ---------------- ----------------------- 50.0/124.9 MB 1.6 MB/s eta 0:00:46\n",
      "   ---------------- ----------------------- 50.0/124.9 MB 1.6 MB/s eta 0:00:46\n",
      "   ---------------- ----------------------- 50.1/124.9 MB 1.6 MB/s eta 0:00:47\n",
      "   ---------------- ----------------------- 50.1/124.9 MB 1.6 MB/s eta 0:00:47\n",
      "   ---------------- ----------------------- 50.1/124.9 MB 1.6 MB/s eta 0:00:47\n",
      "   ---------------- ----------------------- 50.2/124.9 MB 1.6 MB/s eta 0:00:47\n",
      "   ---------------- ----------------------- 50.2/124.9 MB 1.6 MB/s eta 0:00:47\n",
      "   ---------------- ----------------------- 50.3/124.9 MB 1.6 MB/s eta 0:00:48\n",
      "   ---------------- ----------------------- 50.3/124.9 MB 1.6 MB/s eta 0:00:48\n",
      "   ---------------- ----------------------- 50.3/124.9 MB 1.6 MB/s eta 0:00:48\n",
      "   ---------------- ----------------------- 50.4/124.9 MB 1.6 MB/s eta 0:00:48\n",
      "   ---------------- ----------------------- 50.4/124.9 MB 1.6 MB/s eta 0:00:48\n",
      "   ---------------- ----------------------- 50.5/124.9 MB 1.6 MB/s eta 0:00:48\n",
      "   ---------------- ----------------------- 50.5/124.9 MB 1.6 MB/s eta 0:00:48\n",
      "   ---------------- ----------------------- 50.5/124.9 MB 1.5 MB/s eta 0:00:49\n",
      "   ---------------- ----------------------- 50.6/124.9 MB 1.5 MB/s eta 0:00:49\n",
      "   ---------------- ----------------------- 50.6/124.9 MB 1.5 MB/s eta 0:00:49\n",
      "   ---------------- ----------------------- 50.7/124.9 MB 1.5 MB/s eta 0:00:49\n",
      "   ---------------- ----------------------- 50.7/124.9 MB 1.5 MB/s eta 0:00:49\n",
      "   ---------------- ----------------------- 50.8/124.9 MB 1.5 MB/s eta 0:00:49\n",
      "   ---------------- ----------------------- 50.8/124.9 MB 1.5 MB/s eta 0:00:50\n",
      "   ---------------- ----------------------- 50.9/124.9 MB 1.5 MB/s eta 0:00:50\n",
      "   ---------------- ----------------------- 50.9/124.9 MB 1.5 MB/s eta 0:00:50\n",
      "   ---------------- ----------------------- 50.9/124.9 MB 1.5 MB/s eta 0:00:50\n",
      "   ---------------- ----------------------- 51.0/124.9 MB 1.5 MB/s eta 0:00:50\n",
      "   ---------------- ----------------------- 51.0/124.9 MB 1.5 MB/s eta 0:00:50\n",
      "   ---------------- ----------------------- 51.1/124.9 MB 1.5 MB/s eta 0:00:50\n",
      "   ---------------- ----------------------- 51.1/124.9 MB 1.5 MB/s eta 0:00:50\n",
      "   ---------------- ----------------------- 51.1/124.9 MB 1.5 MB/s eta 0:00:51\n",
      "   ---------------- ----------------------- 51.2/124.9 MB 1.5 MB/s eta 0:00:51\n",
      "   ---------------- ----------------------- 51.2/124.9 MB 1.5 MB/s eta 0:00:51\n",
      "   ---------------- ----------------------- 51.3/124.9 MB 1.5 MB/s eta 0:00:51\n",
      "   ---------------- ----------------------- 51.3/124.9 MB 1.5 MB/s eta 0:00:51\n",
      "   ---------------- ----------------------- 51.3/124.9 MB 1.4 MB/s eta 0:00:51\n",
      "   ---------------- ----------------------- 51.4/124.9 MB 1.4 MB/s eta 0:00:51\n",
      "   ---------------- ----------------------- 51.4/124.9 MB 1.4 MB/s eta 0:00:52\n",
      "   ---------------- ----------------------- 51.5/124.9 MB 1.4 MB/s eta 0:00:52\n",
      "   ---------------- ----------------------- 51.5/124.9 MB 1.4 MB/s eta 0:00:52\n",
      "   ---------------- ----------------------- 51.5/124.9 MB 1.4 MB/s eta 0:00:52\n",
      "   ---------------- ----------------------- 51.6/124.9 MB 1.4 MB/s eta 0:00:52\n",
      "   ---------------- ----------------------- 51.6/124.9 MB 1.4 MB/s eta 0:00:52\n",
      "   ---------------- ----------------------- 51.7/124.9 MB 1.4 MB/s eta 0:00:52\n",
      "   ---------------- ----------------------- 51.7/124.9 MB 1.4 MB/s eta 0:00:52\n",
      "   ---------------- ----------------------- 51.8/124.9 MB 1.4 MB/s eta 0:00:53\n",
      "   ---------------- ----------------------- 51.8/124.9 MB 1.4 MB/s eta 0:00:53\n",
      "   ---------------- ----------------------- 51.9/124.9 MB 1.4 MB/s eta 0:00:53\n",
      "   ---------------- ----------------------- 51.9/124.9 MB 1.4 MB/s eta 0:00:53\n",
      "   ---------------- ----------------------- 52.0/124.9 MB 1.4 MB/s eta 0:00:53\n",
      "   ---------------- ----------------------- 52.0/124.9 MB 1.4 MB/s eta 0:00:53\n",
      "   ---------------- ----------------------- 52.1/124.9 MB 1.4 MB/s eta 0:00:53\n",
      "   ---------------- ----------------------- 52.1/124.9 MB 1.4 MB/s eta 0:00:53\n",
      "   ---------------- ----------------------- 52.2/124.9 MB 1.4 MB/s eta 0:00:53\n",
      "   ---------------- ----------------------- 52.2/124.9 MB 1.4 MB/s eta 0:00:53\n",
      "   ---------------- ----------------------- 52.3/124.9 MB 1.4 MB/s eta 0:00:53\n",
      "   ---------------- ----------------------- 52.3/124.9 MB 1.4 MB/s eta 0:00:53\n",
      "   ---------------- ----------------------- 52.4/124.9 MB 1.4 MB/s eta 0:00:53\n",
      "   ---------------- ----------------------- 52.4/124.9 MB 1.4 MB/s eta 0:00:54\n",
      "   ---------------- ----------------------- 52.5/124.9 MB 1.4 MB/s eta 0:00:54\n",
      "   ---------------- ----------------------- 52.6/124.9 MB 1.4 MB/s eta 0:00:54\n",
      "   ---------------- ----------------------- 52.6/124.9 MB 1.4 MB/s eta 0:00:54\n",
      "   ---------------- ----------------------- 52.7/124.9 MB 1.4 MB/s eta 0:00:54\n",
      "   ---------------- ----------------------- 52.7/124.9 MB 1.4 MB/s eta 0:00:54\n",
      "   ---------------- ----------------------- 52.8/124.9 MB 1.3 MB/s eta 0:00:54\n",
      "   ---------------- ----------------------- 52.9/124.9 MB 1.3 MB/s eta 0:00:54\n",
      "   ---------------- ----------------------- 52.9/124.9 MB 1.3 MB/s eta 0:00:54\n",
      "   ---------------- ----------------------- 53.0/124.9 MB 1.3 MB/s eta 0:00:54\n",
      "   ---------------- ----------------------- 53.1/124.9 MB 1.3 MB/s eta 0:00:54\n",
      "   ----------------- ---------------------- 53.1/124.9 MB 1.3 MB/s eta 0:00:54\n",
      "   ----------------- ---------------------- 53.2/124.9 MB 1.3 MB/s eta 0:00:54\n",
      "   ----------------- ---------------------- 53.3/124.9 MB 1.3 MB/s eta 0:00:54\n",
      "   ----------------- ---------------------- 53.3/124.9 MB 1.3 MB/s eta 0:00:54\n",
      "   ----------------- ---------------------- 53.4/124.9 MB 1.3 MB/s eta 0:00:54\n",
      "   ----------------- ---------------------- 53.5/124.9 MB 1.3 MB/s eta 0:00:55\n",
      "   ----------------- ---------------------- 53.5/124.9 MB 1.3 MB/s eta 0:00:54\n",
      "   ----------------- ---------------------- 53.6/124.9 MB 1.3 MB/s eta 0:00:55\n",
      "   ----------------- ---------------------- 53.7/124.9 MB 1.3 MB/s eta 0:00:54\n",
      "   ----------------- ---------------------- 53.8/124.9 MB 1.3 MB/s eta 0:00:54\n",
      "   ----------------- ---------------------- 53.8/124.9 MB 1.3 MB/s eta 0:00:54\n",
      "   ----------------- ---------------------- 53.9/124.9 MB 1.3 MB/s eta 0:00:55\n",
      "   ----------------- ---------------------- 54.0/124.9 MB 1.3 MB/s eta 0:00:54\n",
      "   ----------------- ---------------------- 54.1/124.9 MB 1.3 MB/s eta 0:00:55\n",
      "   ----------------- ---------------------- 54.1/124.9 MB 1.3 MB/s eta 0:00:55\n",
      "   ----------------- ---------------------- 54.2/124.9 MB 1.3 MB/s eta 0:00:55\n",
      "   ----------------- ---------------------- 54.3/124.9 MB 1.3 MB/s eta 0:00:55\n",
      "   ----------------- ---------------------- 54.4/124.9 MB 1.3 MB/s eta 0:00:55\n",
      "   ----------------- ---------------------- 54.4/124.9 MB 1.3 MB/s eta 0:00:55\n",
      "   ----------------- ---------------------- 54.5/124.9 MB 1.3 MB/s eta 0:00:55\n",
      "   ----------------- ---------------------- 54.6/124.9 MB 1.3 MB/s eta 0:00:55\n",
      "   ----------------- ---------------------- 54.7/124.9 MB 1.3 MB/s eta 0:00:55\n",
      "   ----------------- ---------------------- 54.8/124.9 MB 1.3 MB/s eta 0:00:55\n",
      "   ----------------- ---------------------- 54.9/124.9 MB 1.3 MB/s eta 0:00:55\n",
      "   ----------------- ---------------------- 55.0/124.9 MB 1.3 MB/s eta 0:00:54\n",
      "   ----------------- ---------------------- 55.0/124.9 MB 1.3 MB/s eta 0:00:55\n",
      "   ----------------- ---------------------- 55.1/124.9 MB 1.3 MB/s eta 0:00:54\n",
      "   ----------------- ---------------------- 55.1/124.9 MB 1.3 MB/s eta 0:00:54\n",
      "   ----------------- ---------------------- 55.3/124.9 MB 1.3 MB/s eta 0:00:54\n",
      "   ----------------- ---------------------- 55.3/124.9 MB 1.3 MB/s eta 0:00:54\n",
      "   ----------------- ---------------------- 55.4/124.9 MB 1.3 MB/s eta 0:00:54\n",
      "   ----------------- ---------------------- 55.4/124.9 MB 1.3 MB/s eta 0:00:54\n",
      "   ----------------- ---------------------- 55.5/124.9 MB 1.3 MB/s eta 0:00:55\n",
      "   ----------------- ---------------------- 55.6/124.9 MB 1.3 MB/s eta 0:00:55\n",
      "   ----------------- ---------------------- 55.6/124.9 MB 1.3 MB/s eta 0:00:54\n",
      "   ----------------- ---------------------- 55.7/124.9 MB 1.3 MB/s eta 0:00:55\n",
      "   ----------------- ---------------------- 55.8/124.9 MB 1.3 MB/s eta 0:00:54\n",
      "   ----------------- ---------------------- 55.9/124.9 MB 1.3 MB/s eta 0:00:54\n",
      "   ----------------- ---------------------- 55.9/124.9 MB 1.3 MB/s eta 0:00:54\n",
      "   ----------------- ---------------------- 56.0/124.9 MB 1.3 MB/s eta 0:00:55\n",
      "   ----------------- ---------------------- 56.1/124.9 MB 1.3 MB/s eta 0:00:54\n",
      "   ----------------- ---------------------- 56.2/124.9 MB 1.3 MB/s eta 0:00:54\n",
      "   ------------------ --------------------- 56.2/124.9 MB 1.3 MB/s eta 0:00:54\n",
      "   ------------------ --------------------- 56.3/124.9 MB 1.3 MB/s eta 0:00:54\n",
      "   ------------------ --------------------- 56.4/124.9 MB 1.3 MB/s eta 0:00:54\n",
      "   ------------------ --------------------- 56.4/124.9 MB 1.3 MB/s eta 0:00:54\n",
      "   ------------------ --------------------- 56.5/124.9 MB 1.3 MB/s eta 0:00:54\n",
      "   ------------------ --------------------- 56.6/124.9 MB 1.3 MB/s eta 0:00:54\n",
      "   ------------------ --------------------- 56.7/124.9 MB 1.3 MB/s eta 0:00:54\n",
      "   ------------------ --------------------- 56.8/124.9 MB 1.3 MB/s eta 0:00:54\n",
      "   ------------------ --------------------- 56.8/124.9 MB 1.3 MB/s eta 0:00:54\n",
      "   ------------------ --------------------- 56.9/124.9 MB 1.3 MB/s eta 0:00:53\n",
      "   ------------------ --------------------- 57.0/124.9 MB 1.3 MB/s eta 0:00:53\n",
      "   ------------------ --------------------- 57.1/124.9 MB 1.3 MB/s eta 0:00:53\n",
      "   ------------------ --------------------- 57.1/124.9 MB 1.3 MB/s eta 0:00:53\n",
      "   ------------------ --------------------- 57.2/124.9 MB 1.3 MB/s eta 0:00:53\n",
      "   ------------------ --------------------- 57.3/124.9 MB 1.3 MB/s eta 0:00:53\n",
      "   ------------------ --------------------- 57.4/124.9 MB 1.3 MB/s eta 0:00:53\n",
      "   ------------------ --------------------- 57.5/124.9 MB 1.3 MB/s eta 0:00:53\n",
      "   ------------------ --------------------- 57.5/124.9 MB 1.3 MB/s eta 0:00:53\n",
      "   ------------------ --------------------- 57.6/124.9 MB 1.3 MB/s eta 0:00:53\n",
      "   ------------------ --------------------- 57.7/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------ --------------------- 57.8/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------ --------------------- 57.8/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------ --------------------- 58.0/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------ --------------------- 58.0/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------ --------------------- 58.1/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------ --------------------- 58.1/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------ --------------------- 58.2/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------ --------------------- 58.3/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------ --------------------- 58.3/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------ --------------------- 58.4/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------ --------------------- 58.5/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------ --------------------- 58.5/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------ --------------------- 58.6/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------ --------------------- 58.7/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------ --------------------- 58.7/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------ --------------------- 58.8/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------ --------------------- 58.9/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------ --------------------- 58.9/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------ --------------------- 58.9/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------ --------------------- 59.1/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------ --------------------- 59.1/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------ --------------------- 59.2/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------ --------------------- 59.2/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------ --------------------- 59.3/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------ --------------------- 59.3/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------- -------------------- 59.4/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------- -------------------- 59.4/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------- -------------------- 59.5/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------- -------------------- 59.5/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------- -------------------- 59.6/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------- -------------------- 59.6/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------- -------------------- 59.7/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------- -------------------- 59.8/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------- -------------------- 59.8/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------- -------------------- 59.8/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------- -------------------- 59.9/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------- -------------------- 59.9/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------- -------------------- 60.0/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------- -------------------- 60.0/124.9 MB 1.3 MB/s eta 0:00:52\n",
      "   ------------------- -------------------- 60.0/124.9 MB 1.3 MB/s eta 0:00:51\n",
      "   ------------------- -------------------- 60.1/124.9 MB 1.3 MB/s eta 0:00:51\n",
      "   ------------------- -------------------- 60.1/124.9 MB 1.3 MB/s eta 0:00:51\n",
      "   ------------------- -------------------- 60.2/124.9 MB 1.3 MB/s eta 0:00:51\n",
      "   ------------------- -------------------- 60.2/124.9 MB 1.3 MB/s eta 0:00:50\n",
      "   ------------------- -------------------- 60.3/124.9 MB 1.3 MB/s eta 0:00:50\n",
      "   ------------------- -------------------- 60.3/124.9 MB 1.3 MB/s eta 0:00:50\n",
      "   ------------------- -------------------- 60.4/124.9 MB 1.3 MB/s eta 0:00:50\n",
      "   ------------------- -------------------- 60.4/124.9 MB 1.3 MB/s eta 0:00:50\n",
      "   ------------------- -------------------- 60.5/124.9 MB 1.3 MB/s eta 0:00:50\n",
      "   ------------------- -------------------- 60.5/124.9 MB 1.3 MB/s eta 0:00:49\n",
      "   ------------------- -------------------- 60.6/124.9 MB 1.3 MB/s eta 0:00:49\n",
      "   ------------------- -------------------- 60.7/124.9 MB 1.3 MB/s eta 0:00:49\n",
      "   ------------------- -------------------- 60.7/124.9 MB 1.3 MB/s eta 0:00:49\n",
      "   ------------------- -------------------- 60.8/124.9 MB 1.3 MB/s eta 0:00:49\n",
      "   ------------------- -------------------- 60.8/124.9 MB 1.3 MB/s eta 0:00:49\n",
      "   ------------------- -------------------- 60.9/124.9 MB 1.3 MB/s eta 0:00:49\n",
      "   ------------------- -------------------- 60.9/124.9 MB 1.3 MB/s eta 0:00:48\n",
      "   ------------------- -------------------- 61.0/124.9 MB 1.3 MB/s eta 0:00:48\n",
      "   ------------------- -------------------- 61.1/124.9 MB 1.3 MB/s eta 0:00:48\n",
      "   ------------------- -------------------- 61.1/124.9 MB 1.3 MB/s eta 0:00:48\n",
      "   ------------------- -------------------- 61.2/124.9 MB 1.3 MB/s eta 0:00:48\n",
      "   ------------------- -------------------- 61.2/124.9 MB 1.3 MB/s eta 0:00:48\n",
      "   ------------------- -------------------- 61.3/124.9 MB 1.4 MB/s eta 0:00:47\n",
      "   ------------------- -------------------- 61.3/124.9 MB 1.4 MB/s eta 0:00:47\n",
      "   ------------------- -------------------- 61.4/124.9 MB 1.4 MB/s eta 0:00:47\n",
      "   ------------------- -------------------- 61.5/124.9 MB 1.4 MB/s eta 0:00:47\n",
      "   ------------------- -------------------- 61.6/124.9 MB 1.4 MB/s eta 0:00:46\n",
      "   ------------------- -------------------- 61.6/124.9 MB 1.4 MB/s eta 0:00:46\n",
      "   ------------------- -------------------- 61.7/124.9 MB 1.4 MB/s eta 0:00:46\n",
      "   ------------------- -------------------- 61.8/124.9 MB 1.4 MB/s eta 0:00:46\n",
      "   ------------------- -------------------- 61.8/124.9 MB 1.4 MB/s eta 0:00:46\n",
      "   ------------------- -------------------- 61.9/124.9 MB 1.4 MB/s eta 0:00:45\n",
      "   ------------------- -------------------- 62.0/124.9 MB 1.4 MB/s eta 0:00:45\n",
      "   ------------------- -------------------- 62.0/124.9 MB 1.4 MB/s eta 0:00:45\n",
      "   ------------------- -------------------- 62.0/124.9 MB 1.4 MB/s eta 0:00:45\n",
      "   ------------------- -------------------- 62.2/124.9 MB 1.4 MB/s eta 0:00:45\n",
      "   ------------------- -------------------- 62.2/124.9 MB 1.4 MB/s eta 0:00:45\n",
      "   ------------------- -------------------- 62.3/124.9 MB 1.4 MB/s eta 0:00:45\n",
      "   ------------------- -------------------- 62.3/124.9 MB 1.4 MB/s eta 0:00:45\n",
      "   ------------------- -------------------- 62.4/124.9 MB 1.4 MB/s eta 0:00:45\n",
      "   ------------------- -------------------- 62.4/124.9 MB 1.4 MB/s eta 0:00:44\n",
      "   -------------------- ------------------- 62.5/124.9 MB 1.4 MB/s eta 0:00:44\n",
      "   -------------------- ------------------- 62.5/124.9 MB 1.4 MB/s eta 0:00:44\n",
      "   -------------------- ------------------- 62.6/124.9 MB 1.4 MB/s eta 0:00:44\n",
      "   -------------------- ------------------- 62.7/124.9 MB 1.4 MB/s eta 0:00:44\n",
      "   -------------------- ------------------- 62.7/124.9 MB 1.4 MB/s eta 0:00:44\n",
      "   -------------------- ------------------- 62.8/124.9 MB 1.4 MB/s eta 0:00:44\n",
      "   -------------------- ------------------- 62.8/124.9 MB 1.4 MB/s eta 0:00:44\n",
      "   -------------------- ------------------- 62.9/124.9 MB 1.4 MB/s eta 0:00:44\n",
      "   -------------------- ------------------- 63.0/124.9 MB 1.4 MB/s eta 0:00:44\n",
      "   -------------------- ------------------- 63.0/124.9 MB 1.4 MB/s eta 0:00:44\n",
      "   -------------------- ------------------- 63.1/124.9 MB 1.4 MB/s eta 0:00:44\n",
      "   -------------------- ------------------- 63.2/124.9 MB 1.4 MB/s eta 0:00:44\n",
      "   -------------------- ------------------- 63.2/124.9 MB 1.4 MB/s eta 0:00:44\n",
      "   -------------------- ------------------- 63.3/124.9 MB 1.4 MB/s eta 0:00:44\n",
      "   -------------------- ------------------- 63.3/124.9 MB 1.4 MB/s eta 0:00:44\n",
      "   -------------------- ------------------- 63.4/124.9 MB 1.4 MB/s eta 0:00:44\n",
      "   -------------------- ------------------- 63.5/124.9 MB 1.4 MB/s eta 0:00:44\n",
      "   -------------------- ------------------- 63.5/124.9 MB 1.4 MB/s eta 0:00:44\n",
      "   -------------------- ------------------- 63.6/124.9 MB 1.4 MB/s eta 0:00:44\n",
      "   -------------------- ------------------- 63.7/124.9 MB 1.4 MB/s eta 0:00:44\n",
      "   -------------------- ------------------- 63.7/124.9 MB 1.4 MB/s eta 0:00:43\n",
      "   -------------------- ------------------- 63.8/124.9 MB 1.4 MB/s eta 0:00:44\n",
      "   -------------------- ------------------- 63.9/124.9 MB 1.4 MB/s eta 0:00:43\n",
      "   -------------------- ------------------- 63.9/124.9 MB 1.4 MB/s eta 0:00:43\n",
      "   -------------------- ------------------- 64.0/124.9 MB 1.4 MB/s eta 0:00:43\n",
      "   -------------------- ------------------- 64.1/124.9 MB 1.4 MB/s eta 0:00:43\n",
      "   -------------------- ------------------- 64.2/124.9 MB 1.4 MB/s eta 0:00:43\n",
      "   -------------------- ------------------- 64.2/124.9 MB 1.4 MB/s eta 0:00:43\n",
      "   -------------------- ------------------- 64.3/124.9 MB 1.4 MB/s eta 0:00:43\n",
      "   -------------------- ------------------- 64.4/124.9 MB 1.4 MB/s eta 0:00:43\n",
      "   -------------------- ------------------- 64.5/124.9 MB 1.4 MB/s eta 0:00:43\n",
      "   -------------------- ------------------- 64.6/124.9 MB 1.4 MB/s eta 0:00:43\n",
      "   -------------------- ------------------- 64.6/124.9 MB 1.4 MB/s eta 0:00:43\n",
      "   -------------------- ------------------- 64.7/124.9 MB 1.4 MB/s eta 0:00:43\n",
      "   -------------------- ------------------- 64.8/124.9 MB 1.4 MB/s eta 0:00:43\n",
      "   -------------------- ------------------- 64.9/124.9 MB 1.4 MB/s eta 0:00:43\n",
      "   -------------------- ------------------- 65.0/124.9 MB 1.4 MB/s eta 0:00:43\n",
      "   -------------------- ------------------- 65.0/124.9 MB 1.4 MB/s eta 0:00:43\n",
      "   -------------------- ------------------- 65.1/124.9 MB 1.4 MB/s eta 0:00:43\n",
      "   -------------------- ------------------- 65.2/124.9 MB 1.4 MB/s eta 0:00:43\n",
      "   -------------------- ------------------- 65.3/124.9 MB 1.4 MB/s eta 0:00:43\n",
      "   -------------------- ------------------- 65.4/124.9 MB 1.4 MB/s eta 0:00:42\n",
      "   -------------------- ------------------- 65.5/124.9 MB 1.4 MB/s eta 0:00:42\n",
      "   -------------------- ------------------- 65.6/124.9 MB 1.4 MB/s eta 0:00:42\n",
      "   --------------------- ------------------ 65.6/124.9 MB 1.4 MB/s eta 0:00:42\n",
      "   --------------------- ------------------ 65.7/124.9 MB 1.4 MB/s eta 0:00:42\n",
      "   --------------------- ------------------ 65.8/124.9 MB 1.4 MB/s eta 0:00:42\n",
      "   --------------------- ------------------ 65.9/124.9 MB 1.4 MB/s eta 0:00:41\n",
      "   --------------------- ------------------ 66.0/124.9 MB 1.4 MB/s eta 0:00:41\n",
      "   --------------------- ------------------ 66.1/124.9 MB 1.4 MB/s eta 0:00:41\n",
      "   --------------------- ------------------ 66.2/124.9 MB 1.4 MB/s eta 0:00:41\n",
      "   --------------------- ------------------ 66.3/124.9 MB 1.4 MB/s eta 0:00:41\n",
      "   --------------------- ------------------ 66.4/124.9 MB 1.5 MB/s eta 0:00:41\n",
      "   --------------------- ------------------ 66.5/124.9 MB 1.5 MB/s eta 0:00:41\n",
      "   --------------------- ------------------ 66.6/124.9 MB 1.5 MB/s eta 0:00:40\n",
      "   --------------------- ------------------ 66.7/124.9 MB 1.5 MB/s eta 0:00:40\n",
      "   --------------------- ------------------ 66.8/124.9 MB 1.5 MB/s eta 0:00:40\n",
      "   --------------------- ------------------ 66.8/124.9 MB 1.5 MB/s eta 0:00:40\n",
      "   --------------------- ------------------ 66.9/124.9 MB 1.5 MB/s eta 0:00:40\n",
      "   --------------------- ------------------ 67.1/124.9 MB 1.5 MB/s eta 0:00:40\n",
      "   --------------------- ------------------ 67.1/124.9 MB 1.5 MB/s eta 0:00:40\n",
      "   --------------------- ------------------ 67.2/124.9 MB 1.5 MB/s eta 0:00:40\n",
      "   --------------------- ------------------ 67.3/124.9 MB 1.5 MB/s eta 0:00:40\n",
      "   --------------------- ------------------ 67.4/124.9 MB 1.5 MB/s eta 0:00:40\n",
      "   --------------------- ------------------ 67.5/124.9 MB 1.5 MB/s eta 0:00:39\n",
      "   --------------------- ------------------ 67.5/124.9 MB 1.5 MB/s eta 0:00:39\n",
      "   --------------------- ------------------ 67.6/124.9 MB 1.5 MB/s eta 0:00:39\n",
      "   --------------------- ------------------ 67.7/124.9 MB 1.5 MB/s eta 0:00:39\n",
      "   --------------------- ------------------ 67.8/124.9 MB 1.5 MB/s eta 0:00:39\n",
      "   --------------------- ------------------ 67.9/124.9 MB 1.5 MB/s eta 0:00:39\n",
      "   --------------------- ------------------ 67.9/124.9 MB 1.5 MB/s eta 0:00:39\n",
      "   --------------------- ------------------ 68.0/124.9 MB 1.5 MB/s eta 0:00:39\n",
      "   --------------------- ------------------ 68.1/124.9 MB 1.5 MB/s eta 0:00:39\n",
      "   --------------------- ------------------ 68.2/124.9 MB 1.5 MB/s eta 0:00:39\n",
      "   --------------------- ------------------ 68.3/124.9 MB 1.5 MB/s eta 0:00:39\n",
      "   --------------------- ------------------ 68.3/124.9 MB 1.5 MB/s eta 0:00:39\n",
      "   --------------------- ------------------ 68.4/124.9 MB 1.5 MB/s eta 0:00:39\n",
      "   --------------------- ------------------ 68.5/124.9 MB 1.5 MB/s eta 0:00:39\n",
      "   --------------------- ------------------ 68.6/124.9 MB 1.5 MB/s eta 0:00:38\n",
      "   --------------------- ------------------ 68.7/124.9 MB 1.5 MB/s eta 0:00:38\n",
      "   ---------------------- ----------------- 68.8/124.9 MB 1.5 MB/s eta 0:00:38\n",
      "   ---------------------- ----------------- 68.8/124.9 MB 1.5 MB/s eta 0:00:38\n",
      "   ---------------------- ----------------- 68.9/124.9 MB 1.5 MB/s eta 0:00:38\n",
      "   ---------------------- ----------------- 69.0/124.9 MB 1.5 MB/s eta 0:00:38\n",
      "   ---------------------- ----------------- 69.1/124.9 MB 1.5 MB/s eta 0:00:38\n",
      "   ---------------------- ----------------- 69.2/124.9 MB 1.5 MB/s eta 0:00:37\n",
      "   ---------------------- ----------------- 69.3/124.9 MB 1.5 MB/s eta 0:00:37\n",
      "   ---------------------- ----------------- 69.4/124.9 MB 1.5 MB/s eta 0:00:37\n",
      "   ---------------------- ----------------- 69.5/124.9 MB 1.5 MB/s eta 0:00:37\n",
      "   ---------------------- ----------------- 69.6/124.9 MB 1.5 MB/s eta 0:00:37\n",
      "   ---------------------- ----------------- 69.7/124.9 MB 1.5 MB/s eta 0:00:36\n",
      "   ---------------------- ----------------- 69.7/124.9 MB 1.6 MB/s eta 0:00:36\n",
      "   ---------------------- ----------------- 69.8/124.9 MB 1.6 MB/s eta 0:00:36\n",
      "   ---------------------- ----------------- 69.9/124.9 MB 1.6 MB/s eta 0:00:35\n",
      "   ---------------------- ----------------- 70.0/124.9 MB 1.6 MB/s eta 0:00:35\n",
      "   ---------------------- ----------------- 70.1/124.9 MB 1.6 MB/s eta 0:00:35\n",
      "   ---------------------- ----------------- 70.2/124.9 MB 1.6 MB/s eta 0:00:34\n",
      "   ---------------------- ----------------- 70.3/124.9 MB 1.6 MB/s eta 0:00:34\n",
      "   ---------------------- ----------------- 70.4/124.9 MB 1.6 MB/s eta 0:00:34\n",
      "   ---------------------- ----------------- 70.5/124.9 MB 1.6 MB/s eta 0:00:33\n",
      "   ---------------------- ----------------- 70.6/124.9 MB 1.7 MB/s eta 0:00:33\n",
      "   ---------------------- ----------------- 70.7/124.9 MB 1.7 MB/s eta 0:00:33\n",
      "   ---------------------- ----------------- 70.8/124.9 MB 1.7 MB/s eta 0:00:33\n",
      "   ---------------------- ----------------- 70.9/124.9 MB 1.7 MB/s eta 0:00:32\n",
      "   ---------------------- ----------------- 71.0/124.9 MB 1.7 MB/s eta 0:00:32\n",
      "   ---------------------- ----------------- 71.1/124.9 MB 1.7 MB/s eta 0:00:32\n",
      "   ---------------------- ----------------- 71.2/124.9 MB 1.7 MB/s eta 0:00:32\n",
      "   ---------------------- ----------------- 71.3/124.9 MB 1.7 MB/s eta 0:00:32\n",
      "   ---------------------- ----------------- 71.3/124.9 MB 1.7 MB/s eta 0:00:32\n",
      "   ---------------------- ----------------- 71.4/124.9 MB 1.7 MB/s eta 0:00:32\n",
      "   ---------------------- ----------------- 71.5/124.9 MB 1.7 MB/s eta 0:00:32\n",
      "   ---------------------- ----------------- 71.5/124.9 MB 1.7 MB/s eta 0:00:31\n",
      "   ---------------------- ----------------- 71.6/124.9 MB 1.7 MB/s eta 0:00:31\n",
      "   ---------------------- ----------------- 71.7/124.9 MB 1.7 MB/s eta 0:00:31\n",
      "   ---------------------- ----------------- 71.8/124.9 MB 1.7 MB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 71.9/124.9 MB 1.7 MB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 71.9/124.9 MB 1.7 MB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 72.0/124.9 MB 1.7 MB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 72.1/124.9 MB 1.7 MB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 72.1/124.9 MB 1.7 MB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 72.2/124.9 MB 1.7 MB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 72.3/124.9 MB 1.8 MB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 72.3/124.9 MB 1.7 MB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 72.4/124.9 MB 1.7 MB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 72.4/124.9 MB 1.7 MB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 72.5/124.9 MB 1.7 MB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 72.6/124.9 MB 1.7 MB/s eta 0:00:30\n",
      "   ----------------------- ---------------- 72.6/124.9 MB 1.7 MB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 72.7/124.9 MB 1.7 MB/s eta 0:00:30\n",
      "   ----------------------- ---------------- 72.8/124.9 MB 1.8 MB/s eta 0:00:30\n",
      "   ----------------------- ---------------- 72.8/124.9 MB 1.8 MB/s eta 0:00:30\n",
      "   ----------------------- ---------------- 72.9/124.9 MB 1.8 MB/s eta 0:00:30\n",
      "   ----------------------- ---------------- 73.0/124.9 MB 1.8 MB/s eta 0:00:30\n",
      "   ----------------------- ---------------- 73.0/124.9 MB 1.8 MB/s eta 0:00:30\n",
      "   ----------------------- ---------------- 73.1/124.9 MB 1.8 MB/s eta 0:00:30\n",
      "   ----------------------- ---------------- 73.2/124.9 MB 1.8 MB/s eta 0:00:30\n",
      "   ----------------------- ---------------- 73.2/124.9 MB 1.8 MB/s eta 0:00:30\n",
      "   ----------------------- ---------------- 73.3/124.9 MB 1.8 MB/s eta 0:00:30\n",
      "   ----------------------- ---------------- 73.4/124.9 MB 1.8 MB/s eta 0:00:30\n",
      "   ----------------------- ---------------- 73.5/124.9 MB 1.8 MB/s eta 0:00:30\n",
      "   ----------------------- ---------------- 73.6/124.9 MB 1.8 MB/s eta 0:00:29\n",
      "   ----------------------- ---------------- 73.6/124.9 MB 1.8 MB/s eta 0:00:29\n",
      "   ----------------------- ---------------- 73.7/124.9 MB 1.8 MB/s eta 0:00:29\n",
      "   ----------------------- ---------------- 73.8/124.9 MB 1.8 MB/s eta 0:00:29\n",
      "   ----------------------- ---------------- 73.9/124.9 MB 1.8 MB/s eta 0:00:29\n",
      "   ----------------------- ---------------- 73.9/124.9 MB 1.8 MB/s eta 0:00:29\n",
      "   ----------------------- ---------------- 74.0/124.9 MB 1.8 MB/s eta 0:00:29\n",
      "   ----------------------- ---------------- 74.1/124.9 MB 1.8 MB/s eta 0:00:29\n",
      "   ----------------------- ---------------- 74.2/124.9 MB 1.8 MB/s eta 0:00:29\n",
      "   ----------------------- ---------------- 74.3/124.9 MB 1.8 MB/s eta 0:00:29\n",
      "   ----------------------- ---------------- 74.3/124.9 MB 1.8 MB/s eta 0:00:29\n",
      "   ----------------------- ---------------- 74.4/124.9 MB 1.8 MB/s eta 0:00:29\n",
      "   ----------------------- ---------------- 74.5/124.9 MB 1.8 MB/s eta 0:00:29\n",
      "   ----------------------- ---------------- 74.6/124.9 MB 1.8 MB/s eta 0:00:29\n",
      "   ----------------------- ---------------- 74.7/124.9 MB 1.8 MB/s eta 0:00:29\n",
      "   ----------------------- ---------------- 74.8/124.9 MB 1.8 MB/s eta 0:00:28\n",
      "   ----------------------- ---------------- 74.8/124.9 MB 1.8 MB/s eta 0:00:28\n",
      "   ----------------------- ---------------- 74.9/124.9 MB 1.8 MB/s eta 0:00:28\n",
      "   ------------------------ --------------- 75.0/124.9 MB 1.8 MB/s eta 0:00:28\n",
      "   ------------------------ --------------- 75.1/124.9 MB 1.8 MB/s eta 0:00:28\n",
      "   ------------------------ --------------- 75.2/124.9 MB 1.8 MB/s eta 0:00:28\n",
      "   ------------------------ --------------- 75.3/124.9 MB 1.8 MB/s eta 0:00:28\n",
      "   ------------------------ --------------- 75.4/124.9 MB 1.8 MB/s eta 0:00:28\n",
      "   ------------------------ --------------- 75.5/124.9 MB 1.8 MB/s eta 0:00:28\n",
      "   ------------------------ --------------- 75.6/124.9 MB 1.8 MB/s eta 0:00:28\n",
      "   ------------------------ --------------- 75.7/124.9 MB 1.8 MB/s eta 0:00:28\n",
      "   ------------------------ --------------- 75.7/124.9 MB 1.8 MB/s eta 0:00:28\n",
      "   ------------------------ --------------- 75.8/124.9 MB 1.8 MB/s eta 0:00:27\n",
      "   ------------------------ --------------- 75.9/124.9 MB 1.8 MB/s eta 0:00:27\n",
      "   ------------------------ --------------- 76.0/124.9 MB 1.8 MB/s eta 0:00:27\n",
      "   ------------------------ --------------- 76.1/124.9 MB 1.8 MB/s eta 0:00:27\n",
      "   ------------------------ --------------- 76.2/124.9 MB 1.8 MB/s eta 0:00:27\n",
      "   ------------------------ --------------- 76.3/124.9 MB 1.8 MB/s eta 0:00:27\n",
      "   ------------------------ --------------- 76.4/124.9 MB 1.8 MB/s eta 0:00:27\n",
      "   ------------------------ --------------- 76.5/124.9 MB 1.8 MB/s eta 0:00:27\n",
      "   ------------------------ --------------- 76.6/124.9 MB 1.8 MB/s eta 0:00:27\n",
      "   ------------------------ --------------- 76.7/124.9 MB 1.8 MB/s eta 0:00:27\n",
      "   ------------------------ --------------- 76.8/124.9 MB 1.8 MB/s eta 0:00:27\n",
      "   ------------------------ --------------- 76.9/124.9 MB 1.8 MB/s eta 0:00:27\n",
      "   ------------------------ --------------- 77.0/124.9 MB 1.8 MB/s eta 0:00:27\n",
      "   ------------------------ --------------- 77.1/124.9 MB 1.8 MB/s eta 0:00:27\n",
      "   ------------------------ --------------- 77.3/124.9 MB 1.8 MB/s eta 0:00:27\n",
      "   ------------------------ --------------- 77.4/124.9 MB 1.8 MB/s eta 0:00:26\n",
      "   ------------------------ --------------- 77.5/124.9 MB 1.8 MB/s eta 0:00:26\n",
      "   ------------------------ --------------- 77.6/124.9 MB 1.8 MB/s eta 0:00:26\n",
      "   ------------------------ --------------- 77.7/124.9 MB 1.8 MB/s eta 0:00:26\n",
      "   ------------------------ --------------- 77.8/124.9 MB 1.9 MB/s eta 0:00:26\n",
      "   ------------------------ --------------- 77.9/124.9 MB 1.9 MB/s eta 0:00:26\n",
      "   ------------------------ --------------- 78.0/124.9 MB 1.9 MB/s eta 0:00:25\n",
      "   ------------------------- -------------- 78.1/124.9 MB 1.9 MB/s eta 0:00:25\n",
      "   ------------------------- -------------- 78.3/124.9 MB 1.9 MB/s eta 0:00:25\n",
      "   ------------------------- -------------- 78.4/124.9 MB 1.9 MB/s eta 0:00:25\n",
      "   ------------------------- -------------- 78.5/124.9 MB 1.9 MB/s eta 0:00:25\n",
      "   ------------------------- -------------- 78.6/124.9 MB 1.9 MB/s eta 0:00:25\n",
      "   ------------------------- -------------- 78.7/124.9 MB 1.9 MB/s eta 0:00:25\n",
      "   ------------------------- -------------- 78.8/124.9 MB 1.9 MB/s eta 0:00:25\n",
      "   ------------------------- -------------- 78.9/124.9 MB 1.9 MB/s eta 0:00:24\n",
      "   ------------------------- -------------- 79.1/124.9 MB 1.9 MB/s eta 0:00:24\n",
      "   ------------------------- -------------- 79.2/124.9 MB 1.9 MB/s eta 0:00:24\n",
      "   ------------------------- -------------- 79.3/124.9 MB 1.9 MB/s eta 0:00:24\n",
      "   ------------------------- -------------- 79.4/124.9 MB 1.9 MB/s eta 0:00:24\n",
      "   ------------------------- -------------- 79.5/124.9 MB 2.0 MB/s eta 0:00:24\n",
      "   ------------------------- -------------- 79.7/124.9 MB 2.0 MB/s eta 0:00:24\n",
      "   ------------------------- -------------- 79.8/124.9 MB 2.0 MB/s eta 0:00:24\n",
      "   ------------------------- -------------- 79.9/124.9 MB 2.0 MB/s eta 0:00:23\n",
      "   ------------------------- -------------- 80.0/124.9 MB 2.0 MB/s eta 0:00:23\n",
      "   ------------------------- -------------- 80.2/124.9 MB 2.0 MB/s eta 0:00:23\n",
      "   ------------------------- -------------- 80.3/124.9 MB 2.0 MB/s eta 0:00:23\n",
      "   ------------------------- -------------- 80.4/124.9 MB 2.0 MB/s eta 0:00:23\n",
      "   ------------------------- -------------- 80.5/124.9 MB 2.0 MB/s eta 0:00:23\n",
      "   ------------------------- -------------- 80.7/124.9 MB 2.0 MB/s eta 0:00:23\n",
      "   ------------------------- -------------- 80.8/124.9 MB 2.0 MB/s eta 0:00:22\n",
      "   ------------------------- -------------- 80.9/124.9 MB 2.0 MB/s eta 0:00:22\n",
      "   ------------------------- -------------- 81.1/124.9 MB 2.0 MB/s eta 0:00:22\n",
      "   ------------------------- -------------- 81.2/124.9 MB 2.0 MB/s eta 0:00:22\n",
      "   -------------------------- ------------- 81.3/124.9 MB 2.0 MB/s eta 0:00:22\n",
      "   -------------------------- ------------- 81.4/124.9 MB 2.0 MB/s eta 0:00:22\n",
      "   -------------------------- ------------- 81.6/124.9 MB 2.1 MB/s eta 0:00:21\n",
      "   -------------------------- ------------- 81.7/124.9 MB 2.1 MB/s eta 0:00:21\n",
      "   -------------------------- ------------- 81.8/124.9 MB 2.1 MB/s eta 0:00:21\n",
      "   -------------------------- ------------- 82.0/124.9 MB 2.1 MB/s eta 0:00:21\n",
      "   -------------------------- ------------- 82.1/124.9 MB 2.1 MB/s eta 0:00:21\n",
      "   -------------------------- ------------- 82.2/124.9 MB 2.1 MB/s eta 0:00:20\n",
      "   -------------------------- ------------- 82.2/124.9 MB 2.1 MB/s eta 0:00:20\n",
      "   -------------------------- ------------- 82.5/124.9 MB 2.2 MB/s eta 0:00:20\n",
      "   -------------------------- ------------- 82.6/124.9 MB 2.2 MB/s eta 0:00:20\n",
      "   -------------------------- ------------- 82.7/124.9 MB 2.2 MB/s eta 0:00:20\n",
      "   -------------------------- ------------- 82.8/124.9 MB 2.2 MB/s eta 0:00:20\n",
      "   -------------------------- ------------- 82.9/124.9 MB 2.2 MB/s eta 0:00:19\n",
      "   -------------------------- ------------- 83.0/124.9 MB 2.2 MB/s eta 0:00:19\n",
      "   -------------------------- ------------- 83.1/124.9 MB 2.2 MB/s eta 0:00:19\n",
      "   -------------------------- ------------- 83.2/124.9 MB 2.3 MB/s eta 0:00:19\n",
      "   -------------------------- ------------- 83.3/124.9 MB 2.3 MB/s eta 0:00:19\n",
      "   -------------------------- ------------- 83.4/124.9 MB 2.3 MB/s eta 0:00:19\n",
      "   -------------------------- ------------- 83.5/124.9 MB 2.3 MB/s eta 0:00:19\n",
      "   -------------------------- ------------- 83.6/124.9 MB 2.3 MB/s eta 0:00:18\n",
      "   -------------------------- ------------- 83.7/124.9 MB 2.3 MB/s eta 0:00:18\n",
      "   -------------------------- ------------- 83.8/124.9 MB 2.3 MB/s eta 0:00:18\n",
      "   -------------------------- ------------- 83.9/124.9 MB 2.3 MB/s eta 0:00:18\n",
      "   -------------------------- ------------- 84.0/124.9 MB 2.3 MB/s eta 0:00:18\n",
      "   -------------------------- ------------- 84.1/124.9 MB 2.4 MB/s eta 0:00:18\n",
      "   -------------------------- ------------- 84.3/124.9 MB 2.4 MB/s eta 0:00:18\n",
      "   --------------------------- ------------ 84.4/124.9 MB 2.4 MB/s eta 0:00:17\n",
      "   --------------------------- ------------ 84.5/124.9 MB 2.4 MB/s eta 0:00:17\n",
      "   --------------------------- ------------ 84.6/124.9 MB 2.4 MB/s eta 0:00:17\n",
      "   --------------------------- ------------ 84.7/124.9 MB 2.4 MB/s eta 0:00:17\n",
      "   --------------------------- ------------ 84.8/124.9 MB 2.4 MB/s eta 0:00:17\n",
      "   --------------------------- ------------ 85.0/124.9 MB 2.4 MB/s eta 0:00:17\n",
      "   --------------------------- ------------ 85.1/124.9 MB 2.5 MB/s eta 0:00:17\n",
      "   --------------------------- ------------ 85.2/124.9 MB 2.5 MB/s eta 0:00:17\n",
      "   --------------------------- ------------ 85.3/124.9 MB 2.5 MB/s eta 0:00:17\n",
      "   --------------------------- ------------ 85.5/124.9 MB 2.5 MB/s eta 0:00:16\n",
      "   --------------------------- ------------ 85.6/124.9 MB 2.5 MB/s eta 0:00:16\n",
      "   --------------------------- ------------ 85.7/124.9 MB 2.5 MB/s eta 0:00:16\n",
      "   --------------------------- ------------ 85.8/124.9 MB 2.5 MB/s eta 0:00:16\n",
      "   --------------------------- ------------ 86.0/124.9 MB 2.5 MB/s eta 0:00:16\n",
      "   --------------------------- ------------ 86.1/124.9 MB 2.5 MB/s eta 0:00:16\n",
      "   --------------------------- ------------ 86.2/124.9 MB 2.5 MB/s eta 0:00:16\n",
      "   --------------------------- ------------ 86.3/124.9 MB 2.5 MB/s eta 0:00:16\n",
      "   --------------------------- ------------ 86.5/124.9 MB 2.6 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 86.6/124.9 MB 2.6 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 86.7/124.9 MB 2.6 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 86.9/124.9 MB 2.6 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 87.0/124.9 MB 2.6 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 87.1/124.9 MB 2.6 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 87.3/124.9 MB 2.6 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 87.4/124.9 MB 2.6 MB/s eta 0:00:15\n",
      "   ---------------------------- ----------- 87.5/124.9 MB 2.6 MB/s eta 0:00:15\n",
      "   ---------------------------- ----------- 87.7/124.9 MB 2.6 MB/s eta 0:00:15\n",
      "   ---------------------------- ----------- 87.8/124.9 MB 2.7 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 87.9/124.9 MB 2.7 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 88.1/124.9 MB 2.7 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 88.2/124.9 MB 2.7 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 88.3/124.9 MB 2.7 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 88.5/124.9 MB 2.7 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 88.6/124.9 MB 2.7 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 88.7/124.9 MB 2.7 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 88.8/124.9 MB 2.7 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 89.0/124.9 MB 2.7 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 89.1/124.9 MB 2.7 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 89.2/124.9 MB 2.7 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 89.3/124.9 MB 2.7 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 89.4/124.9 MB 2.7 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 89.5/124.9 MB 2.7 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 89.6/124.9 MB 2.7 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 89.7/124.9 MB 2.7 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 89.8/124.9 MB 2.7 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 89.9/124.9 MB 2.7 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 90.0/124.9 MB 2.7 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 90.2/124.9 MB 2.7 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 90.3/124.9 MB 2.7 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 90.4/124.9 MB 2.6 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 90.5/124.9 MB 2.6 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 90.6/124.9 MB 2.6 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 90.7/124.9 MB 2.6 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 90.8/124.9 MB 2.6 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 90.9/124.9 MB 2.6 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 90.9/124.9 MB 2.6 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 91.1/124.9 MB 2.6 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 91.2/124.9 MB 2.6 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 91.3/124.9 MB 2.6 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 91.4/124.9 MB 2.6 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 91.4/124.9 MB 2.6 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 91.5/124.9 MB 2.6 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 91.5/124.9 MB 2.5 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 91.6/124.9 MB 2.5 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 91.7/124.9 MB 2.5 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 91.7/124.9 MB 2.5 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 91.8/124.9 MB 2.5 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 91.8/124.9 MB 2.5 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 91.9/124.9 MB 2.4 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 92.0/124.9 MB 2.4 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 92.0/124.9 MB 2.4 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 92.1/124.9 MB 2.4 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 92.2/124.9 MB 2.4 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 92.2/124.9 MB 2.4 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 92.3/124.9 MB 2.4 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 92.4/124.9 MB 2.4 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 92.4/124.9 MB 2.3 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 92.5/124.9 MB 2.3 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 92.6/124.9 MB 2.3 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 92.6/124.9 MB 2.3 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 92.7/124.9 MB 2.3 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 92.8/124.9 MB 2.3 MB/s eta 0:00:15\n",
      "   ----------------------------- ---------- 92.9/124.9 MB 2.3 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 92.9/124.9 MB 2.3 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 93.0/124.9 MB 2.3 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 93.1/124.9 MB 2.3 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 93.2/124.9 MB 2.3 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 93.2/124.9 MB 2.3 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 93.3/124.9 MB 2.3 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 93.4/124.9 MB 2.3 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 93.5/124.9 MB 2.3 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 93.6/124.9 MB 2.2 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 93.6/124.9 MB 2.2 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 93.7/124.9 MB 2.2 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 93.8/124.9 MB 2.2 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 93.9/124.9 MB 2.2 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 94.0/124.9 MB 2.2 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 94.0/124.9 MB 2.2 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 94.1/124.9 MB 2.2 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 94.2/124.9 MB 2.2 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 94.2/124.9 MB 2.2 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 94.3/124.9 MB 2.2 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 94.4/124.9 MB 2.2 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 94.4/124.9 MB 2.2 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 94.5/124.9 MB 2.1 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 94.6/124.9 MB 2.1 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 94.6/124.9 MB 2.1 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 94.7/124.9 MB 2.1 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 94.8/124.9 MB 2.1 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 94.8/124.9 MB 2.1 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 94.9/124.9 MB 2.1 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 95.0/124.9 MB 2.1 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 95.0/124.9 MB 2.1 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 95.1/124.9 MB 2.1 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 95.2/124.9 MB 2.1 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 95.2/124.9 MB 2.1 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 95.3/124.9 MB 2.0 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 95.4/124.9 MB 2.0 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 95.4/124.9 MB 2.0 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 95.5/124.9 MB 2.0 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 95.5/124.9 MB 2.0 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 95.6/124.9 MB 2.0 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 95.6/124.9 MB 2.0 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 95.7/124.9 MB 2.0 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 95.7/124.9 MB 2.0 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 95.7/124.9 MB 1.9 MB/s eta 0:00:16\n",
      "   ------------------------------ --------- 95.8/124.9 MB 1.9 MB/s eta 0:00:16\n",
      "   ------------------------------ --------- 95.8/124.9 MB 1.9 MB/s eta 0:00:16\n",
      "   ------------------------------ --------- 95.8/124.9 MB 1.9 MB/s eta 0:00:16\n",
      "   ------------------------------ --------- 95.9/124.9 MB 1.9 MB/s eta 0:00:16\n",
      "   ------------------------------ --------- 95.9/124.9 MB 1.9 MB/s eta 0:00:16\n",
      "   ------------------------------ --------- 96.0/124.9 MB 1.9 MB/s eta 0:00:16\n",
      "   ------------------------------ --------- 96.0/124.9 MB 1.9 MB/s eta 0:00:16\n",
      "   ------------------------------ --------- 96.0/124.9 MB 1.9 MB/s eta 0:00:16\n",
      "   ------------------------------ --------- 96.1/124.9 MB 1.8 MB/s eta 0:00:16\n",
      "   ------------------------------ --------- 96.1/124.9 MB 1.8 MB/s eta 0:00:16\n",
      "   ------------------------------ --------- 96.2/124.9 MB 1.8 MB/s eta 0:00:16\n",
      "   ------------------------------ --------- 96.2/124.9 MB 1.8 MB/s eta 0:00:16\n",
      "   ------------------------------ --------- 96.3/124.9 MB 1.8 MB/s eta 0:00:16\n",
      "   ------------------------------ --------- 96.3/124.9 MB 1.8 MB/s eta 0:00:16\n",
      "   ------------------------------ --------- 96.4/124.9 MB 1.8 MB/s eta 0:00:16\n",
      "   ------------------------------ --------- 96.4/124.9 MB 1.8 MB/s eta 0:00:17\n",
      "   ------------------------------ --------- 96.5/124.9 MB 1.8 MB/s eta 0:00:17\n",
      "   ------------------------------ --------- 96.5/124.9 MB 1.8 MB/s eta 0:00:17\n",
      "   ------------------------------ --------- 96.6/124.9 MB 1.8 MB/s eta 0:00:17\n",
      "   ------------------------------ --------- 96.6/124.9 MB 1.8 MB/s eta 0:00:17\n",
      "   ------------------------------ --------- 96.7/124.9 MB 1.7 MB/s eta 0:00:17\n",
      "   ------------------------------ --------- 96.7/124.9 MB 1.7 MB/s eta 0:00:17\n",
      "   ------------------------------ --------- 96.8/124.9 MB 1.7 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 96.8/124.9 MB 1.7 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 96.9/124.9 MB 1.7 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 96.9/124.9 MB 1.7 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 97.0/124.9 MB 1.7 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 97.1/124.9 MB 1.7 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 97.1/124.9 MB 1.7 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 97.2/124.9 MB 1.7 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 97.2/124.9 MB 1.7 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 97.3/124.9 MB 1.7 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 97.3/124.9 MB 1.6 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 97.4/124.9 MB 1.6 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 97.4/124.9 MB 1.6 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 97.5/124.9 MB 1.6 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 97.5/124.9 MB 1.6 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 97.5/124.9 MB 1.6 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 97.6/124.9 MB 1.6 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 97.6/124.9 MB 1.6 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 97.7/124.9 MB 1.6 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 97.7/124.9 MB 1.6 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 97.8/124.9 MB 1.6 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 97.8/124.9 MB 1.6 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 97.9/124.9 MB 1.6 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 97.9/124.9 MB 1.6 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 98.0/124.9 MB 1.5 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 98.0/124.9 MB 1.5 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 98.1/124.9 MB 1.5 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 98.2/124.9 MB 1.5 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 98.2/124.9 MB 1.5 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 98.3/124.9 MB 1.5 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 98.3/124.9 MB 1.5 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 98.4/124.9 MB 1.5 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 98.4/124.9 MB 1.5 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 98.5/124.9 MB 1.5 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 98.5/124.9 MB 1.5 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 98.6/124.9 MB 1.5 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 98.7/124.9 MB 1.5 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 98.7/124.9 MB 1.5 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 98.8/124.9 MB 1.5 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 98.9/124.9 MB 1.5 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 98.9/124.9 MB 1.5 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 99.0/124.9 MB 1.5 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 99.1/124.9 MB 1.4 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 99.1/124.9 MB 1.4 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 99.2/124.9 MB 1.4 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 99.3/124.9 MB 1.4 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 99.3/124.9 MB 1.4 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 99.4/124.9 MB 1.4 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 99.5/124.9 MB 1.4 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 99.5/124.9 MB 1.4 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 99.6/124.9 MB 1.4 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 99.7/124.9 MB 1.4 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 99.8/124.9 MB 1.4 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 99.8/124.9 MB 1.4 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 99.9/124.9 MB 1.4 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 100.0/124.9 MB 1.4 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 100.1/124.9 MB 1.4 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 100.1/124.9 MB 1.4 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 100.2/124.9 MB 1.4 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 100.3/124.9 MB 1.4 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 100.4/124.9 MB 1.4 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 100.5/124.9 MB 1.4 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 100.5/124.9 MB 1.4 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 100.6/124.9 MB 1.4 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 100.7/124.9 MB 1.4 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 100.8/124.9 MB 1.4 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 100.8/124.9 MB 1.4 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 100.9/124.9 MB 1.4 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 101.0/124.9 MB 1.4 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 101.0/124.9 MB 1.4 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 101.1/124.9 MB 1.4 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 101.2/124.9 MB 1.4 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 101.2/124.9 MB 1.4 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 101.3/124.9 MB 1.4 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 101.4/124.9 MB 1.4 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 101.4/124.9 MB 1.4 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 101.4/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 101.5/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 101.6/124.9 MB 1.4 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 101.6/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 101.7/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 101.7/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 101.8/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 101.8/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 101.9/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 101.9/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 101.9/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 102.0/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 102.0/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 102.1/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 102.1/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 102.1/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 102.2/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 102.2/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 102.2/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 102.3/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 102.3/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 102.4/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 102.4/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 102.4/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 102.5/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 102.5/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 102.6/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 102.6/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 102.7/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 102.7/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 102.8/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 102.8/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 102.9/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 102.9/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 103.0/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 103.0/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   --------------------------------- ------ 103.1/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   --------------------------------- ------ 103.1/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   --------------------------------- ------ 103.2/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   --------------------------------- ------ 103.2/124.9 MB 1.2 MB/s eta 0:00:18\n",
      "   --------------------------------- ------ 103.3/124.9 MB 1.3 MB/s eta 0:00:18\n",
      "   --------------------------------- ------ 103.4/124.9 MB 1.2 MB/s eta 0:00:18\n",
      "   --------------------------------- ------ 103.4/124.9 MB 1.2 MB/s eta 0:00:18\n",
      "   --------------------------------- ------ 103.5/124.9 MB 1.2 MB/s eta 0:00:18\n",
      "   --------------------------------- ------ 103.5/124.9 MB 1.2 MB/s eta 0:00:18\n",
      "   --------------------------------- ------ 103.6/124.9 MB 1.2 MB/s eta 0:00:18\n",
      "   --------------------------------- ------ 103.7/124.9 MB 1.2 MB/s eta 0:00:18\n",
      "   --------------------------------- ------ 103.7/124.9 MB 1.2 MB/s eta 0:00:18\n",
      "   --------------------------------- ------ 103.8/124.9 MB 1.2 MB/s eta 0:00:18\n",
      "   --------------------------------- ------ 103.9/124.9 MB 1.2 MB/s eta 0:00:18\n",
      "   --------------------------------- ------ 103.9/124.9 MB 1.2 MB/s eta 0:00:17\n",
      "   --------------------------------- ------ 104.0/124.9 MB 1.2 MB/s eta 0:00:17\n",
      "   --------------------------------- ------ 104.1/124.9 MB 1.2 MB/s eta 0:00:17\n",
      "   --------------------------------- ------ 104.1/124.9 MB 1.2 MB/s eta 0:00:17\n",
      "   --------------------------------- ------ 104.2/124.9 MB 1.2 MB/s eta 0:00:17\n",
      "   --------------------------------- ------ 104.3/124.9 MB 1.2 MB/s eta 0:00:17\n",
      "   --------------------------------- ------ 104.3/124.9 MB 1.2 MB/s eta 0:00:17\n",
      "   --------------------------------- ------ 104.4/124.9 MB 1.2 MB/s eta 0:00:17\n",
      "   --------------------------------- ------ 104.5/124.9 MB 1.2 MB/s eta 0:00:17\n",
      "   --------------------------------- ------ 104.6/124.9 MB 1.2 MB/s eta 0:00:17\n",
      "   --------------------------------- ------ 104.6/124.9 MB 1.2 MB/s eta 0:00:17\n",
      "   --------------------------------- ------ 104.7/124.9 MB 1.2 MB/s eta 0:00:17\n",
      "   --------------------------------- ------ 104.8/124.9 MB 1.2 MB/s eta 0:00:17\n",
      "   --------------------------------- ------ 104.8/124.9 MB 1.2 MB/s eta 0:00:17\n",
      "   --------------------------------- ------ 104.9/124.9 MB 1.2 MB/s eta 0:00:17\n",
      "   --------------------------------- ------ 105.0/124.9 MB 1.2 MB/s eta 0:00:17\n",
      "   --------------------------------- ------ 105.1/124.9 MB 1.2 MB/s eta 0:00:16\n",
      "   --------------------------------- ------ 105.1/124.9 MB 1.2 MB/s eta 0:00:16\n",
      "   --------------------------------- ------ 105.2/124.9 MB 1.2 MB/s eta 0:00:16\n",
      "   --------------------------------- ------ 105.3/124.9 MB 1.2 MB/s eta 0:00:16\n",
      "   --------------------------------- ------ 105.4/124.9 MB 1.2 MB/s eta 0:00:16\n",
      "   --------------------------------- ------ 105.5/124.9 MB 1.2 MB/s eta 0:00:16\n",
      "   --------------------------------- ------ 105.6/124.9 MB 1.2 MB/s eta 0:00:16\n",
      "   --------------------------------- ------ 105.6/124.9 MB 1.2 MB/s eta 0:00:16\n",
      "   --------------------------------- ------ 105.7/124.9 MB 1.3 MB/s eta 0:00:16\n",
      "   --------------------------------- ------ 105.8/124.9 MB 1.3 MB/s eta 0:00:16\n",
      "   --------------------------------- ------ 105.9/124.9 MB 1.3 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 106.0/124.9 MB 1.3 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 106.1/124.9 MB 1.3 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 106.2/124.9 MB 1.3 MB/s eta 0:00:15\n",
      "   ---------------------------------- ----- 106.2/124.9 MB 1.3 MB/s eta 0:00:15\n",
      "   ---------------------------------- ----- 106.3/124.9 MB 1.3 MB/s eta 0:00:15\n",
      "   ---------------------------------- ----- 106.4/124.9 MB 1.3 MB/s eta 0:00:15\n",
      "   ---------------------------------- ----- 106.5/124.9 MB 1.3 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 106.6/124.9 MB 1.3 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 106.6/124.9 MB 1.3 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 106.7/124.9 MB 1.3 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 106.8/124.9 MB 1.3 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 106.9/124.9 MB 1.4 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 107.0/124.9 MB 1.4 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 107.1/124.9 MB 1.4 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 107.2/124.9 MB 1.4 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 107.3/124.9 MB 1.4 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 107.4/124.9 MB 1.4 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 107.5/124.9 MB 1.4 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 107.6/124.9 MB 1.4 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 107.7/124.9 MB 1.4 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 107.8/124.9 MB 1.4 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 107.9/124.9 MB 1.4 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 108.0/124.9 MB 1.4 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 108.1/124.9 MB 1.4 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 108.2/124.9 MB 1.5 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 108.3/124.9 MB 1.5 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 108.4/124.9 MB 1.5 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 108.5/124.9 MB 1.5 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 108.6/124.9 MB 1.5 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 108.7/124.9 MB 1.5 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 108.8/124.9 MB 1.5 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 108.9/124.9 MB 1.5 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 109.1/124.9 MB 1.5 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 109.2/124.9 MB 1.5 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 109.3/124.9 MB 1.5 MB/s eta 0:00:11\n",
      "   ----------------------------------- ---- 109.4/124.9 MB 1.6 MB/s eta 0:00:11\n",
      "   ----------------------------------- ---- 109.5/124.9 MB 1.6 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 109.6/124.9 MB 1.6 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 109.7/124.9 MB 1.6 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 109.9/124.9 MB 1.6 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 110.0/124.9 MB 1.6 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 110.1/124.9 MB 1.6 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 110.2/124.9 MB 1.6 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 110.4/124.9 MB 1.6 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 110.5/124.9 MB 1.6 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 110.6/124.9 MB 1.6 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 110.7/124.9 MB 1.6 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 110.8/124.9 MB 1.6 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 111.0/124.9 MB 1.6 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 111.1/124.9 MB 1.6 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 111.2/124.9 MB 1.7 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 111.3/124.9 MB 1.7 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 111.5/124.9 MB 1.7 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 111.6/124.9 MB 1.7 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 111.7/124.9 MB 1.7 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 111.8/124.9 MB 1.7 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 112.0/124.9 MB 1.8 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 112.1/124.9 MB 1.8 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 112.3/124.9 MB 1.8 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 112.4/124.9 MB 1.9 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 112.5/124.9 MB 1.9 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 112.7/124.9 MB 1.9 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 112.8/124.9 MB 2.0 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 112.9/124.9 MB 2.0 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 113.1/124.9 MB 2.0 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 113.2/124.9 MB 2.1 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 113.3/124.9 MB 2.1 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 113.5/124.9 MB 2.1 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 113.6/124.9 MB 2.2 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 113.7/124.9 MB 2.2 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 113.9/124.9 MB 2.2 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 114.0/124.9 MB 2.3 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 114.2/124.9 MB 2.3 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 114.3/124.9 MB 2.3 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 114.4/124.9 MB 2.3 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 114.6/124.9 MB 2.3 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 114.7/124.9 MB 2.4 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 114.9/124.9 MB 2.4 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 115.0/124.9 MB 2.4 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 115.2/124.9 MB 2.4 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 115.3/124.9 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 115.4/124.9 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 115.6/124.9 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 115.7/124.9 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 115.9/124.9 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 116.0/124.9 MB 2.6 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 116.2/124.9 MB 2.6 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 116.3/124.9 MB 2.6 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 116.5/124.9 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 116.6/124.9 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 116.7/124.9 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 116.8/124.9 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 116.9/124.9 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 117.0/124.9 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 117.1/124.9 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 117.2/124.9 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 117.3/124.9 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 117.4/124.9 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 117.5/124.9 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 117.5/124.9 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 117.6/124.9 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 117.7/124.9 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 117.8/124.9 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 117.9/124.9 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 118.0/124.9 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 118.0/124.9 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 118.1/124.9 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 118.2/124.9 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 118.3/124.9 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 118.4/124.9 MB 2.6 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 118.4/124.9 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 118.6/124.9 MB 2.6 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 118.6/124.9 MB 2.6 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 118.7/124.9 MB 2.6 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 118.8/124.9 MB 2.6 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 118.8/124.9 MB 2.6 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 118.9/124.9 MB 2.6 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 119.0/124.9 MB 2.6 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 119.0/124.9 MB 2.5 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 119.1/124.9 MB 2.5 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 119.2/124.9 MB 2.5 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 119.2/124.9 MB 2.5 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 119.3/124.9 MB 2.5 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 119.3/124.9 MB 2.5 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 119.4/124.9 MB 2.5 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 119.5/124.9 MB 2.5 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 119.5/124.9 MB 2.5 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 119.6/124.9 MB 2.4 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 119.6/124.9 MB 2.4 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 119.7/124.9 MB 2.4 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 119.7/124.9 MB 2.4 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 119.8/124.9 MB 2.4 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 119.8/124.9 MB 2.4 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 119.9/124.9 MB 2.3 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 120.0/124.9 MB 2.3 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 120.0/124.9 MB 2.3 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 120.1/124.9 MB 2.3 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 120.1/124.9 MB 2.3 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 120.2/124.9 MB 2.3 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 120.3/124.9 MB 2.3 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 120.3/124.9 MB 2.3 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 120.4/124.9 MB 2.2 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 120.4/124.9 MB 2.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 120.5/124.9 MB 2.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 120.6/124.9 MB 2.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 120.6/124.9 MB 2.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 120.7/124.9 MB 2.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 120.7/124.9 MB 2.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 120.8/124.9 MB 2.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 120.9/124.9 MB 2.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 120.9/124.9 MB 2.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 120.9/124.9 MB 2.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 121.0/124.9 MB 2.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 121.1/124.9 MB 2.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 121.1/124.9 MB 2.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 121.1/124.9 MB 2.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 121.2/124.9 MB 2.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 121.3/124.9 MB 2.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 121.3/124.9 MB 2.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 121.4/124.9 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 121.4/124.9 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 121.5/124.9 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 121.5/124.9 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 121.6/124.9 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 121.6/124.9 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 121.7/124.9 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 121.7/124.9 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  121.8/124.9 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  121.9/124.9 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  121.9/124.9 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  122.0/124.9 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  122.1/124.9 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  122.1/124.9 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  122.2/124.9 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  122.2/124.9 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  122.3/124.9 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  122.4/124.9 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  122.4/124.9 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  122.5/124.9 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  122.6/124.9 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  122.6/124.9 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  122.7/124.9 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  122.8/124.9 MB 1.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  122.9/124.9 MB 1.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  122.9/124.9 MB 1.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  123.0/124.9 MB 1.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  123.1/124.9 MB 1.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  123.1/124.9 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  123.2/124.9 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  123.3/124.9 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  123.4/124.9 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  123.5/124.9 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  123.5/124.9 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  123.6/124.9 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  123.7/124.9 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  123.8/124.9 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  123.9/124.9 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  124.0/124.9 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  124.0/124.9 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  124.1/124.9 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  124.2/124.9 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  124.3/124.9 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  124.4/124.9 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  124.5/124.9 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  124.5/124.9 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  124.6/124.9 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  124.7/124.9 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  124.8/124.9 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  124.9/124.9 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  124.9/124.9 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  124.9/124.9 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  124.9/124.9 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 124.9/124.9 MB 1.6 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000280 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 705\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.520791\n",
      "Validation Spearman Correlation: 0.9984565868418234\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from lightgbm import LGBMRegressor\n",
    "from scipy.stats import spearmanr\n",
    "from textstat import flesch_reading_ease, gunning_fog\n",
    "import spacy\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "# Load spaCy model for POS tagging\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# --- Load Dataset ---\n",
    "train_data = pd.read_csv(\"train.csv\")  # Format: id, text, score\n",
    "val_data = pd.read_csv(\"val.csv\")      # Format: id, text, score\n",
    "test_data = pd.read_csv(\"test.csv\")    # Format: id, text\n",
    "\n",
    "# --- Define Spearman Correlation Metric ---\n",
    "def spearman_correlation(y_true, y_pred):\n",
    "    return spearmanr(y_true, y_pred).correlation\n",
    "\n",
    "spearman_scorer = make_scorer(spearman_correlation, greater_is_better=True)\n",
    "\n",
    "# --- Feature Engineering ---\n",
    "def extract_features(df):\n",
    "    # Basic Features\n",
    "    df[\"sentence_length\"] = df[\"text\"].apply(len)\n",
    "    df[\"word_count\"] = df[\"text\"].apply(lambda x: len(x.split()))\n",
    "    df[\"avg_word_length\"] = df[\"text\"].apply(lambda x: np.mean([len(word) for word in x.split()]) if x.split() else 0)\n",
    "    df[\"punctuation_count\"] = df[\"text\"].str.count(r\"[^\\w\\s]\")\n",
    "    df[\"question_count\"] = df[\"text\"].str.count(r\"\\?\")\n",
    "    df[\"exclamation_count\"] = df[\"text\"].str.count(r\"!\")\n",
    "    \n",
    "    # Lexical Features\n",
    "    df[\"type_token_ratio\"] = df[\"text\"].apply(lambda x: len(set(x.split())) / (len(x.split()) + 1e-5))\n",
    "    df[\"stopword_count\"] = df[\"text\"].apply(lambda x: sum(1 for word in x.split() if word.lower() in spacy.lang.en.stop_words.STOP_WORDS))\n",
    "    \n",
    "    # Readability Metrics\n",
    "    df[\"flesch_reading_ease\"] = df[\"text\"].apply(lambda x: flesch_reading_ease(x))\n",
    "    df[\"gunning_fog\"] = df[\"text\"].apply(lambda x: gunning_fog(x))\n",
    "    \n",
    "    # Syntactic Features (POS Tag Distribution)\n",
    "    def pos_counts(text):\n",
    "        doc = nlp(text)\n",
    "        pos_tags = [token.pos_ for token in doc]\n",
    "        return {tag: pos_tags.count(tag) for tag in set(pos_tags)}\n",
    "    \n",
    "    pos_features = df[\"text\"].apply(pos_counts)\n",
    "    pos_df = pd.DataFrame(pos_features.tolist()).fillna(0)\n",
    "    df = pd.concat([df.reset_index(drop=True), pos_df.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    return df.drop(columns=[\"text\"])\n",
    "\n",
    "# Extract features for training, validation, and testing\n",
    "X_train = extract_features(train_data)\n",
    "y_train = train_data[\"score\"]\n",
    "\n",
    "X_val = extract_features(val_data)\n",
    "y_val = val_data[\"score\"]\n",
    "\n",
    "X_test = extract_features(test_data)\n",
    "\n",
    "# --- Align Feature Columns ---\n",
    "def align_features(train_df, other_df):\n",
    "    # Add missing columns to other_df\n",
    "    for col in train_df.columns:\n",
    "        if col not in other_df.columns:\n",
    "            other_df[col] = 0\n",
    "    # Drop extra columns in other_df\n",
    "    for col in other_df.columns:\n",
    "        if col not in train_df.columns:\n",
    "            other_df.drop(columns=[col], inplace=True)\n",
    "    # Reorder columns to match train_df\n",
    "    return other_df[train_df.columns]\n",
    "\n",
    "# Align validation and test datasets to match the training dataset\n",
    "X_val = align_features(X_train, X_val)\n",
    "X_test = align_features(X_train, X_test)\n",
    "\n",
    "\n",
    "# --- Feature Selection ---\n",
    "selector = SelectKBest(score_func=f_regression, k=20)\n",
    "X_train = selector.fit_transform(X_train, y_train)\n",
    "X_val = selector.transform(X_val)\n",
    "X_test = selector.transform(X_test)\n",
    "\n",
    "# --- Model Tuning ---\n",
    "# Combine LightGBM and XGBoost in a voting regressor for an ensemble\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "lgb_model = LGBMRegressor(n_estimators=1000, learning_rate=0.01, max_depth=10, num_leaves=50, random_state=42)\n",
    "xgb_model = XGBRegressor(n_estimators=1000, learning_rate=0.01, max_depth=10, random_state=42)\n",
    "\n",
    "ensemble_model = VotingRegressor([(\"lgb\", lgb_model), (\"xgb\", xgb_model)])\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# --- Evaluate on Validation Set ---\n",
    "y_val_pred = ensemble_model.predict(X_val)\n",
    "spearman_corr = spearman_correlation(y_val, y_val_pred)\n",
    "print(\"Validation Spearman Correlation:\", spearman_corr)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample submission file 'jovolukic24.csv' generated successfully!\n"
     ]
    }
   ],
   "source": [
    "# --- Generate Predictions for Test Set ---\n",
    "y_test_pred = ensemble_model.predict(X_test)\n",
    "\n",
    "# --- Create Sample Submission ---\n",
    "submission = pd.DataFrame({\"id\": test_data[\"id\"], \"score\": y_test_pred})\n",
    "submission.to_csv(\"jovolukic24.csv\", index=False)\n",
    "\n",
    "print(\"Sample submission file 'jovolukic24.csv' generated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.1, Cross-Validation Spearman Correlation: 0.1047050169953134\n",
      "Alpha: 1.0, Cross-Validation Spearman Correlation: 0.1047905505049009\n",
      "Alpha: 10.0, Cross-Validation Spearman Correlation: 0.10483451657655958\n",
      "Alpha: 100.0, Cross-Validation Spearman Correlation: 0.10255178453565819\n",
      "Best Alpha: 10.0, Best Cross-Validation Score: 0.10483451657655958\n",
      "Validation Spearman Correlation: 0.0764112318103484\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# --- Load Dataset ---\n",
    "train_data = pd.read_csv(\"train.csv\")  # Format: id, text, score\n",
    "val_data = pd.read_csv(\"val.csv\")      # Format: id, text, score\n",
    "test_data = pd.read_csv(\"test.csv\")    # Format: id, text\n",
    "\n",
    "# --- Define Spearman Correlation Metric ---\n",
    "def spearman_correlation(y_true, y_pred):\n",
    "    return spearmanr(y_true, y_pred).correlation\n",
    "\n",
    "spearman_scorer = make_scorer(spearman_correlation, greater_is_better=True)\n",
    "\n",
    "# --- Feature Engineering ---\n",
    "def extract_features(df):\n",
    "    # Basic Features\n",
    "    df[\"sentence_length\"] = df[\"text\"].apply(len)\n",
    "    df[\"word_count\"] = df[\"text\"].apply(lambda x: len(x.split()))\n",
    "    df[\"avg_word_length\"] = df[\"text\"].apply(lambda x: np.mean([len(word) for word in x.split()]) if x.split() else 0)\n",
    "    df[\"punctuation_count\"] = df[\"text\"].str.count(r\"[^\\w\\s]\")\n",
    "    df[\"stopword_count\"] = df[\"text\"].apply(lambda x: sum(1 for word in x.split() if word.lower() in spacy.lang.en.stop_words.STOP_WORDS))\n",
    "    return df[[\"sentence_length\", \"word_count\", \"avg_word_length\", \"punctuation_count\", \"stopword_count\"]]\n",
    "\n",
    "# Extract features\n",
    "X_train = extract_features(train_data)\n",
    "y_train = train_data[\"score\"]\n",
    "\n",
    "X_val = extract_features(val_data)\n",
    "y_val = val_data[\"score\"]\n",
    "\n",
    "X_test = extract_features(test_data)\n",
    "\n",
    "# --- Ridge Regression ---\n",
    "# Initialize Ridge Regression with hyperparameter tuning\n",
    "alphas = [0.1, 1.0, 10.0, 100.0]  # Regularization strengths to try\n",
    "best_alpha = None\n",
    "best_score = -np.inf\n",
    "\n",
    "# Perform cross-validation to find the best alpha\n",
    "for alpha in alphas:\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    scores = cross_val_score(ridge, X_train, y_train, cv=5, scoring=spearman_scorer)\n",
    "    mean_score = np.mean(scores)\n",
    "    print(f\"Alpha: {alpha}, Cross-Validation Spearman Correlation: {mean_score}\")\n",
    "    if mean_score > best_score:\n",
    "        best_alpha = alpha\n",
    "        best_score = mean_score\n",
    "\n",
    "print(f\"Best Alpha: {best_alpha}, Best Cross-Validation Score: {best_score}\")\n",
    "\n",
    "# Train final model with best alpha\n",
    "ridge = Ridge(alpha=best_alpha)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on validation set\n",
    "y_val_pred = ridge.predict(X_val)\n",
    "val_spearman_corr = spearman_correlation(y_val, y_val_pred)\n",
    "print(\"Validation Spearman Correlation:\", val_spearman_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Generate Predictions for Test Set ---\n",
    "y_test_pred = ridge.predict(X_test)\n",
    "\n",
    "# --- Create Sample Submission ---\n",
    "submission = pd.DataFrame({\"id\": test_data[\"id\"], \"score\": y_test_pred})\n",
    "submission.to_csv(\"sample_submission.csv\", index=False)\n",
    "\n",
    "print(\"Sample submission file 'sample_submission.csv' generated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000108 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 448\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 0.520791\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's rmse: 0.813222\tvalid_0's l2: 0.66133\n",
      "Validation Spearman Correlation: 0.06626610394244006\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.stats import spearmanr\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# --- Load Dataset ---\n",
    "train_data = pd.read_csv(\"train.csv\")  # Format: id, text, score\n",
    "val_data = pd.read_csv(\"val.csv\")      # Format: id, text, score\n",
    "test_data = pd.read_csv(\"test.csv\")    # Format: id, text\n",
    "\n",
    "# --- Define Spearman Correlation Metric ---\n",
    "def spearman_correlation(y_true, y_pred):\n",
    "    return spearmanr(y_true, y_pred).correlation\n",
    "\n",
    "spearman_scorer = make_scorer(spearman_correlation, greater_is_better=True)\n",
    "\n",
    "# --- Feature Engineering ---\n",
    "def extract_features(df):\n",
    "    df[\"sentence_length\"] = df[\"text\"].apply(len)\n",
    "    df[\"word_count\"] = df[\"text\"].apply(lambda x: len(x.split()))\n",
    "    df[\"avg_word_length\"] = df[\"text\"].apply(lambda x: np.mean([len(word) for word in x.split()]) if x.split() else 0)\n",
    "    df[\"punctuation_count\"] = df[\"text\"].str.count(r\"[^\\w\\s]\")\n",
    "    df[\"type_token_ratio\"] = df[\"text\"].apply(lambda x: len(set(x.split())) / (len(x.split()) + 1e-5))\n",
    "    return df[[\"sentence_length\", \"word_count\", \"avg_word_length\", \"punctuation_count\", \"type_token_ratio\"]]\n",
    "\n",
    "X_train = extract_features(train_data)\n",
    "y_train = train_data[\"score\"]\n",
    "\n",
    "X_val = extract_features(val_data)\n",
    "y_val = val_data[\"score\"]\n",
    "\n",
    "X_test = extract_features(test_data)\n",
    "\n",
    "# --- Model Training: LightGBM ---\n",
    "lgb_model = LGBMRegressor(n_estimators=1000, learning_rate=0.01, max_depth=5, random_state=42)\n",
    "lgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric=\"rmse\", callbacks=[early_stopping(stopping_rounds=50, verbose=True)])\n",
    "\n",
    "# --- Evaluate on Validation Set ---\n",
    "y_val_pred = lgb_model.predict(X_val)\n",
    "val_spearman_corr = spearman_correlation(y_val, y_val_pred)\n",
    "print(\"Validation Spearman Correlation:\", val_spearman_corr)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Generate Predictions for Test Set ---\n",
    "y_test_pred = lgb_model.predict(X_test)\n",
    "\n",
    "# --- Create Sample Submission ---\n",
    "submission = pd.DataFrame({\"id\": test_data[\"id\"], \"score\": y_test_pred})\n",
    "submission.to_csv(\"sample_submission.csv\", index=False)\n",
    "\n",
    "print(\"Sample submission file 'sample_submission.csv' generated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Spearman Correlation: 0.4123602272416702\n",
      "Cross-Validation Spearman Correlation Scores: [0.36257665 0.33906107 0.34410552 0.32748827 0.33575692]\n",
      "Mean Spearman Correlation (CV): 0.3417976865078033\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# --- Load Dataset ---\n",
    "train_data = pd.read_csv(\"train.csv\")  # Format: id, text, score\n",
    "val_data = pd.read_csv(\"val.csv\")      # Format: id, text, score\n",
    "test_data = pd.read_csv(\"test.csv\")    # Format: id, text\n",
    "\n",
    "# --- Define Spearman Correlation Metric ---\n",
    "def spearman_correlation(y_true, y_pred):\n",
    "    return spearmanr(y_true, y_pred).correlation\n",
    "\n",
    "spearman_scorer = make_scorer(spearman_correlation, greater_is_better=True)\n",
    "\n",
    "# --- TF-IDF Vectorization ---\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=5000,  # Limit to top 5000 features\n",
    "    ngram_range=(1, 2),  # Unigrams and bigrams\n",
    "    stop_words=\"english\"  # Remove common stopwords\n",
    ")\n",
    "\n",
    "# Fit TF-IDF on the training data and transform the datasets\n",
    "X_train = tfidf.fit_transform(train_data[\"text\"])\n",
    "y_train = train_data[\"score\"]\n",
    "\n",
    "X_val = tfidf.transform(val_data[\"text\"])\n",
    "y_val = val_data[\"score\"]\n",
    "\n",
    "X_test = tfidf.transform(test_data[\"text\"])\n",
    "\n",
    "# --- Linear Regression ---\n",
    "# Initialize and train the model\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "# --- Evaluate on Validation Set ---\n",
    "y_val_pred = linear_model.predict(X_val)\n",
    "val_spearman_corr = spearman_correlation(y_val, y_val_pred)\n",
    "print(\"Validation Spearman Correlation:\", val_spearman_corr)\n",
    "\n",
    "# --- Cross-Validation ---\n",
    "cv_scores = cross_val_score(linear_model, X_train, y_train, cv=5, scoring=spearman_scorer)\n",
    "print(\"Cross-Validation Spearman Correlation Scores:\", cv_scores)\n",
    "print(\"Mean Spearman Correlation (CV):\", cv_scores.mean())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample submission file 'sample_submission.csv' generated successfully!\n"
     ]
    }
   ],
   "source": [
    "# --- Generate Predictions for Test Set ---\n",
    "y_test_pred = linear_model.predict(X_test)\n",
    "\n",
    "# --- Create Sample Submission ---\n",
    "submission = pd.DataFrame({\"id\": test_data[\"id\"], \"score\": y_test_pred})\n",
    "submission.to_csv(\"sample_submission.csv\", index=False)\n",
    "\n",
    "print(\"Sample submission file 'sample_submission.csv' generated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.3-cp310-cp310-win_amd64.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from gensim) (1.26.0)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from gensim) (1.11.4)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from gensim) (6.4.0)\n",
      "Downloading gensim-4.3.3-cp310-cp310-win_amd64.whl (24.0 MB)\n",
      "   ---------------------------------------- 0.0/24.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/24.0 MB 640.0 kB/s eta 0:00:38\n",
      "   ---------------------------------------- 0.1/24.0 MB 812.7 kB/s eta 0:00:30\n",
      "   ---------------------------------------- 0.2/24.0 MB 1.8 MB/s eta 0:00:14\n",
      "   ---------------------------------------- 0.3/24.0 MB 1.8 MB/s eta 0:00:14\n",
      "    --------------------------------------- 0.5/24.0 MB 2.7 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 0.8/24.0 MB 3.2 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 1.1/24.0 MB 3.6 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 1.3/24.0 MB 3.9 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 1.6/24.0 MB 4.1 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 1.9/24.0 MB 4.3 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 2.2/24.0 MB 4.4 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 2.4/24.0 MB 4.7 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 2.6/24.0 MB 4.7 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 2.9/24.0 MB 4.8 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 3.2/24.0 MB 4.8 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 3.5/24.0 MB 4.9 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 3.8/24.0 MB 5.1 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 4.1/24.0 MB 5.1 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 4.4/24.0 MB 5.2 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 4.7/24.0 MB 5.3 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 5.0/24.0 MB 5.3 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 5.3/24.0 MB 5.4 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 5.6/24.0 MB 5.5 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 5.9/24.0 MB 5.5 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 6.2/24.0 MB 5.6 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 6.3/24.0 MB 5.5 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 6.7/24.0 MB 5.5 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 6.9/24.0 MB 5.5 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 7.1/24.0 MB 5.5 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 7.3/24.0 MB 5.4 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 7.6/24.0 MB 5.4 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 7.8/24.0 MB 5.4 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 8.0/24.0 MB 5.4 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 8.2/24.0 MB 5.4 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 8.4/24.0 MB 5.3 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 8.6/24.0 MB 5.3 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 8.8/24.0 MB 5.3 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 9.1/24.0 MB 5.3 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 9.3/24.0 MB 5.3 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 9.5/24.0 MB 5.3 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 9.6/24.0 MB 5.3 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 9.9/24.0 MB 5.2 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 10.2/24.0 MB 5.2 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 10.4/24.0 MB 5.4 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 10.6/24.0 MB 5.5 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 10.8/24.0 MB 5.5 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 11.0/24.0 MB 5.5 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 11.1/24.0 MB 5.5 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 11.4/24.0 MB 5.5 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 11.6/24.0 MB 5.4 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 11.7/24.0 MB 5.3 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 11.9/24.0 MB 5.3 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 12.1/24.0 MB 5.2 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 12.3/24.0 MB 5.2 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 12.5/24.0 MB 5.2 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 12.6/24.0 MB 5.1 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 12.8/24.0 MB 5.1 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 12.9/24.0 MB 5.0 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 13.1/24.0 MB 5.0 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 13.3/24.0 MB 5.0 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 13.5/24.0 MB 4.9 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 13.7/24.0 MB 4.9 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 13.9/24.0 MB 4.9 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 14.1/24.0 MB 4.8 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 14.2/24.0 MB 4.7 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 14.4/24.0 MB 4.7 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 14.6/24.0 MB 4.7 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 14.8/24.0 MB 4.7 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 15.0/24.0 MB 4.6 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 15.1/24.0 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 15.3/24.0 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 15.4/24.0 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 15.5/24.0 MB 4.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 15.7/24.0 MB 4.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 15.8/24.0 MB 4.3 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 16.0/24.0 MB 4.3 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 16.1/24.0 MB 4.2 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 16.2/24.0 MB 4.2 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 16.4/24.0 MB 4.1 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 16.5/24.0 MB 4.2 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 16.7/24.0 MB 4.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 16.8/24.0 MB 4.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 17.0/24.0 MB 4.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 17.1/24.0 MB 4.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 17.3/24.0 MB 4.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 17.4/24.0 MB 4.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 17.6/24.0 MB 4.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 17.7/24.0 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 17.9/24.0 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 18.1/24.0 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 18.2/24.0 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 18.2/24.0 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 18.5/24.0 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 18.6/24.0 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 18.7/24.0 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 18.8/24.0 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 18.9/24.0 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 19.0/24.0 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 19.2/24.0 MB 3.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 19.3/24.0 MB 3.6 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 19.4/24.0 MB 3.6 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 19.5/24.0 MB 3.6 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 19.6/24.0 MB 3.6 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 19.8/24.0 MB 3.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 19.9/24.0 MB 3.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 20.0/24.0 MB 3.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 20.2/24.0 MB 3.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 20.3/24.0 MB 3.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 20.4/24.0 MB 3.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 20.6/24.0 MB 3.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 20.7/24.0 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 20.8/24.0 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 21.0/24.0 MB 3.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.0/24.0 MB 3.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.2/24.0 MB 3.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.3/24.0 MB 3.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.4/24.0 MB 3.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.5/24.0 MB 3.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.6/24.0 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 21.7/24.0 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 21.8/24.0 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 21.9/24.0 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.0/24.0 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.1/24.0 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.2/24.0 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.3/24.0 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.4/24.0 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.5/24.0 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.7/24.0 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.8/24.0 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 22.9/24.0 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.0/24.0 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.1/24.0 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.3/24.0 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.4/24.0 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  23.5/24.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  23.6/24.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  23.7/24.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  23.8/24.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  23.9/24.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.0/24.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.0/24.0 MB 2.8 MB/s eta 0:00:00\n",
      "Installing collected packages: gensim\n",
      "Successfully installed gensim-4.3.3\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Spearman Correlation: 0.46424084777839547\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.stats import spearmanr\n",
    "import numpy as np\n",
    "\n",
    "# --- Load Dataset ---\n",
    "train_data = pd.read_csv(\"train.csv\")  # Format: id, text, score\n",
    "val_data = pd.read_csv(\"val.csv\")      # Format: id, text, score\n",
    "test_data = pd.read_csv(\"test.csv\")    # Format: id, text\n",
    "\n",
    "# --- Define Spearman Correlation Metric ---\n",
    "def spearman_correlation(y_true, y_pred):\n",
    "    return spearmanr(y_true, y_pred).correlation\n",
    "\n",
    "spearman_scorer = make_scorer(spearman_correlation, greater_is_better=True)\n",
    "\n",
    "# --- Train Word2Vec on Training Data ---\n",
    "# Tokenize text\n",
    "train_sentences = train_data[\"text\"].apply(lambda x: x.split())\n",
    "val_sentences = val_data[\"text\"].apply(lambda x: x.split())\n",
    "test_sentences = test_data[\"text\"].apply(lambda x: x.split())\n",
    "\n",
    "# Train Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences=train_sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Create sentence embeddings by averaging word embeddings\n",
    "def get_sentence_embedding(sentences, model, vector_size):\n",
    "    embeddings = []\n",
    "    for sentence in sentences:\n",
    "        vectors = [model.wv[word] for word in sentence if word in model.wv]\n",
    "        if vectors:\n",
    "            embeddings.append(np.mean(vectors, axis=0))\n",
    "        else:\n",
    "            embeddings.append(np.zeros(vector_size))  # Handle empty sentences\n",
    "    return np.array(embeddings)\n",
    "\n",
    "X_train = get_sentence_embedding(train_sentences, word2vec_model, vector_size=100)\n",
    "y_train = train_data[\"score\"]\n",
    "\n",
    "X_val = get_sentence_embedding(val_sentences, word2vec_model, vector_size=100)\n",
    "y_val = val_data[\"score\"]\n",
    "\n",
    "X_test = get_sentence_embedding(test_sentences, word2vec_model, vector_size=100)\n",
    "\n",
    "# --- Linear Regression ---\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "# --- Evaluate on Validation Set ---\n",
    "y_val_pred = linear_model.predict(X_val)\n",
    "val_spearman_corr = spearman_correlation(y_val, y_val_pred)\n",
    "print(\"Validation Spearman Correlation:\", val_spearman_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample submission file 'carolosmora17.csv' generated successfully!\n"
     ]
    }
   ],
   "source": [
    "# --- Generate Predictions for Test Set ---\n",
    "y_test_pred = linear_model.predict(X_test)\n",
    "\n",
    "# --- Create Sample Submission ---\n",
    "submission = pd.DataFrame({\"id\": test_data[\"id\"], \"score\": y_test_pred})\n",
    "submission.to_csv(\"carlosmora17.csv\", index=False)\n",
    "\n",
    "print(\"Sample submission file 'carolosmora17.csv' generated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# --- Load Dataset ---\n",
    "train_data = pd.read_csv(\"train.csv\")  # Format: id, text, score\n",
    "val_data = pd.read_csv(\"val.csv\")      # Format: id, text, score\n",
    "test_data = pd.read_csv(\"test.csv\")    # Format: id, text\n",
    "\n",
    "# --- Define Spearman Correlation Metric ---\n",
    "def spearman_correlation(y_true, y_pred):\n",
    "    return spearmanr(y_true, y_pred).correlation\n",
    "\n",
    "# --- Train Word2Vec ---\n",
    "# Tokenize text into sentences\n",
    "train_sentences = train_data[\"text\"].apply(lambda x: x.split())\n",
    "val_sentences = val_data[\"text\"].apply(lambda x: x.split())\n",
    "test_sentences = test_data[\"text\"].apply(lambda x: x.split())\n",
    "\n",
    "# Train Word2Vec on the training text\n",
    "word2vec_model = Word2Vec(sentences=train_sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# --- Create Sentence Embeddings ---\n",
    "def get_sentence_embedding(sentences, model, vector_size):\n",
    "    embeddings = []\n",
    "    for sentence in sentences:\n",
    "        vectors = [model.wv[word] for word in sentence if word in model.wv]\n",
    "        if vectors:\n",
    "            embeddings.append(np.mean(vectors, axis=0))\n",
    "        else:\n",
    "            embeddings.append(np.zeros(vector_size))  # Handle empty sentences\n",
    "    return np.array(embeddings)\n",
    "\n",
    "# Convert text data to embeddings\n",
    "X_train = get_sentence_embedding(train_sentences, word2vec_model, vector_size=100)\n",
    "y_train = train_data[\"score\"]\n",
    "\n",
    "X_val = get_sentence_embedding(val_sentences, word2vec_model, vector_size=100)\n",
    "y_val = val_data[\"score\"]\n",
    "\n",
    "X_test = get_sentence_embedding(test_sentences, word2vec_model, vector_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Validation Spearman Correlation: 0.4417634092565491\n",
      "Random Forest Cross-Validation Spearman Correlation Scores: [0.44890317 0.49122636 0.47052744 0.45040033 0.46407155]\n",
      "Mean Spearman Correlation (CV): 0.46502576977873006\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# --- Random Forest Model ---\n",
    "rf_model = RandomForestRegressor(n_estimators=500, max_depth=10, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# --- Evaluate on Validation Set ---\n",
    "y_val_pred = rf_model.predict(X_val)\n",
    "val_spearman_corr = spearman_correlation(y_val, y_val_pred)\n",
    "print(\"Random Forest Validation Spearman Correlation:\", val_spearman_corr)\n",
    "\n",
    "# --- Cross-Validation ---\n",
    "cv_scores = cross_val_score(rf_model, X_train, y_train, cv=5, scoring=make_scorer(spearman_correlation))\n",
    "print(\"Random Forest Cross-Validation Spearman Correlation Scores:\", cv_scores)\n",
    "print(\"Mean Spearman Correlation (CV):\", np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample submission file 'iagolopez22.csv' generated successfully!\n"
     ]
    }
   ],
   "source": [
    "# --- Generate Predictions for Test Set ---\n",
    "y_test_pred = rf_model.predict(X_test)\n",
    "\n",
    "# --- Create Sample Submission ---\n",
    "submission_rf = pd.DataFrame({\"id\": test_data[\"id\"], \"score\": y_test_pred})\n",
    "submission_rf.to_csv(\"iagolopez22.csv\", index=False)\n",
    "print(\"Sample submission file 'iagolopez22.csv' generated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002583 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score 0.520791\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[370]\tvalid_0's rmse: 0.732209\tvalid_0's l2: 0.53613\n",
      "LightGBM Validation Spearman Correlation: 0.4432684031283471\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor, early_stopping\n",
    "\n",
    "# --- LightGBM Model ---\n",
    "lgb_model = LGBMRegressor(n_estimators=1000, learning_rate=0.01, max_depth=10, random_state=42)\n",
    "\n",
    "# Early stopping callback\n",
    "callbacks = [early_stopping(stopping_rounds=50, verbose=True)]\n",
    "\n",
    "# Train the model with callbacks\n",
    "lgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric=\"rmse\", callbacks=callbacks)\n",
    "\n",
    "# --- Evaluate on Validation Set ---\n",
    "y_val_pred = lgb_model.predict(X_val)\n",
    "val_spearman_corr = spearman_correlation(y_val, y_val_pred)\n",
    "print(\"LightGBM Validation Spearman Correlation:\", val_spearman_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample submission file 'gregosierra25.csv' generated successfully!\n"
     ]
    }
   ],
   "source": [
    "# --- Generate Predictions for Test Set ---\n",
    "y_test_pred = lgb_model.predict(X_test)\n",
    "\n",
    "# --- Create Sample Submission ---\n",
    "submission_lgb = pd.DataFrame({\"id\": test_data[\"id\"], \"score\": y_test_pred})\n",
    "submission_lgb.to_csv(\"gregosierra25.csv\", index=False)\n",
    "print(\"Sample submission file 'gregosierra25.csv' generated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25948\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 105\n",
      "[LightGBM] [Info] Start training from score 0.520791\n",
      "Best Parameters: {'subsample': 1.0, 'num_leaves': 20, 'n_estimators': 500, 'min_child_samples': 20, 'max_depth': -1, 'learning_rate': 0.01, 'colsample_bytree': 0.6}\n",
      "Best Cross-Validation Spearman Correlation: 0.47616913325451443\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002376 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25948\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 105\n",
      "[LightGBM] [Info] Start training from score 0.520791\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[311]\tvalid_0's rmse: 0.735006\tvalid_0's l2: 0.540234\n",
      "Validation Spearman Correlation: 0.43094915463586375\n",
      "Sample submission file 'denilmaldonado3.csv' generated successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from lightgbm import LGBMRegressor\n",
    "from scipy.stats import spearmanr\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# --- Load Dataset ---\n",
    "train_data = pd.read_csv(\"train.csv\")  # Format: id, text, score\n",
    "val_data = pd.read_csv(\"val.csv\")      # Format: id, text, score\n",
    "test_data = pd.read_csv(\"test.csv\")    # Format: id, text\n",
    "\n",
    "# --- Define Spearman Correlation Metric ---\n",
    "def spearman_correlation(y_true, y_pred):\n",
    "    return spearmanr(y_true, y_pred).correlation\n",
    "\n",
    "spearman_scorer = make_scorer(spearman_correlation, greater_is_better=True)\n",
    "\n",
    "# --- Word2Vec Training ---\n",
    "# Tokenize text\n",
    "train_sentences = train_data[\"text\"].apply(lambda x: x.split())\n",
    "val_sentences = val_data[\"text\"].apply(lambda x: x.split())\n",
    "test_sentences = test_data[\"text\"].apply(lambda x: x.split())\n",
    "\n",
    "# Train Word2Vec on training sentences\n",
    "word2vec_model = Word2Vec(sentences=train_sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Generate sentence embeddings\n",
    "def get_sentence_embedding(sentences, model, vector_size):\n",
    "    embeddings = []\n",
    "    for sentence in sentences:\n",
    "        vectors = [model.wv[word] for word in sentence if word in model.wv]\n",
    "        if vectors:\n",
    "            embeddings.append(np.mean(vectors, axis=0))\n",
    "        else:\n",
    "            embeddings.append(np.zeros(vector_size))  # Handle empty sentences\n",
    "    return np.array(embeddings)\n",
    "\n",
    "# Generate embeddings for train, validation, and test sets\n",
    "X_train_embeddings = get_sentence_embedding(train_sentences, word2vec_model, vector_size=100)\n",
    "y_train = train_data[\"score\"]\n",
    "\n",
    "X_val_embeddings = get_sentence_embedding(val_sentences, word2vec_model, vector_size=100)\n",
    "y_val = val_data[\"score\"]\n",
    "\n",
    "X_test_embeddings = get_sentence_embedding(test_sentences, word2vec_model, vector_size=100)\n",
    "\n",
    "# --- Feature Engineering ---\n",
    "def extract_features(df):\n",
    "    df[\"sentence_length\"] = df[\"text\"].apply(len)\n",
    "    df[\"word_count\"] = df[\"text\"].apply(lambda x: len(x.split()))\n",
    "    df[\"avg_word_length\"] = df[\"text\"].apply(lambda x: np.mean([len(word) for word in x.split()]) if x.split() else 0)\n",
    "    df[\"punctuation_count\"] = df[\"text\"].str.count(r\"[^\\w\\s]\")\n",
    "    df[\"type_token_ratio\"] = df[\"text\"].apply(lambda x: len(set(x.split())) / (len(x.split()) + 1e-5))\n",
    "    return df[[\"sentence_length\", \"word_count\", \"avg_word_length\", \"punctuation_count\", \"type_token_ratio\"]]\n",
    "\n",
    "# Combine embeddings with additional features\n",
    "X_train_features = extract_features(train_data).values\n",
    "X_val_features = extract_features(val_data).values\n",
    "X_test_features = extract_features(test_data).values\n",
    "\n",
    "X_train = np.hstack((X_train_embeddings, X_train_features))\n",
    "X_val = np.hstack((X_val_embeddings, X_val_features))\n",
    "X_test = np.hstack((X_test_embeddings, X_test_features))\n",
    "\n",
    "# --- Hyperparameter Tuning ---\n",
    "# Define parameter grid\n",
    "param_dist = {\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"n_estimators\": [500, 1000, 2000],\n",
    "    \"num_leaves\": [20, 31, 50],\n",
    "    \"max_depth\": [-1, 5, 10],\n",
    "    \"min_child_samples\": [10, 20, 50],\n",
    "    \"subsample\": [0.6, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "}\n",
    "\n",
    "# Initialize LightGBM\n",
    "lgb_model = LGBMRegressor(random_state=42)\n",
    "\n",
    "# Perform Randomized Search\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=lgb_model,\n",
    "    param_distributions=param_dist,\n",
    "    scoring=spearman_scorer,\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    n_iter=50,  # Try 50 parameter combinations\n",
    "    verbose=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit random search on training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best Cross-Validation Spearman Correlation:\", random_search.best_score_)\n",
    "\n",
    "# --- Train Final Model ---\n",
    "best_model = random_search.best_estimator_\n",
    "from lightgbm import early_stopping\n",
    "\n",
    "# Train the final model with callbacks\n",
    "callbacks = [early_stopping(stopping_rounds=50, verbose=True)]\n",
    "best_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric=\"rmse\", callbacks=callbacks)\n",
    "\n",
    "\n",
    "# --- Evaluate on Validation Set ---\n",
    "y_val_pred = best_model.predict(X_val)\n",
    "val_spearman_corr = spearman_correlation(y_val, y_val_pred)\n",
    "print(\"Validation Spearman Correlation:\", val_spearman_corr)\n",
    "\n",
    "# --- Generate Predictions for Test Set ---\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# --- Create Sample Submission ---\n",
    "submission = pd.DataFrame({\"id\": test_data[\"id\"], \"score\": y_test_pred})\n",
    "submission.to_csv(\"denilmaldonado3.csv\", index=False)\n",
    "print(\"Sample submission file 'denilmaldonado3.csv' generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002766 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25948\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 105\n",
      "[LightGBM] [Info] Start training from score 0.520791\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': -1, 'min_child_samples': 30, 'n_estimators': 400, 'num_leaves': 25}\n",
      "Best Cross-Validation Spearman Correlation: 0.48207519039368596\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25948\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 105\n",
      "[LightGBM] [Info] Start training from score 0.520791\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[328]\tvalid_0's rmse: 0.728112\tvalid_0's l2: 0.530148\n",
      "Validation Spearman Correlation: 0.4535051306763876\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample submission file 'luisparadela7.csv' generated successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from lightgbm import LGBMRegressor, plot_importance, early_stopping\n",
    "from scipy.stats import spearmanr\n",
    "from gensim.models import Word2Vec\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Load Dataset ---\n",
    "train_data = pd.read_csv(\"train.csv\")  # Format: id, text, score\n",
    "val_data = pd.read_csv(\"val.csv\")      # Format: id, text, score\n",
    "test_data = pd.read_csv(\"test.csv\")    # Format: id, text\n",
    "\n",
    "# --- Define Spearman Correlation Metric ---\n",
    "def spearman_correlation(y_true, y_pred):\n",
    "    return spearmanr(y_true, y_pred).correlation\n",
    "\n",
    "spearman_scorer = make_scorer(spearman_correlation, greater_is_better=True)\n",
    "\n",
    "# --- Word2Vec Training ---\n",
    "# Tokenize text\n",
    "train_sentences = train_data[\"text\"].apply(lambda x: x.split())\n",
    "val_sentences = val_data[\"text\"].apply(lambda x: x.split())\n",
    "test_sentences = test_data[\"text\"].apply(lambda x: x.split())\n",
    "\n",
    "# Train Word2Vec on training sentences\n",
    "word2vec_model = Word2Vec(sentences=train_sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Generate sentence embeddings\n",
    "def get_sentence_embedding(sentences, model, vector_size):\n",
    "    embeddings = []\n",
    "    for sentence in sentences:\n",
    "        vectors = [model.wv[word] for word in sentence if word in model.wv]\n",
    "        if vectors:\n",
    "            embeddings.append(np.mean(vectors, axis=0))\n",
    "        else:\n",
    "            embeddings.append(np.zeros(vector_size))  # Handle empty sentences\n",
    "    return np.array(embeddings)\n",
    "\n",
    "# Generate embeddings for train, validation, and test sets\n",
    "X_train_embeddings = get_sentence_embedding(train_sentences, word2vec_model, vector_size=100)\n",
    "y_train = train_data[\"score\"]\n",
    "\n",
    "X_val_embeddings = get_sentence_embedding(val_sentences, word2vec_model, vector_size=100)\n",
    "y_val = val_data[\"score\"]\n",
    "\n",
    "X_test_embeddings = get_sentence_embedding(test_sentences, word2vec_model, vector_size=100)\n",
    "\n",
    "# --- Feature Engineering ---\n",
    "def extract_features(df):\n",
    "    df[\"sentence_length\"] = df[\"text\"].apply(len)\n",
    "    df[\"word_count\"] = df[\"text\"].apply(lambda x: len(x.split()))\n",
    "    df[\"avg_word_length\"] = df[\"text\"].apply(lambda x: np.mean([len(word) for word in x.split()]) if x.split() else 0)\n",
    "    df[\"punctuation_count\"] = df[\"text\"].str.count(r\"[^\\w\\s]\")\n",
    "    df[\"type_token_ratio\"] = df[\"text\"].apply(lambda x: len(set(x.split())) / (len(x.split()) + 1e-5))\n",
    "    return df[[\"sentence_length\", \"word_count\", \"avg_word_length\", \"punctuation_count\", \"type_token_ratio\"]]\n",
    "\n",
    "# Combine embeddings with additional features\n",
    "X_train_features = extract_features(train_data).values\n",
    "X_val_features = extract_features(val_data).values\n",
    "X_test_features = extract_features(test_data).values\n",
    "\n",
    "X_train = np.hstack((X_train_embeddings, X_train_features))\n",
    "X_val = np.hstack((X_val_embeddings, X_val_features))\n",
    "X_test = np.hstack((X_test_embeddings, X_test_features))\n",
    "\n",
    "# --- Fine-Tuning with GridSearchCV ---\n",
    "param_grid = {\n",
    "    \"learning_rate\": [0.005, 0.01, 0.02],\n",
    "    \"n_estimators\": [300, 400, 500],\n",
    "    \"num_leaves\": [15, 20, 25],\n",
    "    \"max_depth\": [-1, 5, 10],\n",
    "    \"min_child_samples\": [10, 20, 30],\n",
    "}\n",
    "\n",
    "# Initialize LightGBM\n",
    "lgb_model = LGBMRegressor(random_state=42)\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=lgb_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=spearman_scorer,\n",
    "    cv=3,\n",
    "    verbose=10,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit grid search on training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Spearman Correlation:\", grid_search.best_score_)\n",
    "\n",
    "# --- Train Final Model ---\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Train with callbacks for early stopping\n",
    "callbacks = [early_stopping(stopping_rounds=50, verbose=True)]\n",
    "best_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric=\"rmse\", callbacks=callbacks)\n",
    "\n",
    "# --- Evaluate on Validation Set ---\n",
    "y_val_pred = best_model.predict(X_val)\n",
    "val_spearman_corr = spearman_correlation(y_val, y_val_pred)\n",
    "print(\"Validation Spearman Correlation:\", val_spearman_corr)\n",
    "\n",
    "# --- Feature Importance ---\n",
    "plot_importance(best_model, max_num_features=20, importance_type=\"gain\", figsize=(10, 6))\n",
    "plt.title(\"Top 20 Feature Importances\")\n",
    "plt.show()\n",
    "\n",
    "# --- Generate Predictions for Test Set ---\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# --- Create Sample Submission ---\n",
    "submission = pd.DataFrame({\"id\": test_data[\"id\"], \"score\": y_test_pred})\n",
    "submission.to_csv(\"luisparadela7.csv\", index=False)\n",
    "print(\"Sample submission file 'luisparadela7.csv' generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 41455\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 1176\n",
      "[LightGBM] [Info] Start training from score 0.520791\n",
      "Best Parameters: {'learning_rate': 0.05, 'max_depth': -1, 'min_child_samples': 10, 'n_estimators': 300, 'num_leaves': 25}\n",
      "Best Cross-Validation Spearman Correlation: 0.5590686103261056\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014202 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 41455\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 1176\n",
      "[LightGBM] [Info] Start training from score 0.520791\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[270]\tvalid_0's rmse: 0.662367\tvalid_0's l2: 0.43873\n",
      "Validation Spearman Correlation: 0.583405980814418\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample submission file 'takutooshima8.csv' generated successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from lightgbm import LGBMRegressor, plot_importance\n",
    "from scipy.stats import spearmanr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Load Dataset ---\n",
    "train_data = pd.read_csv(\"train.csv\")  # Format: id, text, score\n",
    "val_data = pd.read_csv(\"val.csv\")      # Format: id, text, score\n",
    "test_data = pd.read_csv(\"test.csv\")    # Format: id, text\n",
    "\n",
    "# --- Define Spearman Correlation Metric ---\n",
    "def spearman_correlation(y_true, y_pred):\n",
    "    return spearmanr(y_true, y_pred).correlation\n",
    "\n",
    "spearman_scorer = make_scorer(spearman_correlation, greater_is_better=True)\n",
    "\n",
    "# --- TF-IDF Features ---\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=5000,  # Limit the number of features\n",
    "    ngram_range=(1, 2),  # Use unigrams and bigrams\n",
    "    stop_words=\"english\"  # Remove common stopwords\n",
    ")\n",
    "\n",
    "# Fit TF-IDF on the training text\n",
    "X_train_tfidf = tfidf.fit_transform(train_data[\"text\"]).toarray()\n",
    "X_val_tfidf = tfidf.transform(val_data[\"text\"]).toarray()\n",
    "X_test_tfidf = tfidf.transform(test_data[\"text\"]).toarray()\n",
    "\n",
    "# --- Word2Vec Training ---\n",
    "train_sentences = train_data[\"text\"].apply(lambda x: x.split())\n",
    "val_sentences = val_data[\"text\"].apply(lambda x: x.split())\n",
    "test_sentences = test_data[\"text\"].apply(lambda x: x.split())\n",
    "\n",
    "# Train Word2Vec on training sentences\n",
    "word2vec_model = Word2Vec(sentences=train_sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Generate sentence embeddings\n",
    "def get_sentence_embedding(sentences, model, vector_size):\n",
    "    embeddings = []\n",
    "    for sentence in sentences:\n",
    "        vectors = [model.wv[word] for word in sentence if word in model.wv]\n",
    "        if vectors:\n",
    "            embeddings.append(np.mean(vectors, axis=0))\n",
    "        else:\n",
    "            embeddings.append(np.zeros(vector_size))  # Handle empty sentences\n",
    "    return np.array(embeddings)\n",
    "\n",
    "X_train_word2vec = get_sentence_embedding(train_sentences, word2vec_model, vector_size=100)\n",
    "X_val_word2vec = get_sentence_embedding(val_sentences, word2vec_model, vector_size=100)\n",
    "X_test_word2vec = get_sentence_embedding(test_sentences, word2vec_model, vector_size=100)\n",
    "\n",
    "# --- Combine TF-IDF and Word2Vec ---\n",
    "X_train = np.hstack((X_train_tfidf, X_train_word2vec))\n",
    "X_val = np.hstack((X_val_tfidf, X_val_word2vec))\n",
    "X_test = np.hstack((X_test_tfidf, X_test_word2vec))\n",
    "y_train = train_data[\"score\"]\n",
    "y_val = val_data[\"score\"]\n",
    "\n",
    "# --- LightGBM Model ---\n",
    "param_grid = {\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"n_estimators\": [300, 400, 500],\n",
    "    \"num_leaves\": [20, 25, 30],\n",
    "    \"max_depth\": [-1, 5, 10],\n",
    "    \"min_child_samples\": [10, 20, 30],\n",
    "}\n",
    "\n",
    "lgb_model = LGBMRegressor(random_state=42)\n",
    "\n",
    "# Grid search for hyperparameter tuning\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=lgb_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=spearman_scorer,\n",
    "    cv=3,\n",
    "    verbose=10,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model and parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Spearman Correlation:\", grid_search.best_score_)\n",
    "\n",
    "# Train final model\n",
    "best_model = grid_search.best_estimator_\n",
    "callbacks = [early_stopping(stopping_rounds=50, verbose=True)]\n",
    "best_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric=\"rmse\", callbacks=callbacks)\n",
    "\n",
    "# --- Evaluate on Validation Set ---\n",
    "y_val_pred = best_model.predict(X_val)\n",
    "val_spearman_corr = spearman_correlation(y_val, y_val_pred)\n",
    "print(\"Validation Spearman Correlation:\", val_spearman_corr)\n",
    "\n",
    "# --- Feature Importance ---\n",
    "plot_importance(best_model, max_num_features=20, importance_type=\"gain\", figsize=(10, 6))\n",
    "plt.title(\"Top 20 Feature Importances\")\n",
    "plt.show()\n",
    "\n",
    "# --- Generate Predictions for Test Set ---\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# --- Create Sample Submission ---\n",
    "submission = pd.DataFrame({\"id\": test_data[\"id\"], \"score\": y_test_pred})\n",
    "submission.to_csv(\"takutooshima8.csv\", index=False)\n",
    "print(\"Sample submission file 'takutooshima8.csv' generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from xgboost) (1.26.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from xgboost) (1.11.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\RoG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 38137\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 615\n",
      "[LightGBM] [Info] Start training from score 0.520791\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[399]\tvalid_0's rmse: 0.670495\tvalid_0's l2: 0.449563\n",
      "[0]\tvalidation-rmse:0.81379\n",
      "[10]\tvalidation-rmse:0.79724\n",
      "[20]\tvalidation-rmse:0.78368\n",
      "[30]\tvalidation-rmse:0.77225\n",
      "[40]\tvalidation-rmse:0.76088\n",
      "[50]\tvalidation-rmse:0.75114\n",
      "[60]\tvalidation-rmse:0.74358\n",
      "[70]\tvalidation-rmse:0.73619\n",
      "[80]\tvalidation-rmse:0.73016\n",
      "[90]\tvalidation-rmse:0.72512\n",
      "[100]\tvalidation-rmse:0.72061\n",
      "[110]\tvalidation-rmse:0.71648\n",
      "[120]\tvalidation-rmse:0.71290\n",
      "[130]\tvalidation-rmse:0.71019\n",
      "[140]\tvalidation-rmse:0.70770\n",
      "[150]\tvalidation-rmse:0.70574\n",
      "[160]\tvalidation-rmse:0.70358\n",
      "[170]\tvalidation-rmse:0.70119\n",
      "[180]\tvalidation-rmse:0.69853\n",
      "[190]\tvalidation-rmse:0.69622\n",
      "[200]\tvalidation-rmse:0.69420\n",
      "[210]\tvalidation-rmse:0.69306\n",
      "[220]\tvalidation-rmse:0.69201\n",
      "[230]\tvalidation-rmse:0.69105\n",
      "[240]\tvalidation-rmse:0.68995\n",
      "[250]\tvalidation-rmse:0.68875\n",
      "[260]\tvalidation-rmse:0.68802\n",
      "[270]\tvalidation-rmse:0.68730\n",
      "[280]\tvalidation-rmse:0.68640\n",
      "[290]\tvalidation-rmse:0.68583\n",
      "[300]\tvalidation-rmse:0.68517\n",
      "[310]\tvalidation-rmse:0.68436\n",
      "[320]\tvalidation-rmse:0.68353\n",
      "[330]\tvalidation-rmse:0.68290\n",
      "[340]\tvalidation-rmse:0.68209\n",
      "[350]\tvalidation-rmse:0.68158\n",
      "[360]\tvalidation-rmse:0.68111\n",
      "[370]\tvalidation-rmse:0.68066\n",
      "[380]\tvalidation-rmse:0.68021\n",
      "[390]\tvalidation-rmse:0.67975\n",
      "[399]\tvalidation-rmse:0.67928\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011650 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 38137\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 615\n",
      "[LightGBM] [Info] Start training from score 0.520791\n",
      "Validation Spearman Correlation (Ensemble): 0.5665060582323109\n",
      "Sample submission file 'vladimirscreciu6.csv' generated successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics import make_scorer\n",
    "from lightgbm import LGBMRegressor, early_stopping\n",
    "import xgboost as xgb\n",
    "from scipy.stats import spearmanr\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# --- Load Dataset ---\n",
    "train_data = pd.read_csv(\"train.csv\")  # Format: id, text, score\n",
    "val_data = pd.read_csv(\"val.csv\")      # Format: id, text, score\n",
    "test_data = pd.read_csv(\"test.csv\")    # Format: id, text\n",
    "\n",
    "# --- Define Spearman Correlation Metric ---\n",
    "def spearman_correlation(y_true, y_pred):\n",
    "    return spearmanr(y_true, y_pred).correlation\n",
    "\n",
    "# --- Preprocessing ---\n",
    "def preprocess_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove stopwords\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    return text\n",
    "\n",
    "train_data[\"cleaned_text\"] = train_data[\"text\"].apply(preprocess_text)\n",
    "val_data[\"cleaned_text\"] = val_data[\"text\"].apply(preprocess_text)\n",
    "test_data[\"cleaned_text\"] = test_data[\"text\"].apply(preprocess_text)\n",
    "\n",
    "# --- TF-IDF Features ---\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words=\"english\"\n",
    ")\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(train_data[\"cleaned_text\"]).toarray()\n",
    "X_val_tfidf = tfidf.transform(val_data[\"cleaned_text\"]).toarray()\n",
    "X_test_tfidf = tfidf.transform(test_data[\"cleaned_text\"]).toarray()\n",
    "\n",
    "# --- Word2Vec Training ---\n",
    "train_sentences = train_data[\"cleaned_text\"].apply(lambda x: x.split())\n",
    "val_sentences = val_data[\"cleaned_text\"].apply(lambda x: x.split())\n",
    "test_sentences = test_data[\"cleaned_text\"].apply(lambda x: x.split())\n",
    "\n",
    "word2vec_model = Word2Vec(sentences=train_sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "def get_sentence_embedding(sentences, model, vector_size):\n",
    "    embeddings = []\n",
    "    for sentence in sentences:\n",
    "        vectors = [model.wv[word] for word in sentence if word in model.wv]\n",
    "        if vectors:\n",
    "            embeddings.append(np.mean(vectors, axis=0))\n",
    "        else:\n",
    "            embeddings.append(np.zeros(vector_size))\n",
    "    return np.array(embeddings)\n",
    "\n",
    "X_train_word2vec = get_sentence_embedding(train_sentences, word2vec_model, vector_size=100)\n",
    "X_val_word2vec = get_sentence_embedding(val_sentences, word2vec_model, vector_size=100)\n",
    "X_test_word2vec = get_sentence_embedding(test_sentences, word2vec_model, vector_size=100)\n",
    "\n",
    "# --- Combine Features ---\n",
    "X_train = np.hstack((X_train_tfidf, X_train_word2vec))\n",
    "X_val = np.hstack((X_val_tfidf, X_val_word2vec))\n",
    "X_test = np.hstack((X_test_tfidf, X_test_word2vec))\n",
    "y_train = train_data[\"score\"]\n",
    "y_val = val_data[\"score\"]\n",
    "\n",
    "# --- LightGBM ---\n",
    "lgb_model = LGBMRegressor(n_estimators=400, learning_rate=0.01, max_depth=-1, num_leaves=25, random_state=42)\n",
    "lgb_callbacks = [early_stopping(stopping_rounds=50, verbose=True)]\n",
    "lgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric=\"rmse\", callbacks=lgb_callbacks)\n",
    "\n",
    "# --- XGBoost with DMatrix ---\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "xgb_params = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"eval_metric\": \"rmse\",\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"max_depth\": 6,\n",
    "    \"seed\": 42,\n",
    "}\n",
    "\n",
    "xgb_booster = xgb.train(\n",
    "    params=xgb_params,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=400,\n",
    "    evals=[(dval, \"validation\")],\n",
    "    early_stopping_rounds=50,\n",
    "    verbose_eval=10\n",
    ")\n",
    "\n",
    "# --- Generate Predictions for Test Set ---\n",
    "xgb_model = xgb.XGBRegressor(**xgb_params, n_estimators=xgb_booster.best_iteration)\n",
    "\n",
    "# --- Ensemble with Voting Regressor ---\n",
    "ensemble = VotingRegressor([('lightgbm', lgb_model), ('xgboost', xgb_model)])\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "# --- Evaluate on Validation Set ---\n",
    "y_val_pred = ensemble.predict(X_val)\n",
    "val_spearman_corr = spearman_correlation(y_val, y_val_pred)\n",
    "print(\"Validation Spearman Correlation (Ensemble):\", val_spearman_corr)\n",
    "\n",
    "# --- Generate Predictions for Test Set ---\n",
    "y_test_pred = ensemble.predict(X_test)\n",
    "\n",
    "# --- Create Sample Submission ---\n",
    "submission = pd.DataFrame({\"id\": test_data[\"id\"], \"score\": y_test_pred})\n",
    "submission.to_csv(\"vladimirscreciu6.csv\", index=False)\n",
    "print(\"Sample submission file 'vladimirscreciu6.csv' generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\RoG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "5 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\sklearn.py\", line 1081, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\sklearn.py\", line 596, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\sklearn.py\", line 1003, in _create_dmatrix\n",
      "    return QuantileDMatrix(\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 1573, in __init__\n",
      "    self._init(\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 1632, in _init\n",
      "    it.reraise()\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 569, in reraise\n",
      "    raise exc  # pylint: disable=raising-bad-type\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 550, in _handle_exception\n",
      "    return fn()\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 637, in <lambda>\n",
      "    return self._handle_exception(lambda: self.next(input_data), 0)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\data.py\", line 1402, in next\n",
      "    input_data(**self.kwargs)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 626, in input_data\n",
      "    self.proxy.set_info(\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 954, in set_info\n",
      "    self.set_label(label)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 1092, in set_label\n",
      "    dispatch_meta_backend(self, label, \"label\", \"float\")\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\data.py\", line 1348, in dispatch_meta_backend\n",
      "    _meta_from_pandas_series(data, name, dtype, handle)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\data.py\", line 679, in _meta_from_pandas_series\n",
      "    _meta_from_numpy(data, name, dtype, handle)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\data.py\", line 1279, in _meta_from_numpy\n",
      "    _check_call(_LIB.XGDMatrixSetInfoFromInterface(handle, c_str(field), interface_str))\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [02:18:48] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\data\\array_interface.cu:44: Check failed: err == cudaGetLastError() (0 vs. 2) : \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\sklearn.py\", line 1081, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\sklearn.py\", line 596, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\sklearn.py\", line 1003, in _create_dmatrix\n",
      "    return QuantileDMatrix(\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 1573, in __init__\n",
      "    self._init(\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 1632, in _init\n",
      "    it.reraise()\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 569, in reraise\n",
      "    raise exc  # pylint: disable=raising-bad-type\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 550, in _handle_exception\n",
      "    return fn()\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 637, in <lambda>\n",
      "    return self._handle_exception(lambda: self.next(input_data), 0)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\data.py\", line 1402, in next\n",
      "    input_data(**self.kwargs)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 626, in input_data\n",
      "    self.proxy.set_info(\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 954, in set_info\n",
      "    self.set_label(label)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 1092, in set_label\n",
      "    dispatch_meta_backend(self, label, \"label\", \"float\")\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\data.py\", line 1348, in dispatch_meta_backend\n",
      "    _meta_from_pandas_series(data, name, dtype, handle)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\data.py\", line 679, in _meta_from_pandas_series\n",
      "    _meta_from_numpy(data, name, dtype, handle)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\data.py\", line 1279, in _meta_from_numpy\n",
      "    _check_call(_LIB.XGDMatrixSetInfoFromInterface(handle, c_str(field), interface_str))\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [02:18:38] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\data\\array_interface.cu:44: Check failed: err == cudaGetLastError() (0 vs. 2) : \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\sklearn.py\", line 1081, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\sklearn.py\", line 596, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\sklearn.py\", line 1003, in _create_dmatrix\n",
      "    return QuantileDMatrix(\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 1573, in __init__\n",
      "    self._init(\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 1632, in _init\n",
      "    it.reraise()\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 569, in reraise\n",
      "    raise exc  # pylint: disable=raising-bad-type\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 550, in _handle_exception\n",
      "    return fn()\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 637, in <lambda>\n",
      "    return self._handle_exception(lambda: self.next(input_data), 0)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\data.py\", line 1402, in next\n",
      "    input_data(**self.kwargs)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 626, in input_data\n",
      "    self.proxy.set_info(\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 954, in set_info\n",
      "    self.set_label(label)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 1092, in set_label\n",
      "    dispatch_meta_backend(self, label, \"label\", \"float\")\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\data.py\", line 1348, in dispatch_meta_backend\n",
      "    _meta_from_pandas_series(data, name, dtype, handle)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\data.py\", line 679, in _meta_from_pandas_series\n",
      "    _meta_from_numpy(data, name, dtype, handle)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\data.py\", line 1279, in _meta_from_numpy\n",
      "    _check_call(_LIB.XGDMatrixSetInfoFromInterface(handle, c_str(field), interface_str))\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [02:18:39] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\data\\array_interface.cu:44: Check failed: err == cudaGetLastError() (0 vs. 2) : \n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan 0.50502653 0.55029289\n",
      " 0.53618265 0.5047111  0.52466171 0.50224565 0.5398629  0.53434448\n",
      " 0.55633716 0.54959146 0.51146935 0.54739998 0.52934903 0.50883698\n",
      " 0.52400702 0.50646186 0.51900829 0.53025626 0.54495495 0.53453782\n",
      " 0.5095954  0.5356675  0.51921286 0.53863706 0.53016183 0.49684594\n",
      " 0.5418166  0.52664493 0.54138843 0.4783482  0.53079228 0.54314658\n",
      " 0.50259908 0.54138724 0.5515862  0.53990081 0.54787461 0.47830508\n",
      " 0.50486065 0.53836252 0.54457027 0.54053082 0.54780792 0.53359414\n",
      " 0.55319479 0.55325099]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'subsample': 1.0, 'reg_lambda': 0.5, 'reg_alpha': 0.1, 'n_estimators': 500, 'min_child_weight': 5, 'max_depth': 3, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 0.6}\n",
      "Best Cross-Validation Spearman Correlation: 0.5563371560940552\n",
      "Validation Spearman Correlation (XGBoost): 0.5786603943358029\n",
      "Sample submission file 'stefanvladoiu2.csv' generated successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.stats import spearmanr\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# --- Load Dataset ---\n",
    "train_data = pd.read_csv(\"train.csv\")  # Format: id, text, score\n",
    "val_data = pd.read_csv(\"val.csv\")      # Format: id, text, score\n",
    "test_data = pd.read_csv(\"test.csv\")    # Format: id, text\n",
    "\n",
    "# --- Define Spearman Correlation Metric ---\n",
    "def spearman_correlation(y_true, y_pred):\n",
    "    return spearmanr(y_true, y_pred).correlation\n",
    "\n",
    "# --- Preprocessing ---\n",
    "def preprocess_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove stopwords\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    return text\n",
    "\n",
    "train_data[\"cleaned_text\"] = train_data[\"text\"].apply(preprocess_text)\n",
    "val_data[\"cleaned_text\"] = val_data[\"text\"].apply(preprocess_text)\n",
    "test_data[\"cleaned_text\"] = test_data[\"text\"].apply(preprocess_text)\n",
    "\n",
    "# --- TF-IDF Features ---\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words=\"english\"\n",
    ")\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(train_data[\"cleaned_text\"]).toarray()\n",
    "X_val_tfidf = tfidf.transform(val_data[\"cleaned_text\"]).toarray()\n",
    "X_test_tfidf = tfidf.transform(test_data[\"cleaned_text\"]).toarray()\n",
    "\n",
    "# --- Word2Vec Training ---\n",
    "train_sentences = train_data[\"cleaned_text\"].apply(lambda x: x.split())\n",
    "val_sentences = val_data[\"cleaned_text\"].apply(lambda x: x.split())\n",
    "test_sentences = test_data[\"cleaned_text\"].apply(lambda x: x.split())\n",
    "\n",
    "word2vec_model = Word2Vec(sentences=train_sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "def get_sentence_embedding(sentences, model, vector_size):\n",
    "    embeddings = []\n",
    "    for sentence in sentences:\n",
    "        vectors = [model.wv[word] for word in sentence if word in model.wv]\n",
    "        if vectors:\n",
    "            embeddings.append(np.mean(vectors, axis=0))\n",
    "        else:\n",
    "            embeddings.append(np.zeros(vector_size))\n",
    "    return np.array(embeddings)\n",
    "\n",
    "X_train_word2vec = get_sentence_embedding(train_sentences, word2vec_model, vector_size=100)\n",
    "X_val_word2vec = get_sentence_embedding(val_sentences, word2vec_model, vector_size=100)\n",
    "X_test_word2vec = get_sentence_embedding(test_sentences, word2vec_model, vector_size=100)\n",
    "\n",
    "# --- Combine Features ---\n",
    "X_train = np.hstack((X_train_tfidf, X_train_word2vec))\n",
    "X_val = np.hstack((X_val_tfidf, X_val_word2vec))\n",
    "X_test = np.hstack((X_test_tfidf, X_test_word2vec))\n",
    "y_train = train_data[\"score\"]\n",
    "y_val = val_data[\"score\"]\n",
    "\n",
    "# --- Hyperparameter Tuning for XGBoost ---\n",
    "param_dist = {\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"n_estimators\": [100, 300, 500],\n",
    "    \"max_depth\": [3, 6, 10],\n",
    "    \"min_child_weight\": [1, 3, 5],\n",
    "    \"subsample\": [0.6, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "    \"gamma\": [0, 0.1, 0.2],\n",
    "    \"reg_alpha\": [0, 0.1, 1],\n",
    "    \"reg_lambda\": [0.5, 1, 2],\n",
    "}\n",
    "\n",
    "xgb_model = XGBRegressor(objective=\"reg:squarederror\", random_state=42)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,\n",
    "    scoring=make_scorer(spearman_correlation),\n",
    "    cv=3,\n",
    "    verbose=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best Parameters and Model\n",
    "best_xgb_model = random_search.best_estimator_\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best Cross-Validation Spearman Correlation:\", random_search.best_score_)\n",
    "\n",
    "# --- Evaluate on Validation Set ---\n",
    "y_val_pred = best_xgb_model.predict(X_val)\n",
    "val_spearman_corr = spearman_correlation(y_val, y_val_pred)\n",
    "print(\"Validation Spearman Correlation (XGBoost):\", val_spearman_corr)\n",
    "\n",
    "# --- Generate Predictions for Test Set ---\n",
    "y_test_pred = best_xgb_model.predict(X_test)\n",
    "\n",
    "# --- Create Sample Submission ---\n",
    "submission = pd.DataFrame({\"id\": test_data[\"id\"], \"score\": y_test_pred})\n",
    "submission.to_csv(\"stefanvladoiu2.csv\", index=False)\n",
    "print(\"Sample submission file 'stefanvladoiu2.csv' generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from optuna) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from optuna) (23.2)\n",
      "Collecting sqlalchemy>=1.4.2 (from optuna)\n",
      "  Downloading SQLAlchemy-2.0.36-cp310-cp310-win_amd64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from optuna) (4.66.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from optuna) (6.0.1)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading Mako-1.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.8.0)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy>=1.4.2->optuna)\n",
      "  Downloading greenlet-3.1.1-cp310-cp310-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
      "Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n",
      "   ---------------------------------------- 0.0/364.4 kB ? eta -:--:--\n",
      "   -------- ------------------------------- 81.9/364.4 kB 1.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 276.5/364.4 kB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 364.4/364.4 kB 3.2 MB/s eta 0:00:00\n",
      "Downloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
      "   ---------------------------------------- 0.0/233.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 233.5/233.5 kB ? eta 0:00:00\n",
      "Downloading SQLAlchemy-2.0.36-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.1 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.0/2.1 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 16.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 14.8 MB/s eta 0:00:00\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading greenlet-3.1.1-cp310-cp310-win_amd64.whl (298 kB)\n",
      "   ---------------------------------------- 0.0/298.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 298.4/298.4 kB 19.2 MB/s eta 0:00:00\n",
      "Downloading Mako-1.3.6-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.6/78.6 kB ? eta 0:00:00\n",
      "Installing collected packages: Mako, greenlet, colorlog, sqlalchemy, alembic, optuna\n",
      "Successfully installed Mako-1.3.6 alembic-1.14.0 colorlog-6.9.0 greenlet-3.1.1 optuna-4.1.0 sqlalchemy-2.0.36\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna-integration[xgboost]\n",
      "  Downloading optuna_integration-4.1.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: optuna in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from optuna-integration[xgboost]) (4.1.0)\n",
      "Requirement already satisfied: xgboost in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from optuna-integration[xgboost]) (2.1.3)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from optuna->optuna-integration[xgboost]) (1.14.0)\n",
      "Requirement already satisfied: colorlog in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from optuna->optuna-integration[xgboost]) (6.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from optuna->optuna-integration[xgboost]) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from optuna->optuna-integration[xgboost]) (23.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from optuna->optuna-integration[xgboost]) (2.0.36)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from optuna->optuna-integration[xgboost]) (4.66.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from optuna->optuna-integration[xgboost]) (6.0.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from xgboost->optuna-integration[xgboost]) (1.11.4)\n",
      "Requirement already satisfied: Mako in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from alembic>=1.5.0->optuna->optuna-integration[xgboost]) (1.3.6)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from alembic>=1.5.0->optuna->optuna-integration[xgboost]) (4.8.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna->optuna-integration[xgboost]) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from colorlog->optuna->optuna-integration[xgboost]) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna->optuna-integration[xgboost]) (2.1.5)\n",
      "Downloading optuna_integration-4.1.0-py3-none-any.whl (97 kB)\n",
      "   ---------------------------------------- 0.0/97.4 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 10.2/97.4 kB ? eta -:--:--\n",
      "   ------------------------- -------------- 61.4/97.4 kB 825.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 97.4/97.4 kB 937.6 kB/s eta 0:00:00\n",
      "Installing collected packages: optuna-integration\n",
      "Successfully installed optuna-integration-4.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna-integration[xgboost]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\RoG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-03 03:03:48,752] A new study created in memory with name: no-name-8b7c34cb-47d6-46a2-8a6b-ca35c39a3c49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearch Best Parameters: {'subsample': 0.7, 'reg_lambda': 1.5, 'reg_alpha': 0, 'n_estimators': 300, 'min_child_weight': 1, 'max_depth': 6, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
      "RandomizedSearch Best CV Spearman Correlation: 0.5517844442063895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RoG\\AppData\\Local\\Temp\\ipykernel_14836\\1783825230.py:114: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1),\n",
      "C:\\Users\\RoG\\AppData\\Local\\Temp\\ipykernel_14836\\1783825230.py:117: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.6, 0.9),\n",
      "C:\\Users\\RoG\\AppData\\Local\\Temp\\ipykernel_14836\\1783825230.py:118: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.6, 0.9),\n",
      "C:\\Users\\RoG\\AppData\\Local\\Temp\\ipykernel_14836\\1783825230.py:119: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gamma\": trial.suggest_uniform(\"gamma\", 0, 0.3),\n",
      "C:\\Users\\RoG\\AppData\\Local\\Temp\\ipykernel_14836\\1783825230.py:120: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1),\n",
      "C:\\Users\\RoG\\AppData\\Local\\Temp\\ipykernel_14836\\1783825230.py:121: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.1, 2),\n",
      "[I 2024-12-03 03:04:14,171] Trial 0 finished with value: 0.5708533799971193 and parameters: {'learning_rate': 0.042522673602762566, 'max_depth': 10, 'min_child_weight': 4, 'subsample': 0.7614680284365771, 'colsample_bytree': 0.7924917561442117, 'gamma': 0.003828355269131511, 'reg_alpha': 0.10391036268798362, 'reg_lambda': 0.13601886083121068}. Best is trial 0 with value: 0.5708533799971193.\n",
      "[I 2024-12-03 03:04:39,320] Trial 1 finished with value: 0.5662685670686141 and parameters: {'learning_rate': 0.046274213663959, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.7491680015146494, 'colsample_bytree': 0.7346373472116909, 'gamma': 0.15309304500944065, 'reg_alpha': 0.15536265929244308, 'reg_lambda': 0.1839083706293975}. Best is trial 0 with value: 0.5708533799971193.\n",
      "[I 2024-12-03 03:05:05,110] Trial 2 finished with value: 0.566030423000307 and parameters: {'learning_rate': 0.03465000130249735, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.7058070053415548, 'colsample_bytree': 0.7629190192209807, 'gamma': 0.09185434486391912, 'reg_alpha': 0.2740343624622445, 'reg_lambda': 1.110688729685853}. Best is trial 0 with value: 0.5708533799971193.\n",
      "[I 2024-12-03 03:05:26,989] Trial 3 finished with value: 0.5701135747147863 and parameters: {'learning_rate': 0.023364755076401605, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.8888584821593047, 'colsample_bytree': 0.8026899123289692, 'gamma': 0.2375572577090897, 'reg_alpha': 0.029815696417447628, 'reg_lambda': 0.2609174018544432}. Best is trial 0 with value: 0.5708533799971193.\n",
      "[I 2024-12-03 03:05:40,886] Trial 4 finished with value: 0.5668058463052276 and parameters: {'learning_rate': 0.09460381755608442, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.831104211120902, 'colsample_bytree': 0.8772750512021481, 'gamma': 0.23700110265897226, 'reg_alpha': 0.5801645613932059, 'reg_lambda': 0.8275454962126184}. Best is trial 0 with value: 0.5708533799971193.\n",
      "[I 2024-12-03 03:06:06,514] Trial 5 finished with value: 0.5642429456132245 and parameters: {'learning_rate': 0.045529915878868635, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.7282483552424008, 'colsample_bytree': 0.7489272282721904, 'gamma': 0.24219497176592403, 'reg_alpha': 0.034332694415270454, 'reg_lambda': 1.461251479871253}. Best is trial 0 with value: 0.5708533799971193.\n",
      "[I 2024-12-03 03:06:20,560] Trial 6 finished with value: 0.5790236443306861 and parameters: {'learning_rate': 0.0963041515928768, 'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.6038521677054717, 'colsample_bytree': 0.6481881112264753, 'gamma': 0.24114647282996665, 'reg_alpha': 0.027878570231250364, 'reg_lambda': 1.8024827571155098}. Best is trial 6 with value: 0.5790236443306861.\n",
      "[I 2024-12-03 03:06:39,387] Trial 7 finished with value: 0.56996591926973 and parameters: {'learning_rate': 0.027009852251058727, 'max_depth': 6, 'min_child_weight': 3, 'subsample': 0.8156858271166866, 'colsample_bytree': 0.8496110758494357, 'gamma': 0.06668076800383667, 'reg_alpha': 0.035638547197265516, 'reg_lambda': 0.2646903842363615}. Best is trial 6 with value: 0.5790236443306861.\n",
      "[I 2024-12-03 03:07:07,527] Trial 8 finished with value: 0.5683844909729706 and parameters: {'learning_rate': 0.014751450246578281, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.694310714612388, 'colsample_bytree': 0.6856189474329176, 'gamma': 0.15757137177884578, 'reg_alpha': 0.15825888452998407, 'reg_lambda': 0.27769271588081423}. Best is trial 6 with value: 0.5790236443306861.\n",
      "[I 2024-12-03 03:07:43,463] Trial 9 finished with value: 0.5770880484855976 and parameters: {'learning_rate': 0.01769142408247335, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.850995131120046, 'colsample_bytree': 0.6103159000794354, 'gamma': 0.15611452169569678, 'reg_alpha': 0.07399666084328159, 'reg_lambda': 0.17944698170761067}. Best is trial 6 with value: 0.5790236443306861.\n",
      "[I 2024-12-03 03:07:55,633] Trial 10 finished with value: 0.5759681913360851 and parameters: {'learning_rate': 0.08663867637945037, 'max_depth': 4, 'min_child_weight': 5, 'subsample': 0.6066741085043721, 'colsample_bytree': 0.6188470436087369, 'gamma': 0.28119255021074263, 'reg_alpha': 0.01115936195759509, 'reg_lambda': 0.6685688842710942}. Best is trial 6 with value: 0.5790236443306861.\n",
      "[I 2024-12-03 03:08:14,908] Trial 11 finished with value: 0.5367675097630393 and parameters: {'learning_rate': 0.010494109340144194, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6258283323978283, 'colsample_bytree': 0.6011565442442255, 'gamma': 0.19383191523006824, 'reg_alpha': 0.05434311939727316, 'reg_lambda': 1.919114522754325}. Best is trial 6 with value: 0.5790236443306861.\n",
      "[I 2024-12-03 03:08:35,627] Trial 12 finished with value: 0.5637853836784046 and parameters: {'learning_rate': 0.01781019964969039, 'max_depth': 6, 'min_child_weight': 4, 'subsample': 0.897503917885343, 'colsample_bytree': 0.6613023786303697, 'gamma': 0.10064693229428535, 'reg_alpha': 0.010510863625185215, 'reg_lambda': 0.44249151231905715}. Best is trial 6 with value: 0.5790236443306861.\n",
      "[I 2024-12-03 03:08:45,376] Trial 13 finished with value: 0.5519875807612937 and parameters: {'learning_rate': 0.06588180497578558, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6646430984523813, 'colsample_bytree': 0.6584144844079192, 'gamma': 0.29048126092795323, 'reg_alpha': 0.06407222817955416, 'reg_lambda': 0.1044862903223793}. Best is trial 6 with value: 0.5790236443306861.\n",
      "[I 2024-12-03 03:09:10,493] Trial 14 finished with value: 0.5688879232017979 and parameters: {'learning_rate': 0.01937263715198111, 'max_depth': 8, 'min_child_weight': 4, 'subsample': 0.8008744234571628, 'colsample_bytree': 0.6978171581224616, 'gamma': 0.19162612756143807, 'reg_alpha': 0.015598219277023349, 'reg_lambda': 0.498528371620744}. Best is trial 6 with value: 0.5790236443306861.\n",
      "[I 2024-12-03 03:09:32,010] Trial 15 finished with value: 0.5499286312374874 and parameters: {'learning_rate': 0.011906683678605926, 'max_depth': 6, 'min_child_weight': 2, 'subsample': 0.8502021231325421, 'colsample_bytree': 0.6336653339195942, 'gamma': 0.19541838499760691, 'reg_alpha': 0.021719884971071683, 'reg_lambda': 0.3646342686447086}. Best is trial 6 with value: 0.5790236443306861.\n",
      "[I 2024-12-03 03:09:46,358] Trial 16 finished with value: 0.5750940907468525 and parameters: {'learning_rate': 0.06360744499859441, 'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.7856646857077701, 'colsample_bytree': 0.695658994659043, 'gamma': 0.12291442647939374, 'reg_alpha': 0.05613676710829374, 'reg_lambda': 0.17251241996162137}. Best is trial 6 with value: 0.5790236443306861.\n",
      "[I 2024-12-03 03:10:12,394] Trial 17 finished with value: 0.5789552454398111 and parameters: {'learning_rate': 0.03174009707284335, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.654754247576157, 'colsample_bytree': 0.6588532233453483, 'gamma': 0.045712849124750585, 'reg_alpha': 0.9106909878549106, 'reg_lambda': 0.7484092806950191}. Best is trial 6 with value: 0.5790236443306861.\n",
      "[I 2024-12-03 03:10:33,966] Trial 18 finished with value: 0.5761050934860666 and parameters: {'learning_rate': 0.06003141952856502, 'max_depth': 8, 'min_child_weight': 4, 'subsample': 0.6460791801659675, 'colsample_bytree': 0.6568017372071581, 'gamma': 0.003458303198915491, 'reg_alpha': 0.6645070699540181, 'reg_lambda': 1.0380766951872278}. Best is trial 6 with value: 0.5790236443306861.\n",
      "[I 2024-12-03 03:10:55,822] Trial 19 finished with value: 0.5670323156827982 and parameters: {'learning_rate': 0.031249201533920183, 'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.6011140780958011, 'colsample_bytree': 0.7182997875604781, 'gamma': 0.048897861310706656, 'reg_alpha': 0.9045030034326261, 'reg_lambda': 1.993421781486918}. Best is trial 6 with value: 0.5790236443306861.\n",
      "[I 2024-12-03 03:11:10,314] Trial 20 finished with value: 0.5478386680260761 and parameters: {'learning_rate': 0.07605183807281872, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.6679151170361841, 'colsample_bytree': 0.6378486410241463, 'gamma': 0.03332569419769107, 'reg_alpha': 0.3387512701718107, 'reg_lambda': 1.3794291857013126}. Best is trial 6 with value: 0.5790236443306861.\n",
      "[I 2024-12-03 03:11:43,124] Trial 21 finished with value: 0.5637707480659211 and parameters: {'learning_rate': 0.01399415762089008, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.644584155642568, 'colsample_bytree': 0.6181395791572016, 'gamma': 0.12950752493823495, 'reg_alpha': 0.09696803584335235, 'reg_lambda': 0.6618222412788469}. Best is trial 6 with value: 0.5790236443306861.\n",
      "[I 2024-12-03 03:12:11,403] Trial 22 finished with value: 0.5835515623188785 and parameters: {'learning_rate': 0.02158439998229514, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.8646222418787073, 'colsample_bytree': 0.6010030629301368, 'gamma': 0.17244768552409692, 'reg_alpha': 0.22505033233934946, 'reg_lambda': 0.7751465862335809}. Best is trial 22 with value: 0.5835515623188785.\n",
      "[I 2024-12-03 03:12:39,610] Trial 23 finished with value: 0.5784717745956928 and parameters: {'learning_rate': 0.02208072313490075, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.6874688716946866, 'colsample_bytree': 0.6662083722160034, 'gamma': 0.2096812687003475, 'reg_alpha': 0.3782210494449072, 'reg_lambda': 0.785191001855154}. Best is trial 22 with value: 0.5835515623188785.\n",
      "[I 2024-12-03 03:13:01,763] Trial 24 finished with value: 0.5622559558175021 and parameters: {'learning_rate': 0.0321598636199964, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.6292587110300488, 'colsample_bytree': 0.6422846825389273, 'gamma': 0.2661373250308472, 'reg_alpha': 0.18980714515044023, 'reg_lambda': 0.542814339791402}. Best is trial 22 with value: 0.5835515623188785.\n",
      "[I 2024-12-03 03:13:31,901] Trial 25 finished with value: 0.5611803389058091 and parameters: {'learning_rate': 0.025704298010064814, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.721823020736077, 'colsample_bytree': 0.680485387440142, 'gamma': 0.1770634152785433, 'reg_alpha': 0.9160051902385232, 'reg_lambda': 1.06736657301097}. Best is trial 22 with value: 0.5835515623188785.\n",
      "[I 2024-12-03 03:13:47,142] Trial 26 finished with value: 0.5617035859501388 and parameters: {'learning_rate': 0.03803056072111994, 'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.67175463452771, 'colsample_bytree': 0.6011217785056512, 'gamma': 0.11925681046479139, 'reg_alpha': 0.4619916296984883, 'reg_lambda': 1.4970657445255087}. Best is trial 22 with value: 0.5835515623188785.\n",
      "[I 2024-12-03 03:14:11,602] Trial 27 finished with value: 0.5600149816856644 and parameters: {'learning_rate': 0.015071382848086366, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.6234519351579488, 'colsample_bytree': 0.716410514256128, 'gamma': 0.21981212021264132, 'reg_alpha': 0.26878475265164115, 'reg_lambda': 0.8652950321032314}. Best is trial 22 with value: 0.5835515623188785.\n",
      "[I 2024-12-03 03:14:29,490] Trial 28 finished with value: 0.5616468635566529 and parameters: {'learning_rate': 0.05811941725698179, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.7665305907223056, 'colsample_bytree': 0.6344225903394218, 'gamma': 0.260287089391611, 'reg_alpha': 0.20961825605567078, 'reg_lambda': 0.40634289897195697}. Best is trial 22 with value: 0.5835515623188785.\n",
      "[I 2024-12-03 03:14:49,710] Trial 29 finished with value: 0.5668725664132739 and parameters: {'learning_rate': 0.05314938444318349, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.7646843777587876, 'colsample_bytree': 0.8194710864180016, 'gamma': 0.06327059659763226, 'reg_alpha': 0.10699279492309231, 'reg_lambda': 0.6196316804008014}. Best is trial 22 with value: 0.5835515623188785.\n",
      "[I 2024-12-03 03:15:08,047] Trial 30 finished with value: 0.5684244227689744 and parameters: {'learning_rate': 0.028615267420294653, 'max_depth': 6, 'min_child_weight': 4, 'subsample': 0.6487792286065553, 'colsample_bytree': 0.77635644579146, 'gamma': 0.030677877890139676, 'reg_alpha': 0.6523819330855182, 'reg_lambda': 0.33579006765353536}. Best is trial 22 with value: 0.5835515623188785.\n",
      "[I 2024-12-03 03:15:36,694] Trial 31 finished with value: 0.5709879145567021 and parameters: {'learning_rate': 0.02067723095920852, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.6892717769374465, 'colsample_bytree': 0.66998991387296, 'gamma': 0.21560843022438098, 'reg_alpha': 0.3826497776926598, 'reg_lambda': 0.8003634550978496}. Best is trial 22 with value: 0.5835515623188785.\n",
      "[I 2024-12-03 03:16:05,084] Trial 32 finished with value: 0.571511428035968 and parameters: {'learning_rate': 0.022674520478692305, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.7375513933178915, 'colsample_bytree': 0.6479766293089227, 'gamma': 0.16986843254434172, 'reg_alpha': 0.44754825882101207, 'reg_lambda': 1.2472972969349891}. Best is trial 22 with value: 0.5835515623188785.\n",
      "[I 2024-12-03 03:16:26,871] Trial 33 finished with value: 0.5807942407592496 and parameters: {'learning_rate': 0.038462981860045396, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.7127979115459695, 'colsample_bytree': 0.7205850378650839, 'gamma': 0.2154946820872494, 'reg_alpha': 0.28124561927423164, 'reg_lambda': 0.9135599216318409}. Best is trial 22 with value: 0.5835515623188785.\n",
      "[I 2024-12-03 03:16:47,546] Trial 34 finished with value: 0.5758694530969407 and parameters: {'learning_rate': 0.03797249249323486, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.7081726704132653, 'colsample_bytree': 0.7370428785575353, 'gamma': 0.13817342298483382, 'reg_alpha': 0.12020773341941522, 'reg_lambda': 0.982365054515225}. Best is trial 22 with value: 0.5835515623188785.\n",
      "[I 2024-12-03 03:17:06,748] Trial 35 finished with value: 0.5743843430764904 and parameters: {'learning_rate': 0.040087625984366666, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.8699247201326685, 'colsample_bytree': 0.7144732102303284, 'gamma': 0.24694248440528488, 'reg_alpha': 0.2741376662093884, 'reg_lambda': 1.6434840402854294}. Best is trial 22 with value: 0.5835515623188785.\n",
      "[I 2024-12-03 03:17:26,514] Trial 36 finished with value: 0.5720968331509115 and parameters: {'learning_rate': 0.05005484941551716, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.7486830671863901, 'colsample_bytree': 0.6239326306232386, 'gamma': 0.23159653253522228, 'reg_alpha': 0.13024992937988347, 'reg_lambda': 1.2337961235266122}. Best is trial 22 with value: 0.5835515623188785.\n",
      "[I 2024-12-03 03:17:54,667] Trial 37 finished with value: 0.559128741004448 and parameters: {'learning_rate': 0.0341853274041847, 'max_depth': 10, 'min_child_weight': 3, 'subsample': 0.6141790929586395, 'colsample_bytree': 0.7680403678371748, 'gamma': 0.08550964340711316, 'reg_alpha': 0.23994179569275106, 'reg_lambda': 0.9029309480791388}. Best is trial 22 with value: 0.5835515623188785.\n",
      "[I 2024-12-03 03:18:07,966] Trial 38 finished with value: 0.569351945141594 and parameters: {'learning_rate': 0.09996418562001873, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.7147172638547973, 'colsample_bytree': 0.7920815654498792, 'gamma': 0.18274968013978804, 'reg_alpha': 0.042008373335854145, 'reg_lambda': 0.7214136673848011}. Best is trial 22 with value: 0.5835515623188785.\n",
      "[I 2024-12-03 03:18:28,746] Trial 39 finished with value: 0.5767398498738208 and parameters: {'learning_rate': 0.044232479089329604, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.6535967082557639, 'colsample_bytree': 0.6802648409834637, 'gamma': 0.25714747452747433, 'reg_alpha': 0.16756261013741505, 'reg_lambda': 1.2161337270648673}. Best is trial 22 with value: 0.5835515623188785.\n",
      "[I 2024-12-03 03:18:57,609] Trial 40 finished with value: 0.5759492009476239 and parameters: {'learning_rate': 0.028593078768837328, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.7889710960747524, 'colsample_bytree': 0.7474244735158969, 'gamma': 0.22649662003296972, 'reg_alpha': 0.02700208984342945, 'reg_lambda': 0.5424584283082172}. Best is trial 22 with value: 0.5835515623188785.\n",
      "[I 2024-12-03 03:19:25,859] Trial 41 finished with value: 0.5675917506058964 and parameters: {'learning_rate': 0.023934926914530186, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.6874269273596345, 'colsample_bytree': 0.6996457471825007, 'gamma': 0.20840644459598703, 'reg_alpha': 0.5239140276742947, 'reg_lambda': 0.7739167675112917}. Best is trial 22 with value: 0.5835515623188785.\n",
      "[I 2024-12-03 03:19:54,872] Trial 42 finished with value: 0.5754004275839636 and parameters: {'learning_rate': 0.02157260897255848, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.6839936382270954, 'colsample_bytree': 0.6657976634627165, 'gamma': 0.20624862904710575, 'reg_alpha': 0.3109448965061602, 'reg_lambda': 1.7080482868554019}. Best is trial 22 with value: 0.5835515623188785.\n",
      "[I 2024-12-03 03:20:25,889] Trial 43 finished with value: 0.5635807738961089 and parameters: {'learning_rate': 0.01718374952607717, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.7384147415164863, 'colsample_bytree': 0.6243672765374589, 'gamma': 0.16437604532116337, 'reg_alpha': 0.7595521091316286, 'reg_lambda': 0.5762082027295635}. Best is trial 22 with value: 0.5835515623188785.\n",
      "[I 2024-12-03 03:20:37,769] Trial 44 finished with value: 0.5510107427449532 and parameters: {'learning_rate': 0.08064496891511849, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.6996654012997281, 'colsample_bytree': 0.6754089875353294, 'gamma': 0.24536258167987224, 'reg_alpha': 0.4412376916937061, 'reg_lambda': 0.7094774585288255}. Best is trial 22 with value: 0.5835515623188785.\n",
      "[I 2024-12-03 03:21:07,204] Trial 45 finished with value: 0.5775760013522869 and parameters: {'learning_rate': 0.02543522920296802, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.6679658293257974, 'colsample_bytree': 0.6519699703619626, 'gamma': 0.14563912506074844, 'reg_alpha': 0.0910940941976703, 'reg_lambda': 0.9563652196254077}. Best is trial 22 with value: 0.5835515623188785.\n",
      "[I 2024-12-03 03:21:22,172] Trial 46 finished with value: 0.5426166643872681 and parameters: {'learning_rate': 0.0192937089316339, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.6809686800924641, 'colsample_bytree': 0.6910947253860974, 'gamma': 0.20335576646384598, 'reg_alpha': 0.2109210558567315, 'reg_lambda': 1.1493949516376543}. Best is trial 22 with value: 0.5835515623188785.\n",
      "[I 2024-12-03 03:21:50,306] Trial 47 finished with value: 0.5583817595141488 and parameters: {'learning_rate': 0.028632341894684096, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.6388180481689426, 'colsample_bytree': 0.8771768867809214, 'gamma': 0.18313929281619568, 'reg_alpha': 0.3591396973413061, 'reg_lambda': 0.4681034782008619}. Best is trial 22 with value: 0.5835515623188785.\n",
      "[I 2024-12-03 03:22:07,933] Trial 48 finished with value: 0.5554550925662474 and parameters: {'learning_rate': 0.01606316811070219, 'max_depth': 5, 'min_child_weight': 2, 'subsample': 0.8358895204282908, 'colsample_bytree': 0.6095137535129885, 'gamma': 0.2754632606590903, 'reg_alpha': 0.1415846930375592, 'reg_lambda': 0.8176119251167286}. Best is trial 22 with value: 0.5835515623188785.\n",
      "[I 2024-12-03 03:22:38,033] Trial 49 finished with value: 0.5648769775774743 and parameters: {'learning_rate': 0.01278135841431236, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.7066208207078994, 'colsample_bytree': 0.7030422692361813, 'gamma': 0.29596672444859934, 'reg_alpha': 0.01799561054723117, 'reg_lambda': 1.4207264373190611}. Best is trial 22 with value: 0.5835515623188785.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Best Parameters: {'learning_rate': 0.02158439998229514, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.8646222418787073, 'colsample_bytree': 0.6010030629301368, 'gamma': 0.17244768552409692, 'reg_alpha': 0.22505033233934946, 'reg_lambda': 0.7751465862335809}\n",
      "[0]\tvalidation-rmse:0.81146\n",
      "[1]\tvalidation-rmse:0.80691\n",
      "[2]\tvalidation-rmse:0.80306\n",
      "[3]\tvalidation-rmse:0.79933\n",
      "[4]\tvalidation-rmse:0.79585\n",
      "[5]\tvalidation-rmse:0.79240\n",
      "[6]\tvalidation-rmse:0.78905\n",
      "[7]\tvalidation-rmse:0.78534\n",
      "[8]\tvalidation-rmse:0.78206\n",
      "[9]\tvalidation-rmse:0.77875\n",
      "[10]\tvalidation-rmse:0.77597\n",
      "[11]\tvalidation-rmse:0.77321\n",
      "[12]\tvalidation-rmse:0.77048\n",
      "[13]\tvalidation-rmse:0.76804\n",
      "[14]\tvalidation-rmse:0.76546\n",
      "[15]\tvalidation-rmse:0.76318\n",
      "[16]\tvalidation-rmse:0.76058\n",
      "[17]\tvalidation-rmse:0.75798\n",
      "[18]\tvalidation-rmse:0.75560\n",
      "[19]\tvalidation-rmse:0.75308\n",
      "[20]\tvalidation-rmse:0.75086\n",
      "[21]\tvalidation-rmse:0.74850\n",
      "[22]\tvalidation-rmse:0.74601\n",
      "[23]\tvalidation-rmse:0.74409\n",
      "[24]\tvalidation-rmse:0.74189\n",
      "[25]\tvalidation-rmse:0.74033\n",
      "[26]\tvalidation-rmse:0.73856\n",
      "[27]\tvalidation-rmse:0.73678\n",
      "[28]\tvalidation-rmse:0.73536\n",
      "[29]\tvalidation-rmse:0.73404\n",
      "[30]\tvalidation-rmse:0.73245\n",
      "[31]\tvalidation-rmse:0.73068\n",
      "[32]\tvalidation-rmse:0.72932\n",
      "[33]\tvalidation-rmse:0.72797\n",
      "[34]\tvalidation-rmse:0.72673\n",
      "[35]\tvalidation-rmse:0.72550\n",
      "[36]\tvalidation-rmse:0.72446\n",
      "[37]\tvalidation-rmse:0.72329\n",
      "[38]\tvalidation-rmse:0.72262\n",
      "[39]\tvalidation-rmse:0.72127\n",
      "[40]\tvalidation-rmse:0.72020\n",
      "[41]\tvalidation-rmse:0.71917\n",
      "[42]\tvalidation-rmse:0.71825\n",
      "[43]\tvalidation-rmse:0.71734\n",
      "[44]\tvalidation-rmse:0.71651\n",
      "[45]\tvalidation-rmse:0.71580\n",
      "[46]\tvalidation-rmse:0.71496\n",
      "[47]\tvalidation-rmse:0.71396\n",
      "[48]\tvalidation-rmse:0.71333\n",
      "[49]\tvalidation-rmse:0.71215\n",
      "[50]\tvalidation-rmse:0.71104\n",
      "[51]\tvalidation-rmse:0.71022\n",
      "[52]\tvalidation-rmse:0.70937\n",
      "[53]\tvalidation-rmse:0.70831\n",
      "[54]\tvalidation-rmse:0.70731\n",
      "[55]\tvalidation-rmse:0.70686\n",
      "[56]\tvalidation-rmse:0.70642\n",
      "[57]\tvalidation-rmse:0.70577\n",
      "[58]\tvalidation-rmse:0.70472\n",
      "[59]\tvalidation-rmse:0.70406\n",
      "[60]\tvalidation-rmse:0.70308\n",
      "[61]\tvalidation-rmse:0.70283\n",
      "[62]\tvalidation-rmse:0.70221\n",
      "[63]\tvalidation-rmse:0.70149\n",
      "[64]\tvalidation-rmse:0.70076\n",
      "[65]\tvalidation-rmse:0.69985\n",
      "[66]\tvalidation-rmse:0.69954\n",
      "[67]\tvalidation-rmse:0.69898\n",
      "[68]\tvalidation-rmse:0.69842\n",
      "[69]\tvalidation-rmse:0.69802\n",
      "[70]\tvalidation-rmse:0.69778\n",
      "[71]\tvalidation-rmse:0.69738\n",
      "[72]\tvalidation-rmse:0.69730\n",
      "[73]\tvalidation-rmse:0.69690\n",
      "[74]\tvalidation-rmse:0.69689\n",
      "[75]\tvalidation-rmse:0.69636\n",
      "[76]\tvalidation-rmse:0.69597\n",
      "[77]\tvalidation-rmse:0.69591\n",
      "[78]\tvalidation-rmse:0.69573\n",
      "[79]\tvalidation-rmse:0.69523\n",
      "[80]\tvalidation-rmse:0.69468\n",
      "[81]\tvalidation-rmse:0.69461\n",
      "[82]\tvalidation-rmse:0.69441\n",
      "[83]\tvalidation-rmse:0.69425\n",
      "[84]\tvalidation-rmse:0.69393\n",
      "[85]\tvalidation-rmse:0.69348\n",
      "[86]\tvalidation-rmse:0.69328\n",
      "[87]\tvalidation-rmse:0.69286\n",
      "[88]\tvalidation-rmse:0.69273\n",
      "[89]\tvalidation-rmse:0.69241\n",
      "[90]\tvalidation-rmse:0.69164\n",
      "[91]\tvalidation-rmse:0.69125\n",
      "[92]\tvalidation-rmse:0.69065\n",
      "[93]\tvalidation-rmse:0.69033\n",
      "[94]\tvalidation-rmse:0.68955\n",
      "[95]\tvalidation-rmse:0.68937\n",
      "[96]\tvalidation-rmse:0.68920\n",
      "[97]\tvalidation-rmse:0.68866\n",
      "[98]\tvalidation-rmse:0.68836\n",
      "[99]\tvalidation-rmse:0.68794\n",
      "[100]\tvalidation-rmse:0.68748\n",
      "[101]\tvalidation-rmse:0.68732\n",
      "[102]\tvalidation-rmse:0.68697\n",
      "[103]\tvalidation-rmse:0.68657\n",
      "[104]\tvalidation-rmse:0.68652\n",
      "[105]\tvalidation-rmse:0.68687\n",
      "[106]\tvalidation-rmse:0.68662\n",
      "[107]\tvalidation-rmse:0.68649\n",
      "[108]\tvalidation-rmse:0.68626\n",
      "[109]\tvalidation-rmse:0.68608\n",
      "[110]\tvalidation-rmse:0.68600\n",
      "[111]\tvalidation-rmse:0.68599\n",
      "[112]\tvalidation-rmse:0.68513\n",
      "[113]\tvalidation-rmse:0.68471\n",
      "[114]\tvalidation-rmse:0.68438\n",
      "[115]\tvalidation-rmse:0.68416\n",
      "[116]\tvalidation-rmse:0.68380\n",
      "[117]\tvalidation-rmse:0.68357\n",
      "[118]\tvalidation-rmse:0.68307\n",
      "[119]\tvalidation-rmse:0.68291\n",
      "[120]\tvalidation-rmse:0.68261\n",
      "[121]\tvalidation-rmse:0.68245\n",
      "[122]\tvalidation-rmse:0.68209\n",
      "[123]\tvalidation-rmse:0.68187\n",
      "[124]\tvalidation-rmse:0.68144\n",
      "[125]\tvalidation-rmse:0.68121\n",
      "[126]\tvalidation-rmse:0.68100\n",
      "[127]\tvalidation-rmse:0.68086\n",
      "[128]\tvalidation-rmse:0.68056\n",
      "[129]\tvalidation-rmse:0.68052\n",
      "[130]\tvalidation-rmse:0.68031\n",
      "[131]\tvalidation-rmse:0.68014\n",
      "[132]\tvalidation-rmse:0.67988\n",
      "[133]\tvalidation-rmse:0.67983\n",
      "[134]\tvalidation-rmse:0.67972\n",
      "[135]\tvalidation-rmse:0.67957\n",
      "[136]\tvalidation-rmse:0.67935\n",
      "[137]\tvalidation-rmse:0.67901\n",
      "[138]\tvalidation-rmse:0.67888\n",
      "[139]\tvalidation-rmse:0.67883\n",
      "[140]\tvalidation-rmse:0.67864\n",
      "[141]\tvalidation-rmse:0.67844\n",
      "[142]\tvalidation-rmse:0.67835\n",
      "[143]\tvalidation-rmse:0.67817\n",
      "[144]\tvalidation-rmse:0.67806\n",
      "[145]\tvalidation-rmse:0.67781\n",
      "[146]\tvalidation-rmse:0.67762\n",
      "[147]\tvalidation-rmse:0.67763\n",
      "[148]\tvalidation-rmse:0.67755\n",
      "[149]\tvalidation-rmse:0.67724\n",
      "[150]\tvalidation-rmse:0.67698\n",
      "[151]\tvalidation-rmse:0.67697\n",
      "[152]\tvalidation-rmse:0.67684\n",
      "[153]\tvalidation-rmse:0.67677\n",
      "[154]\tvalidation-rmse:0.67648\n",
      "[155]\tvalidation-rmse:0.67622\n",
      "[156]\tvalidation-rmse:0.67606\n",
      "[157]\tvalidation-rmse:0.67595\n",
      "[158]\tvalidation-rmse:0.67577\n",
      "[159]\tvalidation-rmse:0.67557\n",
      "[160]\tvalidation-rmse:0.67559\n",
      "[161]\tvalidation-rmse:0.67540\n",
      "[162]\tvalidation-rmse:0.67523\n",
      "[163]\tvalidation-rmse:0.67517\n",
      "[164]\tvalidation-rmse:0.67500\n",
      "[165]\tvalidation-rmse:0.67499\n",
      "[166]\tvalidation-rmse:0.67491\n",
      "[167]\tvalidation-rmse:0.67475\n",
      "[168]\tvalidation-rmse:0.67473\n",
      "[169]\tvalidation-rmse:0.67451\n",
      "[170]\tvalidation-rmse:0.67451\n",
      "[171]\tvalidation-rmse:0.67420\n",
      "[172]\tvalidation-rmse:0.67423\n",
      "[173]\tvalidation-rmse:0.67422\n",
      "[174]\tvalidation-rmse:0.67409\n",
      "[175]\tvalidation-rmse:0.67407\n",
      "[176]\tvalidation-rmse:0.67383\n",
      "[177]\tvalidation-rmse:0.67369\n",
      "[178]\tvalidation-rmse:0.67369\n",
      "[179]\tvalidation-rmse:0.67352\n",
      "[180]\tvalidation-rmse:0.67337\n",
      "[181]\tvalidation-rmse:0.67307\n",
      "[182]\tvalidation-rmse:0.67293\n",
      "[183]\tvalidation-rmse:0.67262\n",
      "[184]\tvalidation-rmse:0.67259\n",
      "[185]\tvalidation-rmse:0.67236\n",
      "[186]\tvalidation-rmse:0.67234\n",
      "[187]\tvalidation-rmse:0.67201\n",
      "[188]\tvalidation-rmse:0.67200\n",
      "[189]\tvalidation-rmse:0.67191\n",
      "[190]\tvalidation-rmse:0.67179\n",
      "[191]\tvalidation-rmse:0.67171\n",
      "[192]\tvalidation-rmse:0.67165\n",
      "[193]\tvalidation-rmse:0.67168\n",
      "[194]\tvalidation-rmse:0.67161\n",
      "[195]\tvalidation-rmse:0.67151\n",
      "[196]\tvalidation-rmse:0.67136\n",
      "[197]\tvalidation-rmse:0.67128\n",
      "[198]\tvalidation-rmse:0.67136\n",
      "[199]\tvalidation-rmse:0.67133\n",
      "[200]\tvalidation-rmse:0.67138\n",
      "[201]\tvalidation-rmse:0.67139\n",
      "[202]\tvalidation-rmse:0.67140\n",
      "[203]\tvalidation-rmse:0.67123\n",
      "[204]\tvalidation-rmse:0.67119\n",
      "[205]\tvalidation-rmse:0.67112\n",
      "[206]\tvalidation-rmse:0.67087\n",
      "[207]\tvalidation-rmse:0.67079\n",
      "[208]\tvalidation-rmse:0.67072\n",
      "[209]\tvalidation-rmse:0.67055\n",
      "[210]\tvalidation-rmse:0.67058\n",
      "[211]\tvalidation-rmse:0.67072\n",
      "[212]\tvalidation-rmse:0.67065\n",
      "[213]\tvalidation-rmse:0.67025\n",
      "[214]\tvalidation-rmse:0.67026\n",
      "[215]\tvalidation-rmse:0.67012\n",
      "[216]\tvalidation-rmse:0.67013\n",
      "[217]\tvalidation-rmse:0.67000\n",
      "[218]\tvalidation-rmse:0.66993\n",
      "[219]\tvalidation-rmse:0.66994\n",
      "[220]\tvalidation-rmse:0.66977\n",
      "[221]\tvalidation-rmse:0.66963\n",
      "[222]\tvalidation-rmse:0.66958\n",
      "[223]\tvalidation-rmse:0.66953\n",
      "[224]\tvalidation-rmse:0.66960\n",
      "[225]\tvalidation-rmse:0.66963\n",
      "[226]\tvalidation-rmse:0.66967\n",
      "[227]\tvalidation-rmse:0.66973\n",
      "[228]\tvalidation-rmse:0.66974\n",
      "[229]\tvalidation-rmse:0.66965\n",
      "[230]\tvalidation-rmse:0.66968\n",
      "[231]\tvalidation-rmse:0.66965\n",
      "[232]\tvalidation-rmse:0.66953\n",
      "[233]\tvalidation-rmse:0.66954\n",
      "[234]\tvalidation-rmse:0.66947\n",
      "[235]\tvalidation-rmse:0.66945\n",
      "[236]\tvalidation-rmse:0.66944\n",
      "[237]\tvalidation-rmse:0.66938\n",
      "[238]\tvalidation-rmse:0.66939\n",
      "[239]\tvalidation-rmse:0.66949\n",
      "[240]\tvalidation-rmse:0.66940\n",
      "[241]\tvalidation-rmse:0.66920\n",
      "[242]\tvalidation-rmse:0.66916\n",
      "[243]\tvalidation-rmse:0.66902\n",
      "[244]\tvalidation-rmse:0.66893\n",
      "[245]\tvalidation-rmse:0.66893\n",
      "[246]\tvalidation-rmse:0.66869\n",
      "[247]\tvalidation-rmse:0.66877\n",
      "[248]\tvalidation-rmse:0.66879\n",
      "[249]\tvalidation-rmse:0.66883\n",
      "[250]\tvalidation-rmse:0.66871\n",
      "[251]\tvalidation-rmse:0.66881\n",
      "[252]\tvalidation-rmse:0.66885\n",
      "[253]\tvalidation-rmse:0.66882\n",
      "[254]\tvalidation-rmse:0.66884\n",
      "[255]\tvalidation-rmse:0.66879\n",
      "[256]\tvalidation-rmse:0.66880\n",
      "[257]\tvalidation-rmse:0.66878\n",
      "[258]\tvalidation-rmse:0.66864\n",
      "[259]\tvalidation-rmse:0.66856\n",
      "[260]\tvalidation-rmse:0.66850\n",
      "[261]\tvalidation-rmse:0.66854\n",
      "[262]\tvalidation-rmse:0.66858\n",
      "[263]\tvalidation-rmse:0.66842\n",
      "[264]\tvalidation-rmse:0.66835\n",
      "[265]\tvalidation-rmse:0.66834\n",
      "[266]\tvalidation-rmse:0.66829\n",
      "[267]\tvalidation-rmse:0.66823\n",
      "[268]\tvalidation-rmse:0.66812\n",
      "[269]\tvalidation-rmse:0.66804\n",
      "[270]\tvalidation-rmse:0.66791\n",
      "[271]\tvalidation-rmse:0.66794\n",
      "[272]\tvalidation-rmse:0.66791\n",
      "[273]\tvalidation-rmse:0.66786\n",
      "[274]\tvalidation-rmse:0.66768\n",
      "[275]\tvalidation-rmse:0.66744\n",
      "[276]\tvalidation-rmse:0.66739\n",
      "[277]\tvalidation-rmse:0.66741\n",
      "[278]\tvalidation-rmse:0.66729\n",
      "[279]\tvalidation-rmse:0.66723\n",
      "[280]\tvalidation-rmse:0.66709\n",
      "[281]\tvalidation-rmse:0.66709\n",
      "[282]\tvalidation-rmse:0.66701\n",
      "[283]\tvalidation-rmse:0.66700\n",
      "[284]\tvalidation-rmse:0.66705\n",
      "[285]\tvalidation-rmse:0.66703\n",
      "[286]\tvalidation-rmse:0.66705\n",
      "[287]\tvalidation-rmse:0.66708\n",
      "[288]\tvalidation-rmse:0.66709\n",
      "[289]\tvalidation-rmse:0.66697\n",
      "[290]\tvalidation-rmse:0.66688\n",
      "[291]\tvalidation-rmse:0.66696\n",
      "[292]\tvalidation-rmse:0.66677\n",
      "[293]\tvalidation-rmse:0.66677\n",
      "[294]\tvalidation-rmse:0.66659\n",
      "[295]\tvalidation-rmse:0.66661\n",
      "[296]\tvalidation-rmse:0.66670\n",
      "[297]\tvalidation-rmse:0.66668\n",
      "[298]\tvalidation-rmse:0.66665\n",
      "[299]\tvalidation-rmse:0.66672\n",
      "Validation Spearman Correlation (Optuna): 0.5835515623188785\n",
      "Sample submission file 'basiliondong12.csv' generated successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import xgboost as xgb\n",
    "from scipy.stats import spearmanr\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import optuna\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# --- Load Dataset ---\n",
    "train_data = pd.read_csv(\"train.csv\")  # Format: id, text, score\n",
    "val_data = pd.read_csv(\"val.csv\")      # Format: id, text, score\n",
    "test_data = pd.read_csv(\"test.csv\")    # Format: id, text\n",
    "\n",
    "# --- Define Spearman Correlation Metric ---\n",
    "def spearman_correlation(y_true, y_pred):\n",
    "    return spearmanr(y_true, y_pred).correlation\n",
    "\n",
    "# --- Preprocessing ---\n",
    "def preprocess_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove stopwords\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    return text\n",
    "\n",
    "train_data[\"cleaned_text\"] = train_data[\"text\"].apply(preprocess_text)\n",
    "val_data[\"cleaned_text\"] = val_data[\"text\"].apply(preprocess_text)\n",
    "test_data[\"cleaned_text\"] = test_data[\"text\"].apply(preprocess_text)\n",
    "\n",
    "# --- TF-IDF Features ---\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words=\"english\"\n",
    ")\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(train_data[\"cleaned_text\"]).toarray()\n",
    "X_val_tfidf = tfidf.transform(val_data[\"cleaned_text\"]).toarray()\n",
    "X_test_tfidf = tfidf.transform(test_data[\"cleaned_text\"]).toarray()\n",
    "\n",
    "# --- Word2Vec Training ---\n",
    "train_sentences = train_data[\"cleaned_text\"].apply(lambda x: x.split())\n",
    "val_sentences = val_data[\"cleaned_text\"].apply(lambda x: x.split())\n",
    "test_sentences = test_data[\"cleaned_text\"].apply(lambda x: x.split())\n",
    "\n",
    "word2vec_model = Word2Vec(sentences=train_sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "def get_sentence_embedding(sentences, model, vector_size):\n",
    "    embeddings = []\n",
    "    for sentence in sentences:\n",
    "        vectors = [model.wv[word] for word in sentence if word in model.wv]\n",
    "        if vectors:\n",
    "            embeddings.append(np.mean(vectors, axis=0))\n",
    "        else:\n",
    "            embeddings.append(np.zeros(vector_size))\n",
    "    return np.array(embeddings)\n",
    "\n",
    "X_train_word2vec = get_sentence_embedding(train_sentences, word2vec_model, vector_size=100)\n",
    "X_val_word2vec = get_sentence_embedding(val_sentences, word2vec_model, vector_size=100)\n",
    "X_test_word2vec = get_sentence_embedding(test_sentences, word2vec_model, vector_size=100)\n",
    "\n",
    "# --- Combine Features ---\n",
    "X_train = np.hstack((X_train_tfidf, X_train_word2vec))\n",
    "X_val = np.hstack((X_val_tfidf, X_val_word2vec))\n",
    "X_test = np.hstack((X_test_tfidf, X_test_word2vec))\n",
    "y_train = train_data[\"score\"]\n",
    "y_val = val_data[\"score\"]\n",
    "\n",
    "# --- RandomizedSearchCV for Hyperparameter Tuning ---\n",
    "param_dist = {\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"max_depth\": [4, 6, 8],\n",
    "    \"min_child_weight\": [1, 2, 3],\n",
    "    \"subsample\": [0.7, 0.8, 0.9],\n",
    "    \"colsample_bytree\": [0.7, 0.8, 0.9],\n",
    "    \"gamma\": [0, 0.1, 0.2],\n",
    "    \"reg_alpha\": [0, 0.1, 0.5],\n",
    "    \"reg_lambda\": [1, 1.5, 2],\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=42)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,\n",
    "    scoring=make_scorer(spearman_correlation),\n",
    "    cv=3,\n",
    "    verbose=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "best_xgb_model_random = random_search.best_estimator_\n",
    "print(\"RandomizedSearch Best Parameters:\", random_search.best_params_)\n",
    "print(\"RandomizedSearch Best CV Spearman Correlation:\", random_search.best_score_)\n",
    "\n",
    "# --- Optuna for Bayesian Optimization ---\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 10),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 5),\n",
    "        \"subsample\": trial.suggest_uniform(\"subsample\", 0.6, 0.9),\n",
    "        \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.6, 0.9),\n",
    "        \"gamma\": trial.suggest_uniform(\"gamma\", 0, 0.3),\n",
    "        \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1),\n",
    "        \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.1, 2),\n",
    "    }\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dval = xgb.DMatrix(X_val, label=y_val)\n",
    "    evals = [(dval, \"validation\")]\n",
    "    model = xgb.train(param, dtrain, num_boost_round=300, evals=evals, early_stopping_rounds=50, verbose_eval=False)\n",
    "    preds = model.predict(dval)\n",
    "    return spearman_correlation(y_val, preds)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"Optuna Best Parameters:\", study.best_params)\n",
    "\n",
    "# --- Train Best Model from Optuna ---\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "best_params = study.best_params\n",
    "xgb_optuna_model = xgb.train(best_params, dtrain, num_boost_round=300, evals=[(dval, \"validation\")])\n",
    "\n",
    "# --- Evaluate on Validation Set ---\n",
    "y_val_pred_optuna = xgb_optuna_model.predict(dval)\n",
    "val_spearman_corr_optuna = spearman_correlation(y_val, y_val_pred_optuna)\n",
    "print(\"Validation Spearman Correlation (Optuna):\", val_spearman_corr_optuna)\n",
    "\n",
    "# --- Generate Predictions for Test Set ---\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "y_test_pred = xgb_optuna_model.predict(dtest)\n",
    "\n",
    "# --- Create Sample Submission ---\n",
    "submission = pd.DataFrame({\"id\": test_data[\"id\"], \"score\": y_test_pred})\n",
    "submission.to_csv(\"basiliondong12.csv\", index=False)\n",
    "print(\"Sample submission file 'basiliondong12.csv' generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\RoG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 729 candidates, totalling 2187 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "1 fits failed out of a total of 2187.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\sklearn.py\", line 1081, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\sklearn.py\", line 596, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\sklearn.py\", line 1003, in _create_dmatrix\n",
      "    return QuantileDMatrix(\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 1573, in __init__\n",
      "    self._init(\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 1632, in _init\n",
      "    it.reraise()\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 569, in reraise\n",
      "    raise exc  # pylint: disable=raising-bad-type\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 550, in _handle_exception\n",
      "    return fn()\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 637, in <lambda>\n",
      "    return self._handle_exception(lambda: self.next(input_data), 0)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\data.py\", line 1402, in next\n",
      "    input_data(**self.kwargs)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 626, in input_data\n",
      "    self.proxy.set_info(\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 954, in set_info\n",
      "    self.set_label(label)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 1092, in set_label\n",
      "    dispatch_meta_backend(self, label, \"label\", \"float\")\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\data.py\", line 1348, in dispatch_meta_backend\n",
      "    _meta_from_pandas_series(data, name, dtype, handle)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\data.py\", line 679, in _meta_from_pandas_series\n",
      "    _meta_from_numpy(data, name, dtype, handle)\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\data.py\", line 1279, in _meta_from_numpy\n",
      "    _check_call(_LIB.XGDMatrixSetInfoFromInterface(handle, c_str(field), interface_str))\n",
      "  File \"c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\xgboost\\core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [03:33:21] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\data\\array_interface.cu:44: Check failed: err == cudaGetLastError() (0 vs. 2) : \n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\RoG\\anaconda3\\envs\\licenta\\lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.48918666        nan 0.4879598  0.50622339 0.50626267 0.50529791\n",
      " 0.51783958 0.51765948 0.51710778 0.48937843 0.48819546 0.48777754\n",
      " 0.50619776 0.50609144 0.50498216 0.51801601 0.51744902 0.51688318\n",
      " 0.48914088 0.48815573 0.48763597 0.50645929 0.50613651 0.50496748\n",
      " 0.5177958  0.51746198 0.51672318 0.50707623 0.50679801 0.50571584\n",
      " 0.52077056 0.520957   0.51839525 0.52999887 0.53052625 0.52880879\n",
      " 0.50645358 0.5065214  0.5053263  0.52024645 0.52060447 0.51813438\n",
      " 0.52937158 0.52959834 0.52816861 0.50618935 0.50581715 0.50564579\n",
      " 0.51977489 0.51979004 0.51836894 0.52890029 0.52897145 0.52785697\n",
      " 0.51721078 0.51498179 0.51523885 0.52797157 0.52606504 0.52516858\n",
      " 0.53574362 0.53413184 0.53429165 0.51564788 0.51580864 0.51573793\n",
      " 0.52587188 0.52638173 0.52571831 0.5338911  0.53449472 0.53404712\n",
      " 0.51531165 0.51471983 0.51537274 0.52571462 0.52468208 0.52533127\n",
      " 0.53372955 0.5329602  0.53359412 0.52705796 0.53208658 0.53056343\n",
      " 0.54468516 0.54606357 0.5469127  0.55114603 0.55138408 0.55340856\n",
      " 0.52715052 0.53067521 0.53076862 0.54423101 0.54568068 0.54758269\n",
      " 0.55091198 0.55195136 0.5528157  0.52736749 0.53063221 0.53009361\n",
      " 0.54530602 0.54602499 0.54794654 0.55133494 0.55133245 0.55492457\n",
      " 0.53828966 0.54045973 0.53900154 0.54976324 0.55087563 0.55137825\n",
      " 0.55402096 0.55492125 0.55487243 0.53653701 0.53671151 0.53823495\n",
      " 0.54699136 0.54670775 0.54906161 0.55305401 0.55084187 0.55297689\n",
      " 0.53693414 0.53778738 0.53604537 0.54781567 0.54807362 0.54873171\n",
      " 0.55389972 0.55259955 0.55310984 0.53763544 0.53552153 0.53987028\n",
      " 0.54548101 0.54505677 0.54950317 0.54973345 0.548036   0.5513965\n",
      " 0.53757489 0.53761632 0.54071195 0.54379842 0.54651348 0.5498318\n",
      " 0.54689456 0.54991509 0.55177497 0.53941584 0.53576419 0.54173096\n",
      " 0.54593316 0.54478154 0.55138317 0.55010823 0.54795832 0.55340768\n",
      " 0.54110435 0.5432153  0.54340567 0.54691179 0.5510862  0.55131177\n",
      " 0.55193543 0.55197694 0.55377839 0.54071593 0.54112224 0.54296138\n",
      " 0.54914656 0.54972919 0.55060267 0.5534617  0.55195185 0.55413669\n",
      " 0.54156864 0.54096278 0.54318798 0.54907441 0.54849904 0.55169791\n",
      " 0.55276945 0.54944563 0.55336708 0.53951651 0.54414669 0.54819895\n",
      " 0.54394055 0.54790843 0.55190114 0.54457986 0.5470843  0.55246838\n",
      " 0.53585305 0.54139376 0.5441094  0.539191   0.54563309 0.54895464\n",
      " 0.53965669 0.54427169 0.55063101 0.53955571 0.54418039 0.54501971\n",
      " 0.54330269 0.54915379 0.54991976 0.54304084 0.54887969 0.54906343\n",
      " 0.5393489  0.54131021 0.54090502 0.54055262 0.54370522 0.5450753\n",
      " 0.54111235 0.54024357 0.54485443 0.5382804  0.54203526 0.53833089\n",
      " 0.54013636 0.54398901 0.54160312 0.53942066 0.54344957 0.54336937\n",
      " 0.53284276 0.54055335 0.53945646 0.53597305 0.54561742 0.54240743\n",
      " 0.53629119 0.5433155  0.54236939 0.4878675  0.48726761 0.48628113\n",
      " 0.50629099 0.50602281 0.50509082 0.51762257 0.51747312 0.51688815\n",
      " 0.48797883 0.48724397 0.48626514 0.50671601 0.50575871 0.50503159\n",
      " 0.51744808 0.51734812 0.5168313  0.48783681 0.48807272 0.48622148\n",
      " 0.5064609  0.50669554 0.50502638 0.51756895 0.51796633 0.51633718\n",
      " 0.5065171  0.5055201  0.50479427 0.52045677 0.51986568 0.51941511\n",
      " 0.52995058 0.53010037 0.52912365 0.50587217 0.50561894 0.50489034\n",
      " 0.51908923 0.51972808 0.51851072 0.5286786  0.52975407 0.52829473\n",
      " 0.50598545 0.50518602 0.50423696 0.51954347 0.51892099 0.51853359\n",
      " 0.52887631 0.52873724 0.52792922 0.51439859 0.51369742 0.51365211\n",
      " 0.52667294 0.52473176 0.52498171 0.53467131 0.5342924  0.53354473\n",
      " 0.51347121 0.51296988 0.51408277 0.52543782 0.5243674  0.52506504\n",
      " 0.53361429 0.53323434 0.53308777 0.51325207 0.51363844 0.51222691\n",
      " 0.52501711 0.52308539 0.52328876 0.53249966 0.53134014 0.53155317\n",
      " 0.52889448 0.52967131 0.52710576 0.54708097 0.54536026 0.54590619\n",
      " 0.5530635  0.55177084 0.5522842  0.5279658  0.52944563 0.52772303\n",
      " 0.54459335 0.54475889 0.54438823 0.55041063 0.55095613 0.55136422\n",
      " 0.52686394 0.52961087 0.52767053 0.544064   0.54578602 0.54535893\n",
      " 0.55140007 0.55181949 0.55212132 0.53857749 0.53932149 0.53997601\n",
      " 0.54975141 0.55129129 0.55089691 0.55409309 0.55511543 0.55606954\n",
      " 0.53714854 0.53576978 0.53921429 0.54774266 0.54641602 0.5507418\n",
      " 0.55295195 0.5507894  0.55453784 0.53677063 0.536691   0.53715953\n",
      " 0.55054492 0.54787619 0.54836697 0.55493059 0.5508258  0.5531182\n",
      " 0.53721647 0.53799553 0.5406834  0.54590423 0.54775414 0.55044181\n",
      " 0.54752377 0.55015156 0.55427065 0.5379808  0.53709345 0.54118002\n",
      " 0.54686195 0.54676249 0.55177126 0.54958967 0.54851785 0.55484308\n",
      " 0.53782442 0.53527301 0.54007022 0.54689376 0.54523283 0.5492933\n",
      " 0.54979335 0.54826678 0.55104662 0.53967093 0.54407469 0.54202989\n",
      " 0.54574565 0.55033407 0.55151055 0.54820557 0.55370391 0.55282179\n",
      " 0.53909698 0.54309563 0.54274466 0.54555508 0.5494678  0.55161264\n",
      " 0.54959043 0.55225104 0.55274602 0.53902977 0.54288154 0.5423687\n",
      " 0.54654368 0.55056515 0.55171756 0.55027151 0.55206245 0.55334421\n",
      " 0.53901372 0.54409867 0.54421634 0.54097272 0.54944117 0.54914895\n",
      " 0.54074766 0.55022238 0.54828609 0.53959526 0.54495181 0.54204948\n",
      " 0.5438188  0.55048923 0.54678785 0.54340356 0.55130256 0.5463318\n",
      " 0.53879413 0.54359469 0.5444841  0.54095414 0.54836784 0.54955059\n",
      " 0.53828828 0.54756929 0.54862602 0.53639364 0.53652155 0.54121381\n",
      " 0.53839391 0.54048951 0.54541424 0.53675253 0.539968   0.54630771\n",
      " 0.53847479 0.53569448 0.53660376 0.5404773  0.53778271 0.54051527\n",
      " 0.53915599 0.53815363 0.54102236 0.54023005 0.53476909 0.53832542\n",
      " 0.54142171 0.53610529 0.54029283 0.5388246  0.535281   0.54110237\n",
      " 0.4888622  0.48602374 0.48404917 0.50684378 0.50513005 0.50353926\n",
      " 0.51832603 0.51691571 0.51549558 0.48845711 0.48584804 0.48388853\n",
      " 0.50640522 0.50543213 0.50339993 0.51776397 0.51749353 0.51581887\n",
      " 0.48849163 0.48634545 0.48379929 0.506954   0.5054488  0.5031386\n",
      " 0.51785255 0.5174788  0.51569662 0.50776974 0.50516319 0.50448247\n",
      " 0.52090397 0.51986762 0.51847484 0.53098355 0.53046788 0.52922248\n",
      " 0.5074454  0.5056722  0.50439489 0.52029489 0.52024485 0.51862373\n",
      " 0.530818   0.53035716 0.52923421 0.50660606 0.50486015 0.50435792\n",
      " 0.51978157 0.51888591 0.51868654 0.5298798  0.52859899 0.5284865\n",
      " 0.51592087 0.5140358  0.51165202 0.52716299 0.52591626 0.52355556\n",
      " 0.53583006 0.53448492 0.53208881 0.51535904 0.51449878 0.51260398\n",
      " 0.52649059 0.52535727 0.52450643 0.53491941 0.53358539 0.5320792\n",
      " 0.51521325 0.5147563  0.51281216 0.52501321 0.52535222 0.52311826\n",
      " 0.53356344 0.53295148 0.53067964 0.52961205 0.52811963 0.52808908\n",
      " 0.54758737 0.54546219 0.54538113 0.55386015 0.55247621 0.5519691\n",
      " 0.52680727 0.52887593 0.52829757 0.54355447 0.5456819  0.54562222\n",
      " 0.55058796 0.55242957 0.55265441 0.52923555 0.52897799 0.52879998\n",
      " 0.54566299 0.54640039 0.54638953 0.55293822 0.55307691 0.55236612\n",
      " 0.53560561 0.53979072 0.53715455 0.54764406 0.55251666 0.54918959\n",
      " 0.55194276 0.5563043  0.5525097  0.53805116 0.53698073 0.53916423\n",
      " 0.55085598 0.55054449 0.54924994 0.55404592 0.55434704 0.55370824\n",
      " 0.53575821 0.53520865 0.53826613 0.54729104 0.54871519 0.54845449\n",
      " 0.55230106 0.55208843 0.55306698 0.53888594 0.53507129 0.53986648\n",
      " 0.54819105 0.54615027 0.54861546 0.55046668 0.54841858 0.55038806\n",
      " 0.53753619 0.53508357 0.53717035 0.54624415 0.5448062  0.54777627\n",
      " 0.54804538 0.54709592 0.55050468 0.53456836 0.53703379 0.54130232\n",
      " 0.54470341 0.5477457  0.55058534 0.5475338  0.54932991 0.55370637\n",
      " 0.54246315 0.54311712 0.54216372 0.54887682 0.55388248 0.55074056\n",
      " 0.55243959 0.55472921 0.55213289 0.53963003 0.54286294 0.54254502\n",
      " 0.54691418 0.55201018 0.55170185 0.54982356 0.55276907 0.55320072\n",
      " 0.5419918  0.54274032 0.54631447 0.5479844  0.55258048 0.55450497\n",
      " 0.5515751  0.55450748 0.55652266 0.54332809 0.54365587 0.54760701\n",
      " 0.54649266 0.54790354 0.55130906 0.5458538  0.548643   0.55203572\n",
      " 0.54010062 0.54370514 0.54583465 0.54392992 0.54775696 0.55088782\n",
      " 0.54427247 0.54847825 0.55218888 0.53971437 0.54539886 0.54832814\n",
      " 0.5433383  0.55163179 0.55181761 0.54354148 0.5503729  0.55102259\n",
      " 0.5420585  0.53977113 0.54613786 0.54271128 0.54447424 0.54907549\n",
      " 0.54321577 0.54394197 0.54907848 0.53526713 0.53679442 0.54511403\n",
      " 0.53683308 0.53957793 0.54746054 0.53375544 0.53872957 0.54813979\n",
      " 0.53810229 0.53887006 0.54494044 0.54087839 0.54252125 0.54775909\n",
      " 0.5382403  0.53977962 0.5469543 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch Best Parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 300, 'subsample': 0.9}\n",
      "GridSearch Best CV Spearman Correlation: 0.5565226599136056\n",
      "Validation Spearman Correlation (GridSearch): 0.5611624821407921\n",
      "Sample submission file 'lyeshouri14.csv' generated successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.stats import spearmanr\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# --- Load Dataset ---\n",
    "train_data = pd.read_csv(\"train.csv\")  # Format: id, text, score\n",
    "val_data = pd.read_csv(\"val.csv\")      # Format: id, text, score\n",
    "test_data = pd.read_csv(\"test.csv\")    # Format: id, text\n",
    "\n",
    "# --- Define Spearman Correlation Metric ---\n",
    "def spearman_correlation(y_true, y_pred):\n",
    "    return spearmanr(y_true, y_pred).correlation\n",
    "\n",
    "# --- Preprocessing ---\n",
    "def preprocess_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove stopwords\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    return text\n",
    "\n",
    "train_data[\"cleaned_text\"] = train_data[\"text\"].apply(preprocess_text)\n",
    "val_data[\"cleaned_text\"] = val_data[\"text\"].apply(preprocess_text)\n",
    "test_data[\"cleaned_text\"] = test_data[\"text\"].apply(preprocess_text)\n",
    "\n",
    "# --- TF-IDF Features ---\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words=\"english\"\n",
    ")\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(train_data[\"cleaned_text\"]).toarray()\n",
    "X_val_tfidf = tfidf.transform(val_data[\"cleaned_text\"]).toarray()\n",
    "X_test_tfidf = tfidf.transform(test_data[\"cleaned_text\"]).toarray()\n",
    "\n",
    "# --- Word2Vec Training ---\n",
    "train_sentences = train_data[\"cleaned_text\"].apply(lambda x: x.split())\n",
    "val_sentences = val_data[\"cleaned_text\"].apply(lambda x: x.split())\n",
    "test_sentences = test_data[\"cleaned_text\"].apply(lambda x: x.split())\n",
    "\n",
    "word2vec_model = Word2Vec(sentences=train_sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "def get_sentence_embedding(sentences, model, vector_size):\n",
    "    embeddings = []\n",
    "    for sentence in sentences:\n",
    "        vectors = [model.wv[word] for word in sentence if word in model.wv]\n",
    "        if vectors:\n",
    "            embeddings.append(np.mean(vectors, axis=0))\n",
    "        else:\n",
    "            embeddings.append(np.zeros(vector_size))\n",
    "    return np.array(embeddings)\n",
    "\n",
    "X_train_word2vec = get_sentence_embedding(train_sentences, word2vec_model, vector_size=100)\n",
    "X_val_word2vec = get_sentence_embedding(val_sentences, word2vec_model, vector_size=100)\n",
    "X_test_word2vec = get_sentence_embedding(test_sentences, word2vec_model, vector_size=100)\n",
    "\n",
    "# --- Combine Features ---\n",
    "X_train = np.hstack((X_train_tfidf, X_train_word2vec))\n",
    "X_val = np.hstack((X_val_tfidf, X_val_word2vec))\n",
    "X_test = np.hstack((X_test_tfidf, X_test_word2vec))\n",
    "y_train = train_data[\"score\"]\n",
    "y_val = val_data[\"score\"]\n",
    "\n",
    "# --- Grid Search for Hyperparameter Tuning ---\n",
    "param_grid = {\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"max_depth\": [4, 6, 8],\n",
    "    \"min_child_weight\": [1, 2, 3],\n",
    "    \"subsample\": [0.7, 0.8, 0.9],\n",
    "    \"colsample_bytree\": [0.7, 0.8, 0.9],\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "}\n",
    "\n",
    "xgb_model = XGBRegressor(objective=\"reg:squarederror\", random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=make_scorer(spearman_correlation),\n",
    "    cv=3,\n",
    "    verbose=10,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best Parameters and Model\n",
    "best_xgb_model = grid_search.best_estimator_\n",
    "print(\"GridSearch Best Parameters:\", grid_search.best_params_)\n",
    "print(\"GridSearch Best CV Spearman Correlation:\", grid_search.best_score_)\n",
    "\n",
    "# --- Evaluate on Validation Set ---\n",
    "y_val_pred = best_xgb_model.predict(X_val)\n",
    "val_spearman_corr = spearman_correlation(y_val, y_val_pred)\n",
    "print(\"Validation Spearman Correlation (GridSearch):\", val_spearman_corr)\n",
    "\n",
    "# --- Generate Predictions for Test Set ---\n",
    "y_test_pred = best_xgb_model.predict(X_test)\n",
    "\n",
    "# --- Create Sample Submission ---\n",
    "submission = pd.DataFrame({\"id\": test_data[\"id\"], \"score\": y_test_pred})\n",
    "submission.to_csv(\"lyeshouri14.csv\", index=False)\n",
    "print(\"Sample submission file 'lyeshouri14.csv' generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\RoG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Ridge Regression with TF-IDF + Word2Vec Features...\n",
      "Validation Spearman Correlation (TF-IDF + Word2Vec + Ridge): 0.5849440402791134\n",
      "Sample submission file 'submission_ridge_tfidf_word2vec.csv' generated successfully!\n",
      "\n",
      "Training Ridge Regression with Word2Vec Features Only...\n",
      "Validation Spearman Correlation (Word2Vec + Ridge): 0.5087024394610922\n",
      "Sample submission file 'submission_ridge_word2vec.csv' generated successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.stats import spearmanr\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# --- Load Dataset ---\n",
    "train_data = pd.read_csv(\"train.csv\")  # Format: id, text, score\n",
    "val_data = pd.read_csv(\"val.csv\")      # Format: id, text, score\n",
    "test_data = pd.read_csv(\"test.csv\")    # Format: id, text\n",
    "\n",
    "# --- Define Spearman Correlation Metric ---\n",
    "def spearman_correlation(y_true, y_pred):\n",
    "    return spearmanr(y_true, y_pred).correlation\n",
    "\n",
    "# --- Preprocessing ---\n",
    "def preprocess_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove stopwords\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    return text\n",
    "\n",
    "train_data[\"cleaned_text\"] = train_data[\"text\"].apply(preprocess_text)\n",
    "val_data[\"cleaned_text\"] = val_data[\"text\"].apply(preprocess_text)\n",
    "test_data[\"cleaned_text\"] = test_data[\"text\"].apply(preprocess_text)\n",
    "\n",
    "# --- TF-IDF Features ---\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words=\"english\"\n",
    ")\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(train_data[\"cleaned_text\"]).toarray()\n",
    "X_val_tfidf = tfidf.transform(val_data[\"cleaned_text\"]).toarray()\n",
    "X_test_tfidf = tfidf.transform(test_data[\"cleaned_text\"]).toarray()\n",
    "\n",
    "# --- Word2Vec Training ---\n",
    "train_sentences = train_data[\"cleaned_text\"].apply(lambda x: x.split())\n",
    "val_sentences = val_data[\"cleaned_text\"].apply(lambda x: x.split())\n",
    "test_sentences = test_data[\"cleaned_text\"].apply(lambda x: x.split())\n",
    "\n",
    "word2vec_model = Word2Vec(sentences=train_sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "def get_sentence_embedding(sentences, model, vector_size):\n",
    "    embeddings = []\n",
    "    for sentence in sentences:\n",
    "        vectors = [model.wv[word] for word in sentence if word in model.wv]\n",
    "        if vectors:\n",
    "            embeddings.append(np.mean(vectors, axis=0))\n",
    "        else:\n",
    "            embeddings.append(np.zeros(vector_size))\n",
    "    return np.array(embeddings)\n",
    "\n",
    "X_train_word2vec = get_sentence_embedding(train_sentences, word2vec_model, vector_size=100)\n",
    "X_val_word2vec = get_sentence_embedding(val_sentences, word2vec_model, vector_size=100)\n",
    "X_test_word2vec = get_sentence_embedding(test_sentences, word2vec_model, vector_size=100)\n",
    "\n",
    "# --- Target Variable ---\n",
    "y_train = train_data[\"score\"]\n",
    "y_val = val_data[\"score\"]\n",
    "\n",
    "# --- Ridge Regression with TF-IDF + Word2Vec ---\n",
    "print(\"Training Ridge Regression with TF-IDF + Word2Vec Features...\")\n",
    "X_train_combined = np.hstack((X_train_tfidf, X_train_word2vec))\n",
    "X_val_combined = np.hstack((X_val_tfidf, X_val_word2vec))\n",
    "X_test_combined = np.hstack((X_test_tfidf, X_test_word2vec))\n",
    "\n",
    "ridge_model_combined = Ridge()\n",
    "ridge_model_combined.fit(X_train_combined, y_train)\n",
    "\n",
    "# Evaluate on Validation Set\n",
    "y_val_pred_combined = ridge_model_combined.predict(X_val_combined)\n",
    "val_spearman_corr_combined = spearman_correlation(y_val, y_val_pred_combined)\n",
    "print(\"Validation Spearman Correlation (TF-IDF + Word2Vec + Ridge):\", val_spearman_corr_combined)\n",
    "\n",
    "# Generate Predictions for Test Set\n",
    "y_test_pred_combined = ridge_model_combined.predict(X_test_combined)\n",
    "\n",
    "# Create Sample Submission\n",
    "submission_combined = pd.DataFrame({\"id\": test_data[\"id\"], \"score\": y_test_pred_combined})\n",
    "submission_combined.to_csv(\"silviulungjr33.csv\", index=False)\n",
    "print(\"Sample submission file 'submission_ridge_tfidf_word2vec.csv' generated successfully!\")\n",
    "\n",
    "# --- Ridge Regression with Word2Vec Only ---\n",
    "print(\"\\nTraining Ridge Regression with Word2Vec Features Only...\")\n",
    "ridge_model_word2vec = Ridge()\n",
    "ridge_model_word2vec.fit(X_train_word2vec, y_train)\n",
    "\n",
    "# Evaluate on Validation Set\n",
    "y_val_pred_word2vec = ridge_model_word2vec.predict(X_val_word2vec)\n",
    "val_spearman_corr_word2vec = spearman_correlation(y_val, y_val_pred_word2vec)\n",
    "print(\"Validation Spearman Correlation (Word2Vec + Ridge):\", val_spearman_corr_word2vec)\n",
    "\n",
    "# Generate Predictions for Test Set\n",
    "y_test_pred_word2vec = ridge_model_word2vec.predict(X_test_word2vec)\n",
    "\n",
    "# Create Sample Submission\n",
    "submission_word2vec = pd.DataFrame({\"id\": test_data[\"id\"], \"score\": y_test_pred_word2vec})\n",
    "submission_word2vec.to_csv(\"relustoian32.csv\", index=False)\n",
    "print(\"Sample submission file 'submission_ridge_word2vec.csv' generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\RoG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Best Ridge Parameters: {'alpha': 100}\n",
      "Best Cross-Validation Spearman Correlation: 0.5791215569765563\n",
      "Validation Spearman Correlation (Improved Ridge): 0.6020660564040241\n",
      "Sample submission file 'submission_ridge_improved.csv' generated successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.stats import spearmanr\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# --- Load Dataset ---\n",
    "train_data = pd.read_csv(\"train.csv\")  # Format: id, text, score\n",
    "val_data = pd.read_csv(\"val.csv\")      # Format: id, text, score\n",
    "test_data = pd.read_csv(\"test.csv\")    # Format: id, text\n",
    "\n",
    "# --- Define Spearman Correlation Metric ---\n",
    "def spearman_correlation(y_true, y_pred):\n",
    "    return spearmanr(y_true, y_pred).correlation\n",
    "\n",
    "# --- Preprocessing ---\n",
    "def preprocess_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove stopwords\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    return text\n",
    "\n",
    "train_data[\"cleaned_text\"] = train_data[\"text\"].apply(preprocess_text)\n",
    "val_data[\"cleaned_text\"] = val_data[\"text\"].apply(preprocess_text)\n",
    "test_data[\"cleaned_text\"] = test_data[\"text\"].apply(preprocess_text)\n",
    "\n",
    "# --- TF-IDF Features ---\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words=\"english\"\n",
    ")\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(train_data[\"cleaned_text\"]).toarray()\n",
    "X_val_tfidf = tfidf.transform(val_data[\"cleaned_text\"]).toarray()\n",
    "X_test_tfidf = tfidf.transform(test_data[\"cleaned_text\"]).toarray()\n",
    "\n",
    "# --- Dimensionality Reduction for TF-IDF ---\n",
    "svd = TruncatedSVD(n_components=300, random_state=42)\n",
    "X_train_tfidf_reduced = svd.fit_transform(X_train_tfidf)\n",
    "X_val_tfidf_reduced = svd.transform(X_val_tfidf)\n",
    "X_test_tfidf_reduced = svd.transform(X_test_tfidf)\n",
    "\n",
    "# --- Word2Vec Training ---\n",
    "train_sentences = train_data[\"cleaned_text\"].apply(lambda x: x.split())\n",
    "val_sentences = val_data[\"cleaned_text\"].apply(lambda x: x.split())\n",
    "test_sentences = test_data[\"cleaned_text\"].apply(lambda x: x.split())\n",
    "\n",
    "word2vec_model = Word2Vec(sentences=train_sentences, vector_size=200, window=5, min_count=1, workers=4)\n",
    "\n",
    "def get_sentence_embedding(sentences, model, vector_size):\n",
    "    embeddings = []\n",
    "    for sentence in sentences:\n",
    "        vectors = [model.wv[word] for word in sentence if word in model.wv]\n",
    "        if vectors:\n",
    "            embeddings.append(np.mean(vectors, axis=0))\n",
    "        else:\n",
    "            embeddings.append(np.zeros(vector_size))\n",
    "    return np.array(embeddings)\n",
    "\n",
    "X_train_word2vec = get_sentence_embedding(train_sentences, word2vec_model, vector_size=200)\n",
    "X_val_word2vec = get_sentence_embedding(val_sentences, word2vec_model, vector_size=200)\n",
    "X_test_word2vec = get_sentence_embedding(test_sentences, word2vec_model, vector_size=200)\n",
    "\n",
    "# --- Combine Features ---\n",
    "X_train_combined = np.hstack((X_train_tfidf_reduced, X_train_word2vec))\n",
    "X_val_combined = np.hstack((X_val_tfidf_reduced, X_val_word2vec))\n",
    "X_test_combined = np.hstack((X_test_tfidf_reduced, X_test_word2vec))\n",
    "\n",
    "# Normalize Features\n",
    "scaler = StandardScaler()\n",
    "X_train_combined = scaler.fit_transform(X_train_combined)\n",
    "X_val_combined = scaler.transform(X_val_combined)\n",
    "X_test_combined = scaler.transform(X_test_combined)\n",
    "\n",
    "# --- Target Variable ---\n",
    "y_train = train_data[\"score\"]\n",
    "y_val = val_data[\"score\"]\n",
    "\n",
    "# --- Ridge Regression with Hyperparameter Tuning ---\n",
    "param_grid = {\n",
    "    \"alpha\": [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "}\n",
    "\n",
    "ridge_model = Ridge()\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=ridge_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=make_scorer(spearman_correlation),\n",
    "    cv=3,\n",
    "    verbose=10,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_combined, y_train)\n",
    "\n",
    "# Best Parameters and Model\n",
    "best_ridge_model = grid_search.best_estimator_\n",
    "print(\"Best Ridge Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Spearman Correlation:\", grid_search.best_score_)\n",
    "\n",
    "# --- Evaluate on Validation Set ---\n",
    "y_val_pred_combined = best_ridge_model.predict(X_val_combined)\n",
    "val_spearman_corr_combined = spearman_correlation(y_val, y_val_pred_combined)\n",
    "print(\"Validation Spearman Correlation (Improved Ridge):\", val_spearman_corr_combined)\n",
    "\n",
    "# --- Generate Predictions for Test Set ---\n",
    "y_test_pred_combined = best_ridge_model.predict(X_test_combined)\n",
    "\n",
    "# --- Create Sample Submission ---\n",
    "submission_combined = pd.DataFrame({\"id\": test_data[\"id\"], \"score\": y_test_pred_combined})\n",
    "submission_combined.to_csv(\"stefanbana31.csv\", index=False)\n",
    "print(\"Sample submission file 'submission_ridge_improved.csv' generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\RoG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Best Ridge Parameters: {'alpha': 500}\n",
      "Best Cross-Validation Spearman Correlation: 0.588936667929304\n",
      "Validation Spearman Correlation (Improved Ridge): 0.605014086634251\n",
      "Sample submission file 'submission_ridge_improved.csv' generated successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.stats import spearmanr\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# --- Load Dataset ---\n",
    "train_data = pd.read_csv(\"train.csv\")  # Format: id, text, score\n",
    "val_data = pd.read_csv(\"val.csv\")      # Format: id, text, score\n",
    "test_data = pd.read_csv(\"test.csv\")    # Format: id, text\n",
    "\n",
    "# --- Define Spearman Correlation Metric ---\n",
    "def spearman_correlation(y_true, y_pred):\n",
    "    return spearmanr(y_true, y_pred).correlation\n",
    "\n",
    "# --- Preprocessing ---\n",
    "def preprocess_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove stopwords\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    return text\n",
    "\n",
    "train_data[\"cleaned_text\"] = train_data[\"text\"].apply(preprocess_text)\n",
    "val_data[\"cleaned_text\"] = val_data[\"text\"].apply(preprocess_text)\n",
    "test_data[\"cleaned_text\"] = test_data[\"text\"].apply(preprocess_text)\n",
    "\n",
    "# --- Additional Sentence Features ---\n",
    "def extract_sentence_features(df):\n",
    "    df[\"sentence_length\"] = df[\"text\"].apply(len)\n",
    "    df[\"word_count\"] = df[\"text\"].apply(lambda x: len(x.split()))\n",
    "    df[\"punctuation_count\"] = df[\"text\"].str.count(r'[^\\w\\s]')\n",
    "    return df[[\"sentence_length\", \"word_count\", \"punctuation_count\"]]\n",
    "\n",
    "train_sentence_features = extract_sentence_features(train_data)\n",
    "val_sentence_features = extract_sentence_features(val_data)\n",
    "test_sentence_features = extract_sentence_features(test_data)\n",
    "\n",
    "# --- TF-IDF Features ---\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=10000,  # Increased size\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words=\"english\"\n",
    ")\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(train_data[\"cleaned_text\"]).toarray()\n",
    "X_val_tfidf = tfidf.transform(val_data[\"cleaned_text\"]).toarray()\n",
    "X_test_tfidf = tfidf.transform(test_data[\"cleaned_text\"]).toarray()\n",
    "\n",
    "# --- Dimensionality Reduction for TF-IDF ---\n",
    "svd = TruncatedSVD(n_components=300, random_state=42)\n",
    "X_train_tfidf_reduced = svd.fit_transform(X_train_tfidf)\n",
    "X_val_tfidf_reduced = svd.transform(X_val_tfidf)\n",
    "X_test_tfidf_reduced = svd.transform(X_test_tfidf)\n",
    "\n",
    "# --- Word2Vec Training ---\n",
    "train_sentences = train_data[\"cleaned_text\"].apply(lambda x: x.split())\n",
    "val_sentences = val_data[\"cleaned_text\"].apply(lambda x: x.split())\n",
    "test_sentences = test_data[\"cleaned_text\"].apply(lambda x: x.split())\n",
    "\n",
    "word2vec_model = Word2Vec(sentences=train_sentences, vector_size=300, window=10, min_count=1, workers=4, epochs=20)\n",
    "\n",
    "def get_sentence_embedding(sentences, model, vector_size):\n",
    "    embeddings = []\n",
    "    for sentence in sentences:\n",
    "        vectors = [model.wv[word] for word in sentence if word in model.wv]\n",
    "        if vectors:\n",
    "            embeddings.append(np.mean(vectors, axis=0))\n",
    "        else:\n",
    "            embeddings.append(np.zeros(vector_size))\n",
    "    return np.array(embeddings)\n",
    "\n",
    "X_train_word2vec = get_sentence_embedding(train_sentences, word2vec_model, vector_size=300)\n",
    "X_val_word2vec = get_sentence_embedding(val_sentences, word2vec_model, vector_size=300)\n",
    "X_test_word2vec = get_sentence_embedding(test_sentences, word2vec_model, vector_size=300)\n",
    "\n",
    "# --- Polynomial Features ---\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train_word2vec)\n",
    "X_val_poly = poly.transform(X_val_word2vec)\n",
    "X_test_poly = poly.transform(X_test_word2vec)\n",
    "\n",
    "# --- Combine Features ---\n",
    "X_train_combined = np.hstack((X_train_tfidf_reduced, X_train_word2vec, train_sentence_features.values))\n",
    "X_val_combined = np.hstack((X_val_tfidf_reduced, X_val_word2vec, val_sentence_features.values))\n",
    "X_test_combined = np.hstack((X_test_tfidf_reduced, X_test_word2vec, test_sentence_features.values))\n",
    "\n",
    "# Normalize Features\n",
    "scaler = StandardScaler()\n",
    "X_train_combined = scaler.fit_transform(X_train_combined)\n",
    "X_val_combined = scaler.transform(X_val_combined)\n",
    "X_test_combined = scaler.transform(X_test_combined)\n",
    "\n",
    "# --- Target Variable ---\n",
    "y_train = train_data[\"score\"]\n",
    "y_val = val_data[\"score\"]\n",
    "\n",
    "# --- Ridge Regression with Hyperparameter Tuning ---\n",
    "param_grid = {\n",
    "    \"alpha\": [0.01, 0.1, 1, 10, 100, 500],  # Expanded range\n",
    "}\n",
    "\n",
    "ridge_model = Ridge()\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=ridge_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=make_scorer(spearman_correlation),\n",
    "    cv=5,  # Increased folds for stability\n",
    "    verbose=10,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_combined, y_train)\n",
    "\n",
    "# Best Parameters and Model\n",
    "best_ridge_model = grid_search.best_estimator_\n",
    "print(\"Best Ridge Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Spearman Correlation:\", grid_search.best_score_)\n",
    "\n",
    "# --- Evaluate on Validation Set ---\n",
    "y_val_pred_combined = best_ridge_model.predict(X_val_combined)\n",
    "val_spearman_corr_combined = spearman_correlation(y_val, y_val_pred_combined)\n",
    "print(\"Validation Spearman Correlation (Improved Ridge):\", val_spearman_corr_combined)\n",
    "\n",
    "# --- Generate Predictions for Test Set ---\n",
    "y_test_pred_combined = best_ridge_model.predict(X_test_combined)\n",
    "\n",
    "# --- Create Sample Submission ---\n",
    "submission_combined = pd.DataFrame({\"id\": test_data[\"id\"], \"score\": y_test_pred_combined})\n",
    "submission_combined.to_csv(\"mariandanciu37.csv\", index=False)\n",
    "print(\"Sample submission file 'submission_ridge_improved.csv' generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\RoG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best Ridge Parameters: {'alpha': 1000.0}\n",
      "Best Cross-Validation Spearman Correlation: 0.5749472848816216\n",
      "Validation Spearman Correlation (Improved Ridge): 0.5763983917988468\n",
      "Sample submission file 'davidbarbu27.csv' generated successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.stats import spearmanr\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# --- Load Dataset ---\n",
    "train_data = pd.read_csv(\"train.csv\")  # Format: id, text, score\n",
    "val_data = pd.read_csv(\"val.csv\")      # Format: id, text, score\n",
    "test_data = pd.read_csv(\"test.csv\")    # Format: id, text\n",
    "\n",
    "# --- Define Spearman Correlation Metric ---\n",
    "def spearman_correlation(y_true, y_pred):\n",
    "    return spearmanr(y_true, y_pred).correlation\n",
    "\n",
    "# --- Preprocessing ---\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)  # Remove stopwords\n",
    "    return text\n",
    "\n",
    "train_data[\"cleaned_text\"] = train_data[\"text\"].apply(preprocess_text)\n",
    "val_data[\"cleaned_text\"] = val_data[\"text\"].apply(preprocess_text)\n",
    "test_data[\"cleaned_text\"] = test_data[\"text\"].apply(preprocess_text)\n",
    "\n",
    "# --- Additional Sentence Features ---\n",
    "def extract_sentence_features(df):\n",
    "    df[\"sentence_length\"] = df[\"text\"].apply(len)\n",
    "    df[\"word_count\"] = df[\"text\"].apply(lambda x: len(x.split()))\n",
    "    df[\"punctuation_count\"] = df[\"text\"].str.count(r'[^\\w\\s]')\n",
    "    return df[[\"sentence_length\", \"word_count\", \"punctuation_count\"]]\n",
    "\n",
    "train_sentence_features = extract_sentence_features(train_data)\n",
    "val_sentence_features = extract_sentence_features(val_data)\n",
    "test_sentence_features = extract_sentence_features(test_data)\n",
    "\n",
    "# --- TF-IDF Features ---\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=10000,  # Larger size for richer features\n",
    "    ngram_range=(1, 3),  # Increased n-gram range\n",
    "    stop_words=\"english\"\n",
    ")\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(train_data[\"cleaned_text\"]).toarray()\n",
    "X_val_tfidf = tfidf.transform(val_data[\"cleaned_text\"]).toarray()\n",
    "X_test_tfidf = tfidf.transform(test_data[\"cleaned_text\"]).toarray()\n",
    "\n",
    "# --- Dimensionality Reduction for TF-IDF ---\n",
    "svd = TruncatedSVD(n_components=500, random_state=42)  # Reduce TF-IDF to 500 dimensions\n",
    "X_train_tfidf_reduced = svd.fit_transform(X_train_tfidf)\n",
    "X_val_tfidf_reduced = svd.transform(X_val_tfidf)\n",
    "X_test_tfidf_reduced = svd.transform(X_test_tfidf)\n",
    "\n",
    "# --- Word2Vec Training ---\n",
    "train_sentences = train_data[\"cleaned_text\"].apply(lambda x: x.split())\n",
    "val_sentences = val_data[\"cleaned_text\"].apply(lambda x: x.split())\n",
    "test_sentences = test_data[\"cleaned_text\"].apply(lambda x: x.split())\n",
    "\n",
    "word2vec_model = Word2Vec(\n",
    "    sentences=train_sentences, \n",
    "    vector_size=300,  # Larger vector size\n",
    "    window=10,  # Wider context\n",
    "    min_count=1, \n",
    "    workers=4, \n",
    "    epochs=20  # Increased epochs for better embeddings\n",
    ")\n",
    "\n",
    "def get_sentence_embedding(sentences, model, vector_size):\n",
    "    embeddings = []\n",
    "    for sentence in sentences:\n",
    "        vectors = [model.wv[word] for word in sentence if word in model.wv]\n",
    "        if vectors:\n",
    "            embeddings.append(np.mean(vectors, axis=0))\n",
    "        else:\n",
    "            embeddings.append(np.zeros(vector_size))\n",
    "    return np.array(embeddings)\n",
    "\n",
    "X_train_word2vec = get_sentence_embedding(train_sentences, word2vec_model, vector_size=300)\n",
    "X_val_word2vec = get_sentence_embedding(val_sentences, word2vec_model, vector_size=300)\n",
    "X_test_word2vec = get_sentence_embedding(test_sentences, word2vec_model, vector_size=300)\n",
    "\n",
    "# --- Dimensionality Reduction for Word2Vec ---\n",
    "svd_word2vec = TruncatedSVD(n_components=50, random_state=42)  # Reduce Word2Vec to 50 dimensions\n",
    "X_train_word2vec_reduced = svd_word2vec.fit_transform(X_train_word2vec)\n",
    "X_val_word2vec_reduced = svd_word2vec.transform(X_val_word2vec)\n",
    "X_test_word2vec_reduced = svd_word2vec.transform(X_test_word2vec)\n",
    "\n",
    "# --- Polynomial Features on Reduced Word2Vec ---\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)  # Reduced degree\n",
    "X_train_poly = poly.fit_transform(X_train_word2vec_reduced)\n",
    "X_val_poly = poly.transform(X_val_word2vec_reduced)\n",
    "X_test_poly = poly.transform(X_test_word2vec_reduced)\n",
    "\n",
    "# --- Combine Features ---\n",
    "X_train_combined = np.hstack((X_train_tfidf_reduced, X_train_poly, train_sentence_features.values))\n",
    "X_val_combined = np.hstack((X_val_tfidf_reduced, X_val_poly, val_sentence_features.values))\n",
    "X_test_combined = np.hstack((X_test_tfidf_reduced, X_test_poly, test_sentence_features.values))\n",
    "\n",
    "# Normalize Features\n",
    "scaler = StandardScaler()\n",
    "X_train_combined = scaler.fit_transform(X_train_combined)\n",
    "X_val_combined = scaler.transform(X_val_combined)\n",
    "X_test_combined = scaler.transform(X_test_combined)\n",
    "\n",
    "# --- Target Variable ---\n",
    "y_train = train_data[\"score\"]\n",
    "y_val = val_data[\"score\"]\n",
    "\n",
    "# --- Ridge Regression with Hyperparameter Tuning ---\n",
    "param_grid = {\n",
    "    \"alpha\": np.logspace(-2, 3, 10)  # Expanded range with finer granularity\n",
    "}\n",
    "\n",
    "ridge_model = Ridge()\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=ridge_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=make_scorer(spearman_correlation),\n",
    "    cv=5,  # Increased folds for better generalization\n",
    "    verbose=10,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_combined, y_train)\n",
    "\n",
    "# Best Parameters and Model\n",
    "best_ridge_model = grid_search.best_estimator_\n",
    "print(\"Best Ridge Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Spearman Correlation:\", grid_search.best_score_)\n",
    "\n",
    "# --- Evaluate on Validation Set ---\n",
    "y_val_pred_combined = best_ridge_model.predict(X_val_combined)\n",
    "val_spearman_corr_combined = spearman_correlation(y_val, y_val_pred_combined)\n",
    "print(\"Validation Spearman Correlation (Improved Ridge):\", val_spearman_corr_combined)\n",
    "\n",
    "# --- Generate Predictions for Test Set ---\n",
    "y_test_pred_combined = best_ridge_model.predict(X_test_combined)\n",
    "\n",
    "# --- Create Sample Submission ---\n",
    "submission_combined = pd.DataFrame({\"id\": test_data[\"id\"], \"score\": y_test_pred_combined})\n",
    "submission_combined.to_csv(\"davidbarbu27.csv\", index=False)\n",
    "print(\"Sample submission file 'davidbarbu27.csv' generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\RoG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 15 candidates, totalling 150 fits\n",
      "Best Ridge Parameters: {'alpha': 1000.0}\n",
      "Best Cross-Validation Spearman Correlation: 0.49722463175314013\n",
      "Validation Spearman Correlation (Improved Ridge): 0.46857148077465377\n",
      "Sample submission file 'submission_ridge_optimized.csv' generated successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.stats import spearmanr\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# --- Load Dataset ---\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "val_data = pd.read_csv(\"val.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# --- Define Spearman Correlation Metric ---\n",
    "def spearman_correlation(y_true, y_pred):\n",
    "    return spearmanr(y_true, y_pred).correlation\n",
    "\n",
    "# --- Preprocessing ---\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    return text\n",
    "\n",
    "train_data[\"cleaned_text\"] = train_data[\"text\"].apply(preprocess_text)\n",
    "val_data[\"cleaned_text\"] = val_data[\"text\"].apply(preprocess_text)\n",
    "test_data[\"cleaned_text\"] = test_data[\"text\"].apply(preprocess_text)\n",
    "\n",
    "# --- Additional Sentence Features ---\n",
    "def extract_sentence_features(df):\n",
    "    df[\"sentence_length\"] = df[\"text\"].apply(len)\n",
    "    df[\"word_count\"] = df[\"text\"].apply(lambda x: len(x.split()))\n",
    "    df[\"punctuation_count\"] = df[\"text\"].str.count(r'[^\\w\\s]')\n",
    "    return df[[\"sentence_length\", \"word_count\", \"punctuation_count\"]]\n",
    "\n",
    "train_sentence_features = extract_sentence_features(train_data)\n",
    "val_sentence_features = extract_sentence_features(val_data)\n",
    "test_sentence_features = extract_sentence_features(test_data)\n",
    "\n",
    "# --- TF-IDF Features ---\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    ngram_range=(1, 3),\n",
    "    stop_words=\"english\"\n",
    ")\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(train_data[\"cleaned_text\"]).toarray()\n",
    "X_val_tfidf = tfidf.transform(val_data[\"cleaned_text\"]).toarray()\n",
    "X_test_tfidf = tfidf.transform(test_data[\"cleaned_text\"]).toarray()\n",
    "\n",
    "# --- Dimensionality Reduction for TF-IDF ---\n",
    "svd_tfidf = TruncatedSVD(n_components=400, random_state=42)\n",
    "X_train_tfidf_reduced = svd_tfidf.fit_transform(X_train_tfidf)\n",
    "X_val_tfidf_reduced = svd_tfidf.transform(X_val_tfidf)\n",
    "X_test_tfidf_reduced = svd_tfidf.transform(X_test_tfidf)\n",
    "\n",
    "# --- Word2Vec Training ---\n",
    "train_sentences = train_data[\"cleaned_text\"].apply(lambda x: x.split())\n",
    "val_sentences = val_data[\"cleaned_text\"].apply(lambda x: x.split())\n",
    "test_sentences = test_data[\"cleaned_text\"].apply(lambda x: x.split())\n",
    "\n",
    "word2vec_model = Word2Vec(\n",
    "    sentences=train_sentences,\n",
    "    vector_size=400,\n",
    "    window=10,\n",
    "    min_count=1,\n",
    "    workers=4,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "def get_sentence_embedding(sentences, model, vector_size):\n",
    "    embeddings = []\n",
    "    for sentence in sentences:\n",
    "        vectors = [model.wv[word] for word in sentence if word in model.wv]\n",
    "        if vectors:\n",
    "            embeddings.append(np.mean(vectors, axis=0))\n",
    "        else:\n",
    "            embeddings.append(np.zeros(vector_size))\n",
    "    return np.array(embeddings)\n",
    "\n",
    "X_train_word2vec = get_sentence_embedding(train_sentences, word2vec_model, vector_size=400)\n",
    "X_val_word2vec = get_sentence_embedding(val_sentences, word2vec_model, vector_size=400)\n",
    "X_test_word2vec = get_sentence_embedding(test_sentences, word2vec_model, vector_size=400)\n",
    "\n",
    "# --- Dimensionality Reduction for Word2Vec ---\n",
    "svd_word2vec = TruncatedSVD(n_components=100, random_state=42)\n",
    "X_train_word2vec_reduced = svd_word2vec.fit_transform(X_train_word2vec)\n",
    "X_val_word2vec_reduced = svd_word2vec.transform(X_val_word2vec)\n",
    "X_test_word2vec_reduced = svd_word2vec.transform(X_test_word2vec)\n",
    "\n",
    "# --- Polynomial Features on Reduced Word2Vec ---\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train_word2vec_reduced)\n",
    "X_val_poly = poly.transform(X_val_word2vec_reduced)\n",
    "X_test_poly = poly.transform(X_test_word2vec_reduced)\n",
    "\n",
    "# --- Combine Features ---\n",
    "X_train_combined = np.hstack((X_train_tfidf_reduced, X_train_poly, train_sentence_features.values))\n",
    "X_val_combined = np.hstack((X_val_tfidf_reduced, X_val_poly, val_sentence_features.values))\n",
    "X_test_combined = np.hstack((X_test_tfidf_reduced, X_test_poly, test_sentence_features.values))\n",
    "\n",
    "# Normalize Features\n",
    "scaler = StandardScaler()\n",
    "X_train_combined = scaler.fit_transform(X_train_combined)\n",
    "X_val_combined = scaler.transform(X_val_combined)\n",
    "X_test_combined = scaler.transform(X_test_combined)\n",
    "\n",
    "# --- Target Variable ---\n",
    "y_train = train_data[\"score\"]\n",
    "y_val = val_data[\"score\"]\n",
    "\n",
    "# --- Ridge Regression with Hyperparameter Tuning ---\n",
    "param_grid = {\n",
    "    \"alpha\": np.logspace(-2, 3, 15)\n",
    "}\n",
    "\n",
    "ridge_model = Ridge()\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=ridge_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=make_scorer(spearman_correlation),\n",
    "    cv=10,\n",
    "    verbose=10,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_combined, y_train)\n",
    "\n",
    "# Best Parameters and Model\n",
    "best_ridge_model = grid_search.best_estimator_\n",
    "print(\"Best Ridge Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Spearman Correlation:\", grid_search.best_score_)\n",
    "\n",
    "# --- Evaluate on Validation Set ---\n",
    "y_val_pred_combined = best_ridge_model.predict(X_val_combined)\n",
    "val_spearman_corr_combined = spearman_correlation(y_val, y_val_pred_combined)\n",
    "print(\"Validation Spearman Correlation (Improved Ridge):\", val_spearman_corr_combined)\n",
    "\n",
    "# --- Generate Predictions for Test Set ---\n",
    "y_test_pred_combined = best_ridge_model.predict(X_test_combined)\n",
    "\n",
    "# --- Create Sample Submission ---\n",
    "submission_combined = pd.DataFrame({\"id\": test_data[\"id\"], \"score\": y_test_pred_combined})\n",
    "submission_combined.to_csv(\"jurajbadelj15.csv\", index=False)\n",
    "print(\"Sample submission file 'submission_ridge_optimized.csv' generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\RoG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 50 folds for each of 80 candidates, totalling 4000 fits\n",
      "Best Ridge Parameters: {'alpha': 1689.849786812462}\n",
      "Best Cross-Validation Spearman Correlation: 0.5768633211688421\n",
      "Validation Spearman Correlation (Optimized Ridge): 0.5756855052752906\n",
      "Sample submission file 'submission_word2vec_ridge_advanced.csv' generated successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.stats import spearmanr\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# --- Load Dataset ---\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "val_data = pd.read_csv(\"val.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# --- Define Spearman Correlation Metric ---\n",
    "def spearman_correlation(y_true, y_pred):\n",
    "    return spearmanr(y_true, y_pred).correlation\n",
    "\n",
    "# --- Preprocessing ---\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = ' '.join(stemmer.stem(word) for word in text.split() if word not in stop_words)  # Stemming and stopwords\n",
    "    return text\n",
    "\n",
    "train_data[\"cleaned_text\"] = train_data[\"text\"].apply(preprocess_text)\n",
    "val_data[\"cleaned_text\"] = val_data[\"text\"].apply(preprocess_text)\n",
    "test_data[\"cleaned_text\"] = test_data[\"text\"].apply(preprocess_text)\n",
    "\n",
    "# Combine Training and Validation Data for Word2Vec\n",
    "combined_sentences = pd.concat([train_data[\"cleaned_text\"], val_data[\"cleaned_text\"]]).apply(lambda x: x.split())\n",
    "\n",
    "# --- Word2Vec Training ---\n",
    "word2vec_model = Word2Vec(\n",
    "    sentences=combined_sentences,\n",
    "    vector_size=400,  # Larger vector size\n",
    "    window=8,  # Adjusted window size\n",
    "    min_count=2,  # Further filter rare words\n",
    "    workers=8,  # Utilize maximum parallelism\n",
    "    epochs=300,  # Further increased epochs\n",
    "    sg=1,  # Skip-gram model\n",
    "    negative=15  # Negative sampling\n",
    ")\n",
    "\n",
    "def get_sentence_embedding(sentences, model, vector_size):\n",
    "    embeddings = []\n",
    "    for sentence in sentences:\n",
    "        vectors = [model.wv[word] for word in sentence if word in model.wv]\n",
    "        if vectors:\n",
    "            embeddings.append(np.mean(vectors, axis=0))\n",
    "        else:\n",
    "            embeddings.append(np.zeros(vector_size))\n",
    "    return np.array(embeddings)\n",
    "\n",
    "X_train_word2vec = get_sentence_embedding(train_data[\"cleaned_text\"].apply(lambda x: x.split()), word2vec_model, vector_size=400)\n",
    "X_val_word2vec = get_sentence_embedding(val_data[\"cleaned_text\"].apply(lambda x: x.split()), word2vec_model, vector_size=400)\n",
    "X_test_word2vec = get_sentence_embedding(test_data[\"cleaned_text\"].apply(lambda x: x.split()), word2vec_model, vector_size=400)\n",
    "\n",
    "# --- Additional Features ---\n",
    "def extract_features(df):\n",
    "    df[\"sentence_length\"] = df[\"text\"].apply(len)\n",
    "    df[\"word_count\"] = df[\"text\"].apply(lambda x: len(x.split()))\n",
    "    df[\"punctuation_count\"] = df[\"text\"].str.count(r'[^\\w\\s]')\n",
    "    return df[[\"sentence_length\", \"word_count\", \"punctuation_count\"]]\n",
    "\n",
    "train_features = extract_features(train_data)\n",
    "val_features = extract_features(val_data)\n",
    "test_features = extract_features(test_data)\n",
    "\n",
    "# --- Dimensionality Reduction ---\n",
    "svd = TruncatedSVD(n_components=250, random_state=42)  # Experimenting with increased dimensions\n",
    "X_train_reduced = svd.fit_transform(X_train_word2vec)\n",
    "X_val_reduced = svd.transform(X_val_word2vec)\n",
    "X_test_reduced = svd.transform(X_test_word2vec)\n",
    "\n",
    "# Combine Word2Vec and Handcrafted Features\n",
    "X_train_combined = np.hstack((X_train_reduced, train_features.values))\n",
    "X_val_combined = np.hstack((X_val_reduced, val_features.values))\n",
    "X_test_combined = np.hstack((X_test_reduced, test_features.values))\n",
    "\n",
    "# Normalize Features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_combined)\n",
    "X_val_scaled = scaler.transform(X_val_combined)\n",
    "X_test_scaled = scaler.transform(X_test_combined)\n",
    "\n",
    "# --- Target Variable ---\n",
    "y_train = train_data[\"score\"]\n",
    "y_val = val_data[\"score\"]\n",
    "\n",
    "# --- Ridge Regression with Extensive Hyperparameter Tuning ---\n",
    "param_grid = {\n",
    "    \"alpha\": np.logspace(-5, 5, 80)  # Expanded range with finer granularity\n",
    "}\n",
    "\n",
    "ridge_model = Ridge()\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=ridge_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=make_scorer(spearman_correlation),\n",
    "    cv=50,  # Further increased folds for stability\n",
    "    verbose=10,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best Parameters and Model\n",
    "best_ridge_model = grid_search.best_estimator_\n",
    "print(\"Best Ridge Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Spearman Correlation:\", grid_search.best_score_)\n",
    "\n",
    "# --- Evaluate on Validation Set ---\n",
    "y_val_pred = best_ridge_model.predict(X_val_scaled)\n",
    "val_spearman_corr = spearman_correlation(y_val, y_val_pred)\n",
    "print(\"Validation Spearman Correlation (Optimized Ridge):\", val_spearman_corr)\n",
    "\n",
    "# --- Generate Predictions for Test Set ---\n",
    "y_test_pred = best_ridge_model.predict(X_test_scaled)\n",
    "\n",
    "# --- Create Sample Submission ---\n",
    "submission = pd.DataFrame({\"id\": test_data[\"id\"], \"score\": y_test_pred})\n",
    "submission.to_csv(\"gjokozajkov26.csv\", index=False)\n",
    "print(\"Sample submission file 'submission_word2vec_ridge_advanced.csv' generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\RoG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n",
      "Best Ridge Parameters: {'alpha': 910.2981779915227}\n",
      "Best Ridge Spearman CV Score: 0.5734762933159474\n",
      "Fitting 10 folds for each of 81 candidates, totalling 810 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007888 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 51000\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 200\n",
      "[LightGBM] [Info] Start training from score 0.520791\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best LightGBM Parameters: {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 1000, 'num_leaves': 50}\n",
      "Best LightGBM Spearman CV Score: 0.5929619029258858\n",
      "Fitting 10 folds for each of 81 candidates, totalling 810 fits\n",
      "Best XGBoost Parameters: {'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 1000, 'subsample': 0.6}\n",
      "Best XGBoost Spearman CV Score: 0.603313946525784\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 51000\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 200\n",
      "[LightGBM] [Info] Start training from score 0.520791\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Validation Spearman Correlation (Ensemble): 0.6119316194025156\n",
      "Sample submission file 'submission_ensemble.csv' generated successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from scipy.stats import spearmanr\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# --- Load Dataset ---\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "val_data = pd.read_csv(\"val.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# --- Define Spearman Correlation Metric ---\n",
    "def spearman_correlation(y_true, y_pred):\n",
    "    return spearmanr(y_true, y_pred).correlation\n",
    "\n",
    "spearman_scorer = make_scorer(spearman_correlation, greater_is_better=True)\n",
    "\n",
    "# --- Preprocessing ---\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = ' '.join(stemmer.stem(word) for word in text.split() if word not in stop_words)  # Stemming and stopwords\n",
    "    return text\n",
    "\n",
    "train_data[\"cleaned_text\"] = train_data[\"text\"].apply(preprocess_text)\n",
    "val_data[\"cleaned_text\"] = val_data[\"text\"].apply(preprocess_text)\n",
    "test_data[\"cleaned_text\"] = test_data[\"text\"].apply(preprocess_text)\n",
    "\n",
    "# Combine Training and Validation Data for Word2Vec\n",
    "combined_sentences = pd.concat([train_data[\"cleaned_text\"], val_data[\"cleaned_text\"]]).apply(lambda x: x.split())\n",
    "\n",
    "# --- Word2Vec Training ---\n",
    "word2vec_model = Word2Vec(\n",
    "    sentences=combined_sentences,\n",
    "    vector_size=400,  # Larger vector size\n",
    "    window=8,  # Adjusted window size\n",
    "    min_count=2,  # Further filter rare words\n",
    "    workers=8,  # Utilize maximum parallelism\n",
    "    epochs=200,  # Increased epochs\n",
    "    sg=1,  # Skip-gram model\n",
    "    negative=10  # Negative sampling\n",
    ")\n",
    "\n",
    "def get_sentence_embedding(sentences, model, vector_size):\n",
    "    embeddings = []\n",
    "    for sentence in sentences:\n",
    "        vectors = [model.wv[word] for word in sentence if word in model.wv]\n",
    "        if vectors:\n",
    "            embeddings.append(np.mean(vectors, axis=0))\n",
    "        else:\n",
    "            embeddings.append(np.zeros(vector_size))\n",
    "    return np.array(embeddings)\n",
    "\n",
    "X_train_word2vec = get_sentence_embedding(train_data[\"cleaned_text\"].apply(lambda x: x.split()), word2vec_model, vector_size=400)\n",
    "X_val_word2vec = get_sentence_embedding(val_data[\"cleaned_text\"].apply(lambda x: x.split()), word2vec_model, vector_size=400)\n",
    "X_test_word2vec = get_sentence_embedding(test_data[\"cleaned_text\"].apply(lambda x: x.split()), word2vec_model, vector_size=400)\n",
    "\n",
    "# --- Dimensionality Reduction ---\n",
    "svd = TruncatedSVD(n_components=200, random_state=42)  # Experimenting with increased dimensions\n",
    "X_train_reduced = svd.fit_transform(X_train_word2vec)\n",
    "X_val_reduced = svd.transform(X_val_word2vec)\n",
    "X_test_reduced = svd.transform(X_test_word2vec)\n",
    "\n",
    "# Normalize Features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_reduced)\n",
    "X_val_scaled = scaler.transform(X_val_reduced)\n",
    "X_test_scaled = scaler.transform(X_test_reduced)\n",
    "\n",
    "# --- Target Variable ---\n",
    "y_train = train_data[\"score\"]\n",
    "y_val = val_data[\"score\"]\n",
    "\n",
    "# --- Ridge Regression ---\n",
    "ridge_param_grid = {\"alpha\": np.logspace(-5, 5, 50)}\n",
    "ridge = Ridge()\n",
    "\n",
    "ridge_grid = GridSearchCV(\n",
    "    estimator=ridge,\n",
    "    param_grid=ridge_param_grid,\n",
    "    scoring=spearman_scorer,\n",
    "    cv=10,  # 10-fold CV\n",
    "    verbose=10,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "ridge_grid.fit(X_train_scaled, y_train)\n",
    "ridge_best = ridge_grid.best_estimator_\n",
    "print(\"Best Ridge Parameters:\", ridge_grid.best_params_)\n",
    "print(\"Best Ridge Spearman CV Score:\", ridge_grid.best_score_)\n",
    "\n",
    "# --- LightGBM ---\n",
    "lgbm_param_grid = {\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"n_estimators\": [200, 500, 1000],\n",
    "    \"max_depth\": [-1, 5, 10],\n",
    "    \"num_leaves\": [20, 31, 50]\n",
    "}\n",
    "lgbm = LGBMRegressor()\n",
    "\n",
    "lgbm_grid = GridSearchCV(\n",
    "    estimator=lgbm,\n",
    "    param_grid=lgbm_param_grid,\n",
    "    scoring=spearman_scorer,\n",
    "    cv=10,\n",
    "    verbose=10,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "lgbm_grid.fit(X_train_scaled, y_train)\n",
    "lgbm_best = lgbm_grid.best_estimator_\n",
    "print(\"Best LightGBM Parameters:\", lgbm_grid.best_params_)\n",
    "print(\"Best LightGBM Spearman CV Score:\", lgbm_grid.best_score_)\n",
    "\n",
    "# --- XGBoost ---\n",
    "xgb_param_grid = {\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"n_estimators\": [200, 500, 1000],\n",
    "    \"max_depth\": [3, 6, 10],\n",
    "    \"subsample\": [0.6, 0.8, 1.0]\n",
    "}\n",
    "xgb = XGBRegressor()\n",
    "\n",
    "xgb_grid = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=xgb_param_grid,\n",
    "    scoring=spearman_scorer,\n",
    "    cv=10,\n",
    "    verbose=10,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "xgb_grid.fit(X_train_scaled, y_train)\n",
    "xgb_best = xgb_grid.best_estimator_\n",
    "print(\"Best XGBoost Parameters:\", xgb_grid.best_params_)\n",
    "print(\"Best XGBoost Spearman CV Score:\", xgb_grid.best_score_)\n",
    "\n",
    "# --- Ensemble Model ---\n",
    "ensemble = VotingRegressor([\n",
    "    ('ridge', ridge_best),\n",
    "    ('lgbm', lgbm_best),\n",
    "    ('xgb', xgb_best)\n",
    "])\n",
    "ensemble.fit(X_train_scaled, y_train)\n",
    "\n",
    "# --- Evaluate on Validation Set ---\n",
    "y_val_pred = ensemble.predict(X_val_scaled)\n",
    "val_spearman_corr = spearman_correlation(y_val, y_val_pred)\n",
    "print(\"Validation Spearman Correlation (Ensemble):\", val_spearman_corr)\n",
    "\n",
    "# --- Generate Predictions for Test Set ---\n",
    "y_test_pred = ensemble.predict(X_test_scaled)\n",
    "\n",
    "# --- Create Sample Submission ---\n",
    "submission = pd.DataFrame({\"id\": test_data[\"id\"], \"score\": y_test_pred})\n",
    "submission.to_csv(\"submission_ensemble.csv\", index=False)\n",
    "print(\"Sample submission file 'submission_ensemble.csv' generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\RoG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016512 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 102000\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 400\n",
      "[LightGBM] [Info] Start training from score 0.520791\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013099 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 102000\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 400\n",
      "[LightGBM] [Info] Start training from score 0.520791\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Validation Spearman Correlation (Ensemble): 0.6197409213401084\n",
      "Sample submission file 'submission_ensemble_optimized.csv' generated successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from scipy.stats import spearmanr\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# --- Load Dataset ---\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "val_data = pd.read_csv(\"val.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# --- Define Spearman Correlation Metric ---\n",
    "def spearman_correlation(y_true, y_pred):\n",
    "    return spearmanr(y_true, y_pred).correlation\n",
    "\n",
    "spearman_scorer = make_scorer(spearman_correlation, greater_is_better=True)\n",
    "\n",
    "# --- Preprocessing ---\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = ' '.join(stemmer.stem(word) for word in text.split() if word not in stop_words)  # Stemming and stopwords\n",
    "    return text\n",
    "\n",
    "train_data[\"cleaned_text\"] = train_data[\"text\"].apply(preprocess_text)\n",
    "val_data[\"cleaned_text\"] = val_data[\"text\"].apply(preprocess_text)\n",
    "test_data[\"cleaned_text\"] = test_data[\"text\"].apply(preprocess_text)\n",
    "\n",
    "# Combine Training and Validation Data for Word2Vec\n",
    "combined_sentences = pd.concat([train_data[\"cleaned_text\"], val_data[\"cleaned_text\"]]).apply(lambda x: x.split())\n",
    "\n",
    "# --- Word2Vec Training ---\n",
    "word2vec_model = Word2Vec(\n",
    "    sentences=combined_sentences,\n",
    "    vector_size=300,  # Optimized for smaller dataset\n",
    "    window=5,  # Smaller context window\n",
    "    min_count=3,\n",
    "    workers=4,\n",
    "    epochs=30,  # Reduced epochs\n",
    "    sg=1,\n",
    "    negative=10\n",
    ")\n",
    "\n",
    "def get_sentence_embedding(sentences, model, vector_size):\n",
    "    embeddings = []\n",
    "    for sentence in sentences:\n",
    "        vectors = [model.wv[word] for word in sentence if word in model.wv]\n",
    "        if vectors:\n",
    "            embeddings.append(np.mean(vectors, axis=0))\n",
    "        else:\n",
    "            embeddings.append(np.zeros(vector_size))\n",
    "    return np.array(embeddings)\n",
    "\n",
    "X_train_word2vec = get_sentence_embedding(train_data[\"cleaned_text\"].apply(lambda x: x.split()), word2vec_model, vector_size=300)\n",
    "X_val_word2vec = get_sentence_embedding(val_data[\"cleaned_text\"].apply(lambda x: x.split()), word2vec_model, vector_size=300)\n",
    "X_test_word2vec = get_sentence_embedding(test_data[\"cleaned_text\"].apply(lambda x: x.split()), word2vec_model, vector_size=300)\n",
    "\n",
    "# --- TF-IDF Features ---\n",
    "tfidf = TfidfVectorizer(max_features=3000, ngram_range=(1, 2))  # Reduced max features\n",
    "X_train_tfidf = tfidf.fit_transform(train_data[\"cleaned_text\"])\n",
    "X_val_tfidf = tfidf.transform(val_data[\"cleaned_text\"])\n",
    "X_test_tfidf = tfidf.transform(test_data[\"cleaned_text\"])\n",
    "\n",
    "# --- Dimensionality Reduction for TF-IDF ---\n",
    "svd_tfidf = TruncatedSVD(n_components=100, random_state=42)  # Reduced dimensions\n",
    "X_train_tfidf_reduced = svd_tfidf.fit_transform(X_train_tfidf)\n",
    "X_val_tfidf_reduced = svd_tfidf.transform(X_val_tfidf)\n",
    "X_test_tfidf_reduced = svd_tfidf.transform(X_test_tfidf)\n",
    "\n",
    "# --- Combine Features ---\n",
    "X_train_combined = np.hstack((X_train_word2vec, X_train_tfidf_reduced))\n",
    "X_val_combined = np.hstack((X_val_word2vec, X_val_tfidf_reduced))\n",
    "X_test_combined = np.hstack((X_test_word2vec, X_test_tfidf_reduced))\n",
    "\n",
    "# Normalize Features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_combined)\n",
    "X_val_scaled = scaler.transform(X_val_combined)\n",
    "X_test_scaled = scaler.transform(X_test_combined)\n",
    "\n",
    "# --- Target Variable ---\n",
    "y_train = train_data[\"score\"]\n",
    "y_val = val_data[\"score\"]\n",
    "\n",
    "# --- Ridge Regression ---\n",
    "ridge_param_grid = {\"alpha\": [1, 10, 100, 1000]}\n",
    "ridge = Ridge()\n",
    "\n",
    "ridge_grid = GridSearchCV(\n",
    "    estimator=ridge,\n",
    "    param_grid=ridge_param_grid,\n",
    "    scoring=spearman_scorer,\n",
    "    cv=5,\n",
    "    verbose=10,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "ridge_grid.fit(X_train_scaled, y_train)\n",
    "ridge_best = ridge_grid.best_estimator_\n",
    "\n",
    "# --- LightGBM ---\n",
    "lgbm_param_grid = {\n",
    "    \"learning_rate\": [0.05, 0.1],\n",
    "    \"n_estimators\": [500, 1000],\n",
    "    \"max_depth\": [5, 10],\n",
    "    \"num_leaves\": [31, 50]\n",
    "}\n",
    "lgbm = LGBMRegressor()\n",
    "\n",
    "lgbm_grid = GridSearchCV(\n",
    "    estimator=lgbm,\n",
    "    param_grid=lgbm_param_grid,\n",
    "    scoring=spearman_scorer,\n",
    "    cv=5,\n",
    "    verbose=10,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "lgbm_grid.fit(X_train_scaled, y_train)\n",
    "lgbm_best = lgbm_grid.best_estimator_\n",
    "\n",
    "# --- XGBoost ---\n",
    "xgb_param_grid = {\n",
    "    \"learning_rate\": [0.05, 0.1],\n",
    "    \"n_estimators\": [500, 1000],\n",
    "    \"max_depth\": [3, 6],\n",
    "    \"subsample\": [0.8, 1.0]\n",
    "}\n",
    "xgb = XGBRegressor()\n",
    "\n",
    "xgb_grid = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=xgb_param_grid,\n",
    "    scoring=spearman_scorer,\n",
    "    cv=5,\n",
    "    verbose=10,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "xgb_grid.fit(X_train_scaled, y_train)\n",
    "xgb_best = xgb_grid.best_estimator_\n",
    "\n",
    "# --- Ensemble Model ---\n",
    "ensemble = VotingRegressor([('ridge', ridge_best), ('lgbm', lgbm_best), ('xgb', xgb_best)])\n",
    "ensemble.fit(X_train_scaled, y_train)\n",
    "\n",
    "# --- Evaluate on Validation Set ---\n",
    "y_val_pred = ensemble.predict(X_val_scaled)\n",
    "val_spearman_corr = spearman_correlation(y_val, y_val_pred)\n",
    "print(\"Validation Spearman Correlation (Ensemble):\", val_spearman_corr)\n",
    "\n",
    "# --- Generate Predictions for Test Set ---\n",
    "y_test_pred = ensemble.predict(X_test_scaled)\n",
    "\n",
    "# --- Create Sample Submission ---\n",
    "submission = pd.DataFrame({\"id\": test_data[\"id\"], \"score\": y_test_pred})\n",
    "submission.to_csv(\"mihaicapatina23.csv\", index=False)\n",
    "print(\"Sample submission file 'submission_ensemble_optimized.csv' generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikeras\n",
      "  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from scikeras) (3.3.3)\n",
      "Collecting scikit-learn>=1.4.2 (from scikeras)\n",
      "  Downloading scikit_learn-1.5.2-cp310-cp310-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: absl-py in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from keras>=3.2.0->scikeras) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from keras>=3.2.0->scikeras) (1.26.0)\n",
      "Requirement already satisfied: rich in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from keras>=3.2.0->scikeras) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from keras>=3.2.0->scikeras) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.3.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (3.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from optree->keras>=3.2.0->scikeras) (4.8.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from rich->keras>=3.2.0->scikeras) (2.17.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\rog\\anaconda3\\envs\\licenta\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n",
      "Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n",
      "Downloading scikit_learn-1.5.2-cp310-cp310-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/11.0 MB 3.5 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.6/11.0 MB 6.7 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.6/11.0 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 15.7 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 4.1/11.0 MB 18.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.8/11.0 MB 21.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.3/11.0 MB 23.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.9/11.0 MB 24.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.5/11.0 MB 28.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 29.7 MB/s eta 0:00:00\n",
      "Installing collected packages: scikit-learn, scikeras\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.3.2\n",
      "    Uninstalling scikit-learn-1.3.2:\n",
      "      Successfully uninstalled scikit-learn-1.3.2\n",
      "Successfully installed scikeras-0.13.0 scikit-learn-1.5.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\RoG\\anaconda3\\envs\\licenta\\Lib\\site-packages\\~klearn'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "!pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026452 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 153000\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 600\n",
      "[LightGBM] [Info] Start training from score 0.520791\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 153000\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 600\n",
      "[LightGBM] [Info] Start training from score 0.522991\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018724 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 153000\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 600\n",
      "[LightGBM] [Info] Start training from score 0.517383\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 153000\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 600\n",
      "[LightGBM] [Info] Start training from score 0.521470\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018813 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 153000\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 600\n",
      "[LightGBM] [Info] Start training from score 0.523460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 153000\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 600\n",
      "[LightGBM] [Info] Start training from score 0.518652\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Validation Spearman Correlation: 0.6217523776103973\n",
      "Submission saved!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# --- Spearman Correlation ---\n",
    "def spearman_correlation(y_true, y_pred):\n",
    "    return spearmanr(y_true, y_pred).correlation\n",
    "\n",
    "spearman_scorer = make_scorer(spearman_correlation, greater_is_better=True)\n",
    "\n",
    "# --- Load Data ---\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "val_data = pd.read_csv(\"val.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# --- Preprocessing ---\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    return text.strip()\n",
    "\n",
    "train_data[\"cleaned_text\"] = train_data[\"text\"].apply(preprocess_text)\n",
    "val_data[\"cleaned_text\"] = val_data[\"text\"].apply(preprocess_text)\n",
    "test_data[\"cleaned_text\"] = test_data[\"text\"].apply(preprocess_text)\n",
    "\n",
    "# --- Word2Vec Embeddings ---\n",
    "sentences = train_data[\"cleaned_text\"].apply(str.split).tolist()\n",
    "word2vec_model = Word2Vec(sentences, vector_size=300, window=5, min_count=2, workers=4, epochs=50)\n",
    "\n",
    "def get_sentence_embedding(texts, model, vector_size=300):\n",
    "    embeddings = []\n",
    "    for text in texts:\n",
    "        vectors = [model.wv[word] for word in text.split() if word in model.wv]\n",
    "        if vectors:\n",
    "            embeddings.append(np.mean(vectors, axis=0))\n",
    "        else:\n",
    "            embeddings.append(np.zeros(vector_size))\n",
    "    return np.array(embeddings)\n",
    "\n",
    "X_train_word2vec = get_sentence_embedding(train_data[\"cleaned_text\"], word2vec_model)\n",
    "X_val_word2vec = get_sentence_embedding(val_data[\"cleaned_text\"], word2vec_model)\n",
    "X_test_word2vec = get_sentence_embedding(test_data[\"cleaned_text\"], word2vec_model)\n",
    "\n",
    "# --- TF-IDF Features ---\n",
    "tfidf = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "X_train_tfidf = tfidf.fit_transform(train_data[\"cleaned_text\"]).toarray()\n",
    "X_val_tfidf = tfidf.transform(val_data[\"cleaned_text\"]).toarray()\n",
    "X_test_tfidf = tfidf.transform(test_data[\"cleaned_text\"]).toarray()\n",
    "\n",
    "# --- Dimensionality Reduction ---\n",
    "svd = TruncatedSVD(n_components=300, random_state=42)\n",
    "X_train_tfidf_reduced = svd.fit_transform(X_train_tfidf)\n",
    "X_val_tfidf_reduced = svd.transform(X_val_tfidf)\n",
    "X_test_tfidf_reduced = svd.transform(X_test_tfidf)\n",
    "\n",
    "# --- Combine Features ---\n",
    "X_train_combined = np.hstack((X_train_word2vec, X_train_tfidf_reduced))\n",
    "X_val_combined = np.hstack((X_val_word2vec, X_val_tfidf_reduced))\n",
    "X_test_combined = np.hstack((X_test_word2vec, X_test_tfidf_reduced))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_combined = scaler.fit_transform(X_train_combined)\n",
    "X_val_combined = scaler.transform(X_val_combined)\n",
    "X_test_combined = scaler.transform(X_test_combined)\n",
    "\n",
    "y_train = train_data[\"score\"].values\n",
    "y_val = val_data[\"score\"].values\n",
    "\n",
    "# --- Hyperparameter Optimization with Stacking ---\n",
    "ridge = Ridge(alpha=10)\n",
    "lgbm = LGBMRegressor(\n",
    "    n_estimators=1000, learning_rate=0.05, max_depth=8, num_leaves=31, random_state=42\n",
    ")\n",
    "xgb = XGBRegressor(\n",
    "    n_estimators=1000, learning_rate=0.05, max_depth=6, subsample=0.8, colsample_bytree=0.8, random_state=42\n",
    ")\n",
    "\n",
    "stacking_regressor = StackingRegressor(\n",
    "    estimators=[(\"ridge\", ridge), (\"lgbm\", lgbm), (\"xgb\", xgb)],\n",
    "    final_estimator=Ridge(alpha=1.0)\n",
    ")\n",
    "\n",
    "stacking_regressor.fit(X_train_combined, y_train)\n",
    "\n",
    "# --- Evaluate ---\n",
    "val_preds = stacking_regressor.predict(X_val_combined)\n",
    "val_spearman_corr = spearman_correlation(y_val, val_preds)\n",
    "print(f\"Validation Spearman Correlation: {val_spearman_corr}\")\n",
    "\n",
    "# --- Test Predictions ---\n",
    "test_preds = stacking_regressor.predict(X_test_combined)\n",
    "submission = pd.DataFrame({\"id\": test_data[\"id\"], \"score\": test_preds})\n",
    "submission.to_csv(\"laurentiupopescu21.csv\", index=False)\n",
    "print(\"Submission saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "licenta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
